<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[大话正则表达式]]></title>
    <url>%2F2019%2F09%2F30%2Fnarration-of-regex%2F</url>
    <content type="text"><![CDATA[语法元字符 字符 描述 \d 匹配一个数字字符。等价于 [0-9]。 \D 匹配一个非数字字符。等价于 [^0-9]。 \w 匹配字母、数字、下划线。等价于’[A-Za-z0-9_]‘ \W 匹配非字母、数字、下划线。等价于 ‘[^A-Za-z0-9_]‘ \s 匹配任何空白字符，包括空格、制表符、换页符 \S 匹配任何非空白字符。等价于 [^ \f\n\r\t\v] . 匹配除换行符（\n、\r）之外的任何单个字符。要匹配包括 ‘\n’ 在内的任何字符，请使用像”(. \f 匹配一个换页符。 \n 匹配一个换行符。 \r 匹配一个回车符。 \t 匹配一个制表符。 \v 匹配一个垂直制表符。 ^ 匹配输入字符串开始的位置。 $ 匹配输入字符串结尾的位置 \b 匹配一个单词边界，也就是指单词和空格间的位置。例如， ‘er\b’ 可以匹配”never” 中的 ‘er’，但不能匹配 “verb” 中的 ‘er’。 \B 与 \b 相反：er\B’ 能匹配 “verb” 中的 ‘er’，但不能匹配 “never” 中的 ‘er’。 区间 字符 描述 [0-9] 匹配 0-9 之间的数字 [A-Z] 匹配 A-Z 之间的字母，也可以组合 [A-Za-z0-9] 限定符 字符 描述 * 匹配前面的子表达式零次或多次。例如，zo* 能匹配 “z” 以及 “zoo”。* 等价于{0,} + 匹配前面的子表达式一次或多次。例如，’zo+’ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,} ? 匹配前面的子表达式零次或一次。例如，”do(es)?” 可以匹配 “do” 、 “does” 中的 “does” 、 “doxy” 中的 “do” 。? 等价于 {0,1} {n} n 是一个非负整数。匹配确定的 n 次。例如，’o{2}’ 不能匹配 “Bob” 中的 ‘o’，但是能匹配 “food” 中的两个 o {n,} n 是一个非负整数。至少匹配n 次。例如，’o{2,}’ 不能匹配 “Bob” 中的 ‘o’，但能匹配 “foooood” 中的所有 o。’o{1,}’ 等价于 ‘o+’。’o{0,}’ 则等价于 ‘o*‘ {n,m} m 和 n 均为非负整数，其中n &lt;= m。最少匹配 n 次且最多匹配 m 次。例如，”o{1,3}” 将匹配 “fooooood” 中的前三个 o。’o{0,1}’ 等价于 ‘o?’。请注意在逗号和两个数之间不能有空格 子表达式用圆括号组成一个比较复杂的匹配模式，那么一个圆括号的部分可以看作是一个子表达式。 捕获 &amp; 反捕获 多个子表达式所匹配到的内容按顺序出现在内存的缓冲区中捕获数组，称为捕获； 反捕获 与 捕获相反，标记不需要捕获的内容； 反向引用圆括号的内容被捕获后，可以在这个括号后被使用，从而写出一个比较实用的匹配模式； 贪婪匹配当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能多的字符； 懒惰 / 非贪婪当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能少的字符； 懒惰量词是在贪婪量词后面加个? 代码 说明 *? 重复多次，但尽可能少重复 +? 重复1次、多次，但尽可能少重复 ?? 重复0次、1次，但尽可能少重复 {n,m}? 重复n~m次，但尽可能少重复 {n,}? 重复n次以上，但尽可能少重复]]></content>
      <tags>
        <tag>regex</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话计算机网络]]></title>
    <url>%2F2019%2F09%2F24%2Fnarration-of-network%2F</url>
    <content type="text"><![CDATA[闲话计算机网络网络结构学习计算机网络时我们一般采用折中的办法，也就是中和 OSI 和 TCP/IP 的优点，采用一种只有五层协议的体系结构，这样既简洁又能将概念阐述清楚。 应用层（application layer） 通过应用进程间的交互来完成特定网络应用。应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如域名系统 DNS，支持万维网应用的 HTTP 协议，支持电子邮件的 SMTP 协议等等。我们把应用层交互的数据单元称为报文。 运输层（transport layer） 负责向两台主机进程之间的通信提供通用的数据传输服务。应用进程利用该服务传送应用层报文。“通用的”是指并不针对某一个特定的网络应用，而是多种应用可以使用同一个运输层服务。由于一台主机可同时运行多个线程，因此运输层有复用和分用的功能。所谓复用就是指多个应用层进程可同时使用下面运输层的服务，分用和复用相反，是运输层把收到的信息分别交付上面应用层中的相应进程。 网络层 在计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点， 确保数据及时传送。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP / IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报，简称数据报。 数据链路层（data link layer） 通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如：同步信息，地址信息，差错控制等）。在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。这样，数据链路层在收到一个帧后，就可从中提出数据部分，上交给网络层。控制信息还使接收端能够检测到所收到的帧中有无差错。如果发现差错，数据链路层就简单地丢弃这个出了差错的帧，以避免继续在网络中传送下去白白浪费网络资源。如果需要改正数据在链路层传输时出现差错（这就是说，数据链路层不仅要检错，而且还要纠错），那么就要采用可靠性传输协议来纠正出现的差错。这种方法会使链路层的协议复杂些。 物理层 在物理层上所传送的数据单位是比特。物理层（physical layer）的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。 每一层对应的网络协议计算机五层网络体系中涉及的协议非常多，下面就常用的做了列举：coggle脑图 ARP 协议的工作原理网络层的 ARP 协议完成了 IP 地址与物理地址的映射。首先，每台主机都会在自己的 ARP 缓冲区中建立一个 ARP 列表，以表示 IP 地址和 MAC 地址的对应关系。当源主机需要将一个数据包要发送到目的主机时，会首先检查自己 ARP 列表中是否存在该 IP 地址对应的 MAC 地址：如果有，就直接将数据包发送到这个 MAC 地址；如果没有，就向本地网段发起一个 ARP 请求的广播包，查询此目的主机对应的 MAC 地址。 此 ARP 请求数据包里包括源主机的 IP 地址、硬件地址、以及目的主机的 IP 地址。网络中所有的主机收到这个 ARP 请求后，会检查数据包中的目的 IP 是否和自己的 IP 地址一致。如果不相同就忽略此数据包；如果相同，该主机首先将发送端的 MAC 地址和 IP 地址添加到自己的 ARP 列表中，如果 ARP 表中已经存在该 IP 的信息，则将其覆盖，然后给源主机发送一个 ARP 响应数据包，告诉对方自己是它需要查找的 MAC 地址；源主机收到这个 ARP 响应数据包后，将得到的目的主机的 IP 地址和 MAC 地址添加到自己的 ARP 列表中，并利用此信息开始数据的传输。如果源主机一直没有收到 ARP 响应数据包，表示 ARP 查询失败。 IP 地址分类IP 地址是指互联网协议地址，是 IP 协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。IP 地址编址方案将 IP 地址空间划分为 A、B、C、D、E 五类，其中 A、B、C 是基本类，D、E 类作为多播和保留使用，为特殊地址。 每个 IP 地址包括两个标识码（ID），即网络 ID 和主机 ID。同一个物理网络上的所有主机都使用同一个网络 ID，网络上的一个主机（包括网络上工作站，服务器和路由器等）有一个主机 ID 与其对应。A~E 类地址的特点如下： A 类地址：以 0 开头，第一个字节范围：0~127； B 类地址：以 10 开头，第一个字节范围：128~191； C 类地址：以 110 开头，第一个字节范围：192~223； D 类地址：以 1110 开头，第一个字节范围为 224~239； E 类地址：以 1111 开头，保留地址 5、TCP 的主要特点是什么？1. TCP 是面向连接的。（就好像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连接）； 2. 每一条 TCP 连接只能有两个端点，每一条 TCP 连接只能是点对点的（一对一）； 3. TCP 提供可靠交付的服务。通过 TCP 连接传送的数据，无差错、不丢失、不重复、并且按序到达； 4. TCP 提供全双工通信。TCP 允许通信双方的应用进程在任何时候都能发送数据。TCP 连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据； 5. 面向字节流。TCP 中的“流”（Stream）指的是流入进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和 TCP 的交互是一次一个数据块（大小不等），但 TCP 把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。 6、UDP 的主要特点是什么？1. UDP 是无连接的； 2. UDP 使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）； 3. UDP 是面向报文的； 4. UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 直播，实时视频会议等）； 5. UDP 支持一对一、一对多、多对一和多对多的交互通信； 6. UDP 的首部开销小，只有 8 个字节，比 TCP 的 20 个字节的首部要短。 7、TCP 和 UDP 的区别？TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的运输服务（TCP 的可靠体现在 TCP 在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。 UDP 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如：QQ 语音、 QQ 视频 、直播等等。 8、TCP 和 UDP 分别对应的常见应用层协议有哪些？ 1. TCP 对应的应用层协议 FTP：定义了文件传输协议，使用 21 端口。常说某某计算机开了 FTP 服务便是启动了文件传输服务。下载文件，上传主页，都要用到 FTP 服务。 Telnet：它是一种用于远程登陆的端口，用户可以以自己的身份远程连接到计算机上，通过这种端口可以提供一种基于 DOS 模式下的通信服务。如以前的 BBS 是-纯字符界面的，支持 BBS 的服务器将 23 端口打开，对外提供服务。 SMTP：定义了简单邮件传送协议，现在很多邮件服务器都用的是这个协议，用于发送邮件。如常见的免费邮件服务中用的就是这个邮件服务端口，所以在电子邮件设置-中常看到有这么 SMTP 端口设置这个栏，服务器开放的是 25 号端口。 POP3：它是和 SMTP 对应，POP3 用于接收邮件。通常情况下，POP3 协议所用的是 110 端口。也是说，只要你有相应的使用 POP3 协议的程序（例如 Fo-xmail 或 Outlook），就可以不以 Web 方式登陆进邮箱界面，直接用邮件程序就可以收到邮件（如是163 邮箱就没有必要先进入网易网站，再进入自己的邮-箱来收信）。 HTTP：从 Web 服务器传输超文本到本地浏览器的传送协议。 2. UDP 对应的应用层协议 DNS：用于域名解析服务，将域名地址转换为 IP 地址。DNS 用的是 53 号端口。 SNMP：简单网络管理协议，使用 161 号端口，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势。 TFTP(Trival File Transfer Protocal)：简单文件传输协议，该协议在熟知端口 69 上使用 UDP 服务。 9、详细说下 TCP 三次握手的过程？ 1. 三次握手 TCP 建立连接的过程叫做握手，握手需要在客户和服务器之间交换三个 TCP 报文段。 最初客户端和服务端都处于 CLOSED(关闭) 状态。本例中 A（Client） 主动打开连接，B（Server） 被动打开连接。 一开始，B 的 TCP 服务器进程首先创建传输控制块TCB，准备接受客户端进程的连接请求。然后服务端进程就处于 LISTEN(监听) 状态，等待客户端的连接请求。如有，立即作出响应。 第一次握手：A 的 TCP 客户端进程也是首先创建传输控制块 TCB。然后，在打算建立 TCP 连接时，向 B 发出连接请求报文段，这时首部中的同步位 SYN=1，同时选择一个初始序号 seq = x。TCP 规定，SYN 报文段（即 SYN = 1 的报文段）不能携带数据，但要消耗掉一个序号。这时，TCP 客户进程进入 SYN-SENT（同步已发送）状态。 第二次握手：B 收到连接请求报文后，如果同意建立连接，则向 A 发送确认。在确认报文段中应把 SYN 位和 ACK 位都置 1，确认号是 ack = x + 1，同时也为自己选择一个初始序号 seq = y。请注意，这个报文段也不能携带数据，但同样要消耗掉一个序号。这时 TCP 服务端进程进入 SYN-RCVD（同步收到）状态。 第三次握手：TCP 客户进程收到 B 的确认后，还要向 B 给出确认。确认报文段的 ACK 置 1，确认号 ack = y + 1，而自己的序号 seq = x + 1。这时 ACK 报文段可以携带数据。但如果不携带数据则不消耗序号，这种情况下，下一个数据报文段的序号仍是 seq = x + 1。这时，TCP 连接已经建立，A 进入 ESTABLISHED（已建立连接）状态。 10、为什么两次握手不可以呢？为了防止已经失效的连接请求报文段突然又传送到了 B，因而产生错误。比如下面这种情况：A 发出的第一个连接请求报文段并没有丢失，而是在网路结点长时间滞留了，以致于延误到连接释放以后的某个时间段才到达 B。本来这是一个早已失效的报文段。但是 B 收到此失效的链接请求报文段后，就误认为 A 又发出一次新的连接请求。于是就向 A 发出确认报文段，同意建立连接。 对于上面这种情况，如果不进行第三次握手，B 发出确认后就认为新的运输连接已经建立了，并一直等待 A 发来数据。B 的许多资源就这样白白浪费了。 如果采用了三次握手，由于 A 实际上并没有发出建立连接请求，所以不会理睬 B 的确认，也不会向 B 发送数据。B 由于收不到确认，就知道 A 并没有要求建立连接。 11、为什么不需要四次握手？有人可能会说 A 发出第三次握手的信息后在没有接收到 B 的请求就已经进入了连接状态，那如果 A 的这个确认包丢失或者滞留了怎么办？ 我们需要明白一点，完全可靠的通信协议是不存在的。在经过三次握手之后，客户端和服务端已经可以确认之前的通信状况，都收到了确认信息。所以即便再增加握手次数也不能保证后面的通信完全可靠，所以是没有必要的。 12、Server 端收到 Client 端的 SYN 后，为什么还要传回 SYN？接收端传回发送端所发送的 SYN 是为了告诉发送端，我接收到的信息确实就是你所发送的信号了。 SYN 是 TCP / IP 建立连接时使用的握手信号。在客户机和服务器之间建立正常的 TCP 网络连接时，客户机首先发出一个 SYN 消息，服务器使用 SYN-ACK 应答表示接收到了这个消息，最后客户机再以 ACK(Acknowledgement[汉译：确认字符，在数据通信传输中，接收站发给发送站的一种传输控制字符。它表示确认发来的数据已经接受无误]）消息响应。这样在客户机和服务器之间才能建立起可靠的 TCP 连接，数据才可以在客户机和服务器之间传递。 13、传了 SYN，为什么还要传 ACK？双方通信无误必须是两者互相发送信息都无误。传了 SYN，证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要 ACK 信号来进行验证。 14、详细说下 TCP 四次挥手的过程？据传输结束后，通信的双方都可以释放连接。现在 A 和 B 都处于 ESTABLISHED 状态。 第一次挥手：A 的应用进程先向其 TCP 发出连接释放报文段，并停止再发送数据，主动关闭 TCP 连接。A 把连接释放报文段首部的终止控制位 FIN 置 1，其序号 seq = u（等于前面已传送过的数据的最后一个字节的序号加 1），这时 A 进入 FIN-WAIT-1（终止等待1）状态，等待 B 的确认。请注意：TCP 规定，FIN 报文段即使不携带数据，也将消耗掉一个序号。 第二次挥手：B 收到连接释放报文段后立即发出确认，确认号是 ack = u + 1，而这个报文段自己的序号是 v（等于 B 前面已经传送过的数据的最后一个字节的序号加1），然后 B 就进入 CLOSE-WAIT（关闭等待）状态。TCP 服务端进程这时应通知高层应用进程，因而从 A 到 B 这个方向的连接就释放了，这时的 TCP 连接处于半关闭（half-close）状态，即 A 已经没有数据要发送了，但 B 若发送数据，A 仍要接收。也就是说，从 B 到 A 这个方向的连接并未关闭，这个状态可能会持续一段时间。A 收到来自 B 的确认后，就进入 FIN-WAIT-2(终止等待2)状态，等待 B 发出的连接释放报文段。 第三次挥手：若 B 已经没有要向 A 发送的数据，其应用进程就通知 TCP 释放连接。这时 B 发出的连接释放报文段必须使 FIN = 1。假定 B 的序号为 w（在半关闭状态，B 可能又发送了一些数据）。B 还必须重复上次已发送过的确认号 ack = u + 1。这时 B 就进入 LAST-ACK(最后确认)状态，等待 A 的确认。 第四次挥手：A 在收到 B 的连接释放报文后，必须对此发出确认。在确认报文段中把 ACK 置 1，确认号 ack = w + 1，而自己的序号 seq = u + 1（前面发送的 FIN 报文段要消耗一个序号）。然后进入 TIME-WAIT(时间等待) 状态。请注意，现在 TCP 连接还没有释放掉。必须经过时间等待计时器设置的时间 2MSL（MSL：最长报文段寿命）后，A 才能进入到 CLOSED 状态，然后撤销传输控制块，结束这次 TCP 连接。当然如果 B 一收到 A 的确认就进入 CLOSED 状态，然后撤销传输控制块。所以在释放连接时，B 结束 TCP 连接的时间要早于 A。 15、为什么 TIME-WAIT 状态必须等待 2MSL 的时间呢？1. 为了保证 A 发送的最后一个 ACK 报文段能够到达 B。这个 ACK 报文段有可能丢失，因而使处在 LAST-ACK 状态的 B 收不到对已发送的 FIN + ACK 报文段的确认。B 会超时重传这个 FIN+ACK 报文段，而 A 就能在 2MSL 时间内（超时 + 1MSL 传输）收到这个重传的 FIN+ACK 报文段。接着 A 重传一次确认，重新启动 2MSL 计时器。最后，A 和 B 都正常进入到 CLOSED 状态。如果 A 在 TIME-WAIT 状态不等待一段时间，而是在发送完 ACK 报文段后立即释放连接，那么就无法收到 B 重传的 FIN + ACK 报文段，因而也不会再发送一次确认报文段，这样，B 就无法按照正常步骤进入 CLOSED 状态。 2. 防止已失效的连接请求报文段出现在本连接中。A 在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样就可以使下一个连接中不会出现这种旧的连接请求报文段。 16、为什么第二次跟第三次不能合并, 第二次和第三次之间的等待是什么?当服务器执行第二次挥手之后, 此时证明客户端不会再向服务端请求任何数据, 但是服务端可能还正在给客户端发送数据（可能是客户端上一次请求的资源还没有发送完毕），所以此时服务端会等待把之前未传输完的数据传输完毕之后再发送关闭请求。 17、保活计时器的作用？除时间等待计时器外，TCP 还有一个保活计时器（keepalive timer）。设想这样的场景：客户已主动与服务器建立了 TCP 连接。但后来客户端的主机突然发生故障。显然，服务器以后就不能再收到客户端发来的数据。因此，应当有措施使服务器不要再白白等待下去。这就需要使用保活计时器了。 服务器每收到一次客户的数据，就重新设置保活计时器，时间的设置通常是两个小时。若两个小时都没有收到客户端的数据，服务端就发送一个探测报文段，以后则每隔 75 秒钟发送一次。若连续发送 10个 探测报文段后仍然无客户端的响应，服务端就认为客户端出了故障，接着就关闭这个连接。 18、TCP 协议是如何保证可靠传输的？1. 数据包校验：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时 TCP 发送数据端超时后会重发数据； 2. 对失序数据包重排序：既然 TCP 报文段作为 IP 数据报来传输，而 IP 数据报的到达可能会失序，因此 TCP 报文段的到达也可能会失序。TCP 将对失序数据进行重新排序，然后才交给应用层； 3. 丢弃重复数据：对于重复数据，能够丢弃重复数据； 4. 应答机制：当 TCP 收到发自 TCP 连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒； 5. 超时重发：当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段； 6. 流量控制：TCP 连接的每一方都有固定大小的缓冲空间。TCP 的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 19、谈谈你对停止等待协议的理解？停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组；在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。主要包括以下几种情况：无差错情况、出现差错情况（超时重传）、确认丢失和确认迟到、确认丢失和确认迟到。 20、谈谈你对 ARQ 协议的理解？ 自动重传请求 ARQ 协议 停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为自动重传请求 ARQ。 连续 ARQ 协议 连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。 21、谈谈你对滑动窗口的了解？TCP 利用滑动窗口实现流量控制的机制。滑动窗口（Sliding window）是一种流量控制技术。早期的网络通信中，通信双方不会考虑网络的拥挤情况直接发送数据。由于大家不知道网络拥塞状况，同时发送数据，导致中间节点阻塞掉包，谁也发不了数据，所以就有了滑动窗口机制来解决此问题。 TCP 中采用滑动窗口来进行传输控制，滑动窗口的大小意味着接收方还有多大的缓冲区可以用于接收数据。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为 0 时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据，例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个 1 字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。 22、谈下你对流量控制的理解？TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。 23、谈下你对 TCP 拥塞控制的理解？使用了哪些算法？拥塞控制和流量控制不同，前者是一个全局性的过程，而后者指点对点通信量的控制。在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫拥塞。 拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致于过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。 为了进行拥塞控制，TCP 发送方要维持一个拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。 TCP 的拥塞控制采用了四种算法，即：慢开始、拥塞避免、快重传和快恢复。在网络层也可以使路由器采用适当的分组丢弃策略（如：主动队列管理 AQM），以减少网络拥塞的发生。 慢开始： 慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd 初始值为 1，每经过一个传播轮次，cwnd 加倍。 拥塞避免： 拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间 RTT 就把发送方的 cwnd 加 1。 快重传与快恢复： 在 TCP/IP 中，快速重传和快恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。 没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。 有了 FRR，就不会因为重传时要求的暂停被耽误。当有单独的数据包丢失时，快速重传和快恢复（FRR）能最有效地工作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。 24、什么是粘包？在进行 Java NIO 学习时，可能会发现：如果客户端连续不断的向服务端发送数据包时，服务端接收的数据会出现两个数据包粘在一起的情况。 1. TCP 是基于字节流的，虽然应用层和 TCP 传输层之间的数据交互是大小不等的数据块，但是 TCP 把这些数据块仅仅看成一连串无结构的字节流，没有边界； 2. 从 TCP 的帧结构也可以看出，在 TCP 的首部没有表示数据长度的字段。 基于上面两点，在使用 TCP 传输数据时，才有粘包或者拆包现象发生的可能。一个数据包中包含了发送端发送的两个数据包的信息，这种现象即为粘包。 接收端收到了两个数据包，但是这两个数据包要么是不完整的，要么就是多出来一块，这种情况即发生了拆包和粘包。拆包和粘包的问题导致接收端在处理的时候会非常困难，因为无法区分一个完整的数据包。 25、TCP 黏包是怎么产生的？ 发送方产生粘包 采用 TCP 协议传输数据的客户端与服务器经常是保持一个长连接的状态（一次连接发一次数据不存在粘包），双方在连接不断开的情况下，可以一直传输数据。但当发送的数据包过于的小时，那么 TCP 协议默认的会启用 Nagle 算法，将这些较小的数据包进行合并发送（缓冲区数据发送是一个堆压的过程）；这个合并过程就是在发送缓冲区中进行的，也就是说数据发送出来它已经是粘包的状态了。 接收方产生粘包 接收方采用 TCP 协议接收数据时的过程是这样的：数据到接收方，从网络模型的下方传递至传输层，传输层的 TCP 协议处理是将其放置接收缓冲区，然后由应用层来主动获取（C 语言用 recv、read 等函数）；这时会出现一个问题，就是我们在程序中调用的读取数据函数不能及时的把缓冲区中的数据拿出来，而下一个数据又到来并有一部分放入的缓冲区末尾，等我们读取数据时就是一个粘包。（放数据的速度 &gt; 应用层拿数据速度） 26、怎么解决拆包和粘包？分包机制一般有两个通用的解决方法： 1. 特殊字符控制； 2. 在包头首都添加数据包的长度。 如果使用 netty 的话，就有专门的编码器和解码器解决拆包和粘包问题了。 tips：UDP 没有粘包问题，但是有丢包和乱序。不完整的包是不会有的，收到的都是完全正确的包。传送的数据单位协议是 UDP 报文或用户数据报，发送的时候既不合并，也不拆分。 27、你对 HTTP 状态码有了解吗？ 1XX 信息 1. 100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。 2XX 成功 1. 200 OK 2. 204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。 3. 206 Partial Content ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。 3XX 重定向 1. 301 Moved Permanently ：永久性重定向； 2. 302 Found ：临时性重定向； 3. 303 See Other ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。 4. 304 Not Modified ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。 5. 307 Temporary Redirect ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。 4XX 客户端错误 1. 400 Bad Request ：请求报文中存在语法错误。 2. 401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。 3. 403 Forbidden ：请求被拒绝。 4. 404 Not Found 5XX 服务器错误 1. 500 Internal Server Error ：服务器正在执行请求时发生错误； 2. 503 Service Unavailable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。 28、HTTP 状态码 301 和 302 代表的是什么？有什么区别？301，302 都是 HTTP 状态的编码，都代表着某个 URL 发生了转移。 区别： 301 redirect: 301 代表永久性转移（Permanently Moved） 302 redirect: 302 代表暂时性转移（Temporarily Moved） 29、forward 和 redirect 的区别？Forward 和 Redirect 代表了两种请求转发方式：直接转发和间接转发。 直接转发方式（Forward）：客户端和浏览器只发出一次请求，Servlet、HTML、JSP 或其它信息资源，由第二个信息资源响应该请求，在请求对象 request 中，保存的对象对于每个信息资源是共享的。 间接转发方式（Redirect）：实际是两次 HTTP 请求，服务器端在响应第一次请求的时候，让浏览器再向另外一个 URL 发出请求，从而达到转发的目的。 举个通俗的例子： 直接转发就相当于：“A 找 B 借钱，B 说没有，B 去找 C 借，借到借不到都会把消息传递给 A”； 间接转发就相当于：”A 找 B 借钱，B 说没有，让 A 去找 C 借”。 30、HTTP 方法有哪些？客户端发送的 请求报文 第一行为请求行，包含了方法字段。 1. GET：获取资源，当前网络中绝大部分使用的都是 GET； 2. HEAD：获取报文首部，和 GET 方法类似，但是不返回报文实体主体部分； 3. POST：传输实体主体 4. PUT：上传文件，由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法。 5. PATCH：对资源进行部分修改。PUT 也可以用于修改资源，但是只能完全替代原始资源，PATCH 允许部分修改。 6. OPTIONS：查询指定的 URL 支持的方法； 7. CONNECT：要求在与代理服务器通信时建立隧道。使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加密后经网络隧道传输。 8. TRACE：追踪路径。服务器会将通信路径返回给客户端。发送请求时，在 Max-Forwards 首部字段中填入数值，每经过一个服务器就会减 1，当数值为 0 时就停止传输。通常不会使用 TRACE，并且它容易受到 XST 攻击（Cross-Site Tracing，跨站追踪）。 31、说下 GET 和 POST 的区别？GET 和 POST 本质都是 HTTP 请求，只不过对它们的作用做了界定和适配，并且让他们适应各自的场景。 本质区别：GET 只是一次 HTTP请求，POST 先发请求头再发请求体，实际上是两次请求。 1. 从功能上讲，GET 一般用来从服务器上获取资源，POST 一般用来更新服务器上的资源； 2. 从 REST 服务角度上说，GET 是幂等的，即读取同一个资源，总是得到相同的数据，而 POST 不是幂等的，因为每次请求对资源的改变并不是相同的；进一步地，GET 不会改变服务器上的资源，而 POST 会对服务器资源进行改变； 3. 从请求参数形式上看，GET 请求的数据会附在 URL 之后，即将请求数据放置在 HTTP 报文的 请求头 中，以 ? 分割 URL 和传输数据，参数之间以 &amp; 相连。特别地，如果数据是英文字母/数字，原样发送；否则，会将其编码为 application/x-www-form-urlencoded MIME 字符串(如果是空格，转换为+，如果是中文/其他字符，则直接把字符串用 BASE64 加密，得出如：%E4%BD%A0%E5%A5%BD，其中 ％XX 中的 XX 为该符号以 16 进制表示的 ASCII)；而 POST 请求会把提交的数据则放置在是 HTTP 请求报文的 请求体 中； 4. 就安全性而言，POST 的安全性要比 GET 的安全性高，因为 GET 请求提交的数据将明文出现在 URL 上，而且 POST 请求参数则被包装到请求体中，相对更安全； 5. 从请求的大小看，GET 请求的长度受限于浏览器或服务器对 URL 长度的限制，允许发送的数据量比较小，而 POST 请求则是没有大小限制的。 32、在浏览器中输入 URL 地址到显示主页的过程？1. DNS 解析：浏览器查询 DNS，获取域名对应的 IP 地址：具体过程包括浏览器搜索自身的 DNS 缓存、搜索操作系统的 DNS 缓存、读取本地的 Host 文件和向本地 DNS 服务器进行查询等。对于向本地 DNS 服务器进行查询，如果要查询的域名包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析(此解析具有权威性)；如果要查询的域名不由本地 DNS 服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个 IP 地址映射，完成域名解析（此解析不具有权威性）。如果本地域名服务器并未缓存该网址映射关系，那么将根据其设置发起递归查询或者迭代查询； 2. TCP 连接：浏览器获得域名对应的 IP 地址以后，浏览器向服务器请求建立链接，发起三次握手； 3. 发送 HTTP 请求：TCP 连接建立起来后，浏览器向服务器发送 HTTP 请求； 4. 服务器处理请求并返回 HTTP 报文：服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器； 5. 浏览器解析渲染页面：浏览器解析并渲染视图，若遇到对 js 文件、css 文件及图片等静态资源的引用，则重复上述步骤并向服务器请求这些资源；浏览器根据其请求到的资源、数据渲染页面，最终向用户呈现一个完整的页面。 6. 连接结束。 33、DNS 的解析过程？1. 主机向本地域名服务器的查询一般都是采用递归查询。所谓递归查询就是：如果主机所询问的本地域名服务器不知道被查询的域名的 IP 地址，那么本地域名服务器就以 DNS 客户的身份，向根域名服务器继续发出查询请求报文(即替主机继续查询)，而不是让主机自己进行下一步查询。因此，递归查询返回的查询结果或者是所要查询的 IP 地址，或者是报错，表示无法查询到所需的 IP 地址。 2. 本地域名服务器向根域名服务器的查询的迭代查询。迭代查询的特点：当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的 IP 地址，要么告诉本地服务器：“你下一步应当向哪一个域名服务器进行查询”。然后让本地服务器进行后续的查询。根域名服务器通常是把自己知道的顶级域名服务器的 IP 地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询。顶级域名服务器在收到本地域名服务器的查询请求后，要么给出所要查询的 IP 地址，要么告诉本地服务器下一步应当向哪一个权限域名服务器进行查询。最后，本地域名服务器得到了所要解析的 IP 地址或报错，然后把这个结果返回给发起查询的主机。 34、谈谈你对域名缓存的了解？为了提高 DNS 查询效率，并减轻服务器的负荷和减少因特网上的 DNS 查询报文数量，在域名服务器中广泛使用了高速缓存，用来存放最近查询过的域名以及从何处获得域名映射信息的记录。 由于名字到地址的绑定并不经常改变，为保持高速缓存中的内容正确，域名服务器应为每项内容设置计时器并处理超过合理时间的项（例如：每个项目两天）。当域名服务器已从缓存中删去某项信息后又被请求查询该项信息，就必须重新到授权管理该项的域名服务器绑定信息。当权限服务器回答一个查询请求时，在响应中都指明绑定有效存在的时间值。增加此时间值可减少网络开销，而减少此时间值可提高域名解析的正确性。 不仅在本地域名服务器中需要高速缓存，在主机中也需要。许多主机在启动时从本地服务器下载名字和地址的全部数据库，维护存放自己最近使用的域名的高速缓存，并且只在从缓存中找不到名字时才使用域名服务器。维护本地域名服务器数据库的主机应当定期地检查域名服务器以获取新的映射信息，而且主机必须从缓存中删除无效的项。由于域名改动并不频繁，大多数网点不需花精力就能维护数据库的一致性。 35、谈下你对 HTTP 长连接和短连接的理解？分别应用于哪些场景？在 HTTP/1.0 中默认使用短连接。也就是说，客户端和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个 HTML 或其他类型的 Web 页中包含有其他的 Web 资源（如：JavaScript 文件、图像文件、CSS 文件等），每遇到这样一个 Web 资源，浏览器就会重新建立一个 HTTP 会话。 而从 HTTP/1.1 起，默认使用长连接，用以保持连接特性。使用长连接的 HTTP 协议，会在响应头加入这行代码 1Connection:keep-alive复制代码 在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输 HTTP 数据的 TCP 连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。 Keep-Alive 不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如：Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。 36、谈下 HTTP 1.0 和 1.1、1.2 的主要变化？ HTTP1.1 的主要变化： 1. HTTP1.0 经过多年发展，在 1.1 提出了改进。首先是提出了长连接，HTTP 可以在一次 TCP 连接中不断发送请求。 2. 然后 HTTP1.1 支持只发送 header 而不发送 body。原因是先用 header 判断能否成功，再发数据，节约带宽，事实上，post 请求默认就是这样做的。 3. HTTP1.1 的 host 字段。由于虚拟主机可以支持多个域名，所以一般将域名解析后得到 host。 HTTP2.0 的主要变化： 1. HTTP2.0 支持多路复用，同一个连接可以并发处理多个请求，方法是把 HTTP数据包拆为多个帧，并发有序的发送，根据序号在另一端进行重组，而不需要一个个 HTTP请求顺序到达； 2. HTTP2.0 支持服务端推送，就是服务端在 HTTP 请求到达后，除了返回数据之外，还推送了额外的内容给客户端； 3. HTTP2.0 压缩了请求头，同时基本单位是二进制帧流，这样的数据占用空间更少； 4. HTTP2.0 适用于 HTTPS 场景，因为其在 HTTP和 TCP 中间加了一层 SSL 层。 37、HTTPS 的工作过程？1. 客户端发送自己支持的加密规则给服务器，代表告诉服务器要进行连接了； 2. 服务器从中选出一套加密算法和 hash 算法以及自己的身份信息（地址等）以证书的形式发送给浏览器，证书中包含服务器信息，加密公钥，证书的办法机构； 3. 客户端收到网站的证书之后要做下面的事情： 3.1 验证证书的合法性； 3.2 果验证通过证书，浏览器会生成一串随机数，并用证书中的公钥进行加密； 3.3 用约定好的 hash 算法计算握手消息，然后用生成的密钥进行加密，然后一起发送给服务器。 4. 服务器接收到客户端传送来的信息，要做下面的事情： 4.1 用私钥解析出密码，用密码解析握手消息，验证 hash 值是否和浏览器发来的一致； 4.2 使用密钥加密消息； 5. 如果计算法 hash 值一致，握手成功。 38、HTTP 和 HTTPS 的区别？1. 开销：HTTPS 协议需要到 CA 申请证书，一般免费证书很少，需要交费； 2. 资源消耗：HTTP 是超文本传输协议，信息是明文传输，HTTPS 则是具有安全性的 ssl 加密传输协议，需要消耗更多的 CPU 和内存资源； 3. 端口不同：HTTP 和 HTTPS 使用的是完全不同的连接方式，用的端口也不一样，前者是 80，后者是 443； 4. 安全性：HTTP 的连接很简单，是无状态的；HTTPS 协议是由 TSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 HTTP 协议安全。 39、HTTPS 的优缺点？ 优点： 1. 使用 HTTPS 协议可认证用户和服务器，确保数据发送到正确的客户机和服务器； 2. HTTPS 协议是由 SSL + HTTP 协议构建的可进行加密传输、身份认证的网络协议，要比 HTTP 协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性； 3. HTTPS 是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。 缺点： 1. HTTPS 协议握手阶段比较费时，会使页面的加载时间延长近 50%，增加 10% 到 20% 的耗电； 2. HTTPS 连接缓存不如 HTTP 高效，会增加数据开销和功耗，甚至已有的安全措施也会因此而受到影响； 3. SSL 证书需要钱，功能越强大的证书费用越高，个人网站、小网站没有必要一般不会用； 4. SSL 证书通常需要绑定 IP，不能在同一 IP 上绑定多个域名，IPv4 资源不可能支撑这个消耗； 5. HTTPS 协议的加密范围也比较有限，在黑客攻击、拒绝服务攻击、服务器劫持等方面几乎起不到什么作用。最关键的，SSL 证书的信用链体系并不安全，特别是在某些国家可以控制 CA 根证书的情况下，中间人攻击一样可行。 40、什么是数字签名？为了避免数据在传输过程中被替换，比如黑客修改了你的报文内容，但是你并不知道，所以我们让发送端做一个数字签名，把数据的摘要消息进行一个加密，比如 MD5，得到一个签名，和数据一起发送。然后接收端把数据摘要进行 MD5 加密，如果和签名一样，则说明数据确实是真的。 41、什么是数字证书？对称加密中，双方使用公钥进行解密。虽然数字签名可以保证数据不被替换，但是数据是由公钥加密的，如果公钥也被替换，则仍然可以伪造数据，因为用户不知道对方提供的公钥其实是假的。所以为了保证发送方的公钥是真的，CA 证书机构会负责颁发一个证书，里面的公钥保证是真的，用户请求服务器时，服务器将证书发给用户，这个证书是经由系统内置证书的备案的。 42、什么是对称加密和非对称加密？对称密钥加密是指加密和解密使用同一个密钥的方式，这种方式存在的最大问题就是密钥发送问题，即如何安全地将密钥发给对方。 非对称加密指使用一对非对称密钥，即：公钥和私钥，公钥可以随意发布，但私钥只有自己知道。发送密文的一方使用对方的公钥进行加密处理，对方接收到加密信息后，使用自己的私钥进行解密。 由于非对称加密的方式不需要发送用来解密的私钥，所以可以保证安全性。但是和对称加密比起来，它非常的慢，所以我们还是要用对称加密来传送消息，但对称加密所使用的密钥我们可以通过非对称加密的方式发送出去。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Arthas 源码]]></title>
    <url>%2F2019%2F09%2F11%2Fnarration-of-arthas%2F</url>
    <content type="text"><![CDATA[arthas 是Alibaba开源的Java诊断工具，基于jvm Agent方式，使用Instrumentation方式修改字节码方式以及使用java.lang.management包提供的管理接口的方式进行java应用诊断。详细的介绍可以参考官方文档。官方文档地址： https://alibaba.github.io/arthas/GitHub地址： https://github.com/alibaba/arthas/ 组成模块arthas有多个模块组成，如下图所示： arthas-boot.jar 和 as.sh模块功能类似，分别使用java和shell脚本，下载对应的jar包（如 arthas-core.jar 或 arthas-agent.jar），并生成服务端和客户端的启动命令，然后启动客户端和服务端。 arthas-core.jar是服务端程序的启动入口类（入口main函数位于 com.taobao.arthas.core.Arthas），会调用virtualMachine#attach到目标进程，并加载arthas-agent.jar作为agent jar包。 arthas-agent.jar 既可以使用 premain 方式（在目标进程启动之前，通过-agent参数静态指定）；也可以通过 agentmain 方式（在进程启动之后attach上去）。 arthas-agent 会使用自定义的 classloader(ArthasClassLoader) 加载 arthas-core.jar 里面的 com.taobao.arthas.core.config.Configure 类，以及 com.taobao.arthas.core.server.ArthasBootstrap。 同时程序运行的时候会使用arthas-spy.jar。 arthas-spy.jar只包含 Spy 类，目的是为了将 Spy 类使用 BootstrapClassLoader 来加载，从而使目标进程的 java 应用可以访问 Spy 类。通过 ASM 修改字节码，可以将 Spy 类的方法ON_BEFORE_METHOD， ON_RETURN_METHOD等编织到目标类里面。Spy类你可以简单理解为类似spring aop的Advice，有前置方法、后置方法等。 arthas-client.jar客户端程序（入口类 com.taobao.arthas.client.TelnetConsole），用来连接arthas-core.jar启动的服务端代码，使用 telnet 方式。一般由 arthas-boot.jar 和 as.sh 来负责启动。 服务端代码分析读取配置、加载AgentBootstrap、ArthasBootstrap 关键字：arthas-core.jar Arthas.class com.taobao.arthas.agent.AgentBootstrap com.taobao.arthas.core.server.ArthasBootstrap主要做两件事情： 加载 Configure 配置 并运行 com.taobao.arthas.agent.AgentBootstrap使用ArthasClassloader加载com.taobao.arthas.core.config.Configure类(位于arthas-core.jar)，并将传递过来的序列化之后的config，反序列化成对应的Configure对象。 通过 com.taobao.arthas.agent.AgentBootstrap 加载 com.taobao.arthas.core.server.ArthasBootstrap使用ArthasClassloader加载com.taobao.arthas.core.server.ArthasBootstrap类（位于arthas-core.jar），并调用其中bind方法完成进程绑定。 从 as.sh 的启动命令可知，是从 arthas-core.jar 开始启动，arthas-core 的 pom.xml 文件里面指定了 mainClass 为 com.taobao.arthas.core.Arthas ，使得程序启动的时候从该类的 main 方法开始运行。Arthas源码如下： 12345678910111213141516171819202122public class Arthas &#123; private Arthas(String[] args) throws Exception &#123; attachAgent(parse(args)); &#125; private Configure parse(String[] args) &#123; // 省略非关键代码，解析启动参数作为配置，并填充到configure对象里面 return configure; &#125; private void attachAgent(Configure configure) throws Exception &#123; // 省略非关键代码，attach到目标进程 virtualMachine = VirtualMachine.attach("" + configure.getJavaPid()); virtualMachine.loadAgent(configure.getArthasAgent(), configure.getArthasCore() + ";" + configure.toString()); &#125; public static void main(String[] args) &#123; new Arthas(args); &#125;&#125; 解析入参为 ConfigureArthas首先解析入参，生成com.taobao.arthas.core.config.Configure类；Configure 包含了相关配置信息； 加载 arthas-agent.jar使用 jdk-tools 里面的VirtualMachine.loadAgent；加载 arthas-agent.jar 包，并运行； 第一个参数为agent路径； 第二个参数向jar包中的agentmain()方法传递参数（此处为agent-core.jar包路径和config序列化之后的字符串）； 运行 arthas-agent.jar 中的 AgentBootstraparthas-agent.jar包，指定了Agent-Class为com.taobao.arthas.agent.AgentBootstrap，同时可以使用Premain的方式和目标进程同时启动1234&lt;manifestEntries&gt; &lt;Premain-Class&gt;com.taobao.arthas.agent.AgentBootstrap&lt;/Premain-Class&gt; &lt;Agent-Class&gt;com.taobao.arthas.agent.AgentBootstrap&lt;/Agent-Class&gt;&lt;/manifestEntries&gt; 其中 Premain-Class 的 premain 和 Agent-Class 的 agentmain 都调用main方法。 AgentBootstrap 功能AgentBootstrap 的 main方法主要做4件事情： 加载 arthas-spy.jar找到 arthas-spy.jar 路径，并调用 Instrumentation#appendToBootstrapClassLoaderSearch 方法，使用 bootstrapClassLoader 来加载 arthas-spy.jar 里的 Spy 类。 自定义classLoader加载arthas-agentarthas-agent 路径传递给自定义的 classloader(ArthasClassloader) ，用来隔离 arthas 本身的类和目标进程的类。 加载 AdviceWeaver，并传递给SpyloadOrDefineClassLoader 方法使用 ArthasClassloader#loadClass 方法，加载 com.taobao.arthas.core.advisor.AdviceWeaver 类，并将里面的 methodOnBegin、methodOnReturnEnd、methodOnThrowingEnd 等方法取出赋值给 Spy 类对应的方法。同时 Spy 类里面的方法又会通过 ASM 字节码增强的方式，编织到目标代码的方法里面。使得 Spy 间谍类可以关联由 AppClassLoader 加载的目标进程的业务类和 ArthasClassloader 加载的 arthas 类，因此 Spy 类可以看做两者之间的桥梁。根据 classloader 双亲委派特性，子 classloader 可以访问父 classloader 加载的类。源码如下：123456789101112131415161718192021private static ClassLoader getClassLoader(Instrumentation inst, File spyJarFile, File agentJarFile) throws Throwable &#123; // 将Spy添加到BootstrapClassLoader inst.appendToBootstrapClassLoaderSearch(new JarFile(spyJarFile)); // 构造自定义的类加载器ArthasClassloader，尽量减少Arthas对现有工程的侵蚀 return loadOrDefineClassLoader(agentJarFile);&#125; private static void initSpy(ClassLoader classLoader) throws ClassNotFoundException, NoSuchMethodException &#123; // 该classLoader为ArthasClassloader Class&lt;?&gt; adviceWeaverClass = classLoader.loadClass(ADVICEWEAVER); Method onBefore = adviceWeaverClass.getMethod(ON_BEFORE, int.class, ClassLoader.class, String.class, String.class, String.class, Object.class, Object[].class); Method onReturn = adviceWeaverClass.getMethod(ON_RETURN, Object.class); Method onThrows = adviceWeaverClass.getMethod(ON_THROWS, Throwable.class); Method beforeInvoke = adviceWeaverClass.getMethod(BEFORE_INVOint int.class, String.class, String.class, String.class); adviceWeaverClass.getMethod(AFTER_INVOKE, int.class, Str int int.class, String.class, String.class, String.class); Method throwInvoke = adviceWeaverClass.getMethod(THROW_INVOKE, int.class, String.class, String.class, String.class); Method reset = AgentBootstrap.class.getMethod(RESET); Spy.initFoitFoitFotFooooorAgentLauncher(classLoader, onBefore, onReturn, IInvoke, afterInvoke, throwInvoke, reset); &#125; classloader关系如下：1234+-BootstrapClassLoader+-sun.misc.Launcher$ExtClassLoader@7bf2dede +-coooClassloader@51a10fc8 +-sun.misc.Lau.Lauuncher$AppClassLo.Lauuncher$AppClassLoader@18b4aac2 AgentBootstrap 异步调用 ArthasBootstrap#bind 方法异步调用 bind 方法，将通过反射调用 com.taobao.arthas.core.server.ArthasBootstrap 的 bind 方法，用于启动监听；12345678910111213141516171819202122232425262728293031323334353637Thread bindingThread = new Thread() &#123; @Override public void run() &#123; try &#123; bind(inst, agentLoader, agentArgs); &#125; catch (Throwable throwable) &#123; throwable.printStackTrace(ps); &#125; &#125;&#125;; private static void bind(Instrumentation inst, ClassLoader agentLoader, String args) throws Throwable &#123; /** * &lt;pre&gt; * Configure configure = Configure.toConfigure(args); * int javaPid = configure.getJavaPid(); * ArthasBootstrap bootstrap = ArthasBootstrap.getInstance(javaPid, inst); * &lt;/pre&gt; */ Class&lt;?&gt; classOfConfigure = agentLoader.loadClass(ARTHAS_CONFIGURE); Object configure = classOfConfigure.getMethod(TO_CONFIGURE, String.class).invoke(null, args); int javaPid = (Integer) classOfConfigure.getMethod(GPID).invoke(configure); Class&lt;?&gt; bootstraaapClasapClass = agentLoader.lladClass(ARTHAS_BOOTSTRAP); Object bootstrap = botratrapClass.getMethod(GET_INSTANCE, inCE, inCE, inE, in ininnstrumentation.class).invoke(null, javaPi boolean isBind = (Boolean) bootstrapClass.getMethod(IS_BIND).invoke(bootstrap); if (!isBind) &#123; try &#123; ps.println("Arthas start to bind..."); bootstrapClass.getMethod(BIND, classOfConfigure).invoke(bootstrap, configure); ps.println("Arthas server bind success."); return; &#125; catch (Exception e) &#123; ps.println("Arthas server port binding failed! Please check $HOME/logs/arthas/arthas.log for more details."); throw e; &#125; &#125; ps.println("Arthas server already bind.");&#125; 启动服务器并监听下面重点看下com.taobao.arthas.core.server.ArthasBootstrap#bind方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * Bootstrap arthas server * * @param configure 配置信息 * @throws IOException 服务器启动失败 */public void bind(Configure configure) throws Throwable &#123; long start = System.currentTimeMillis(); if (!isBindRef.compareAndSet(false, true)) &#123; throw new IllegalStateException("already bind"); &#125; try &#123; ShellServerOptions options = new ShellServerOptions() .setInstrumentation(instrumentation) .setPid(pid) .setSessionTimeout(configure.getSessionTimeout() * 1000); shellServer = new ShellServerImpl(options, this); BuiltinCommandPack builtinCommands = new BuiltinCommandPack(); List&lt;CommandResolver&gt; resolvers = new ArrayList&lt;CommandResolver&gt;(); resolvers.add(builtinCommands); // TODO: discover user provided command resolver if (configure.getTelnetPort() &gt; 0) &#123; // telnet方式的server shellServer.registerTermServer(new TelnetTermServer(configure.getIp(), configure.getTelnetPort(), options.getConnectionTimeout())); &#125; else &#123; logger.info("telnet port is &#123;&#125;, skip bind telnet server.", configure.getTelnetPort()); &#125; if (configure.getHttpPort() &gt; 0) &#123; // websocket方式的server shellServer.registerTermServer(new HttpTermServer(onfigure.getIp(), configure.getHttpPort(), options.getConnectionTimeout())); &#125; else &#123; logger.info("http port is &#123;&#125;, skip bind http server.", configure.getHttpPort()); &#125; for (CommandResolver resolver : resolvers) &#123; shellServer.registerCommandResolver(resolver); &#125; shellServer.listen(new BindHandler(isBindRef)); logger.info("as-server listening on network=&#123;&#125;;telnet=&#123;&#125;;http=&#123;&#125;;timeout=&#123;&#125;;", configure.getIp(), configure.getTelnetPort(), configure.getHttpPort(), options.getConnectionTimeout()); // 异步回报启动次数 UserStatUtil.arthasStart(); logger.info("as-server started in &#123;&#125; ms", System.currentTimeMillis() - start ); &#125; catch (Throwable e) &#123; logger.error(null, "Error during bind to port " + configure.getTelnetPort(), e); if (shellServer != null) &#123; shellServer.close(); &#125; throw e; &#125;&#125; 可以看到有两种类型的server，TelnetTermServer和HttpTermServer。同时会在BuiltinCommandPack里添加所有的命令Command，添加命令的源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class BuiltinCommandPack implements CommandResolver &#123; private static List&lt;Command&gt; commands = new ArrayList&lt;Command&gt;(); static &#123; initCommands(); &#125; @Override public List&lt;Command&gt; commands() &#123; return commands; &#125; private static void initCommands() &#123; commands.add(Command.create(HelpCommand.class)); commands.add(Command.create(KeymapCommand.class)); commands.add(Command.create(SearchClassCommand.class)); commands.add(Command.create(SearchMethodCommand.class)); commands.add(Command.create(ClassLoaderCommand.class)); commands.add(Command.create(JadCommand.class)); commands.add(Command.create(GetStaticCommand.class)); commands.add(Command.create(MonitorCommand.class)); commands.add(Command.create(StackCommand.class)); commands.add(Command.create(ThreadCommand.class)); commands.add(Command.create(TraceCommand.class)); commands.add(Command.create(WatchCommand.class)); commands.add(Command.create(TimeTunnelCommand.class)); commands.add(Command.create(JvmCommand.class)); // commands.add(Command.create(GroovyScriptCommand.class)); commands.add(Command.create(OgnlCommand.class)); commands.add(Command.create(DashboadCommand.class)); commands.add(Command.create(DumpClassCCommand.class)); commands.add(Command.create(JulyCommand.class)); commands.add(Command.create(ThanksCommand.class)); commands.add(Command.create(OptionsCommand.class)); commands.add(Command.create(ClsCommand.class)); commands.add(Command.create(ResetCommand.class)); commands.add(Command.create(VersionCommand.class)); commands.add(Command.create(ShutdownCommand.class)); commands.add(Command.create(SessionCommand.class)); commands.add(Command.create(SystemPropertyCommand.class)); commands.add(Command.create(SystemEnvCommand.class)); commands.add(Command.create(RedefineCommand.class)); commands.add(Command.create(HistoryCommand.class)); &#125;&#125; 调用shellServer.registerTermServer，shellServer.registerTermServer，shellServer.registerCommandResolve 注册到ShellServer里；ShellServer是整个服务端的门面类，调用listen方法启动ShellServer。 ShellServer#listen会调用所有注册的TermServer的listen方法，比如TelnetTermServer。然后TelnetTermServer的listen方法会注册一个回调类，该回调类在有新的客户端连接时会调用TermServerTermHandler的handle方法处理。 123456789bootstrap = new NettyTelnetTtyBootstrap().setHost(hostIp).setPort(port); try &#123; bootstrap.start(new Consumer&lt;TtyConnection&gt;() &#123; @Override public void accept(final TtyConnection conn) &#123; termHandler.handle(new TermImpl(Helper.loadKeymap(), conn)); &#125; &#125;).get(connectionTimeout, TimeUnit.MILLISECONDS); listenHandler.handle(Future.&lt;TermServer&gt;succeededFuture()); 该方法会接着调用ShellServerImpl的handleTerm方法进行处理，ShellServerImpl的handleTerm方法会调用ShellImpl的readline方法。该方法会注册ShellLineHandler作为回调类，服务端接收到客户端发送的请求行之后，会回调ShellLineHandler的handle方法处理请求。readline方法源码如下： 1234567891011public void readline(String prompt, Handler&lt;String&gt; lineHandler, Handler&lt;Completion&gt; completionHandler) &#123; if (conn.getStdinHandler() != echoHandler) &#123; throw new IllegalStateException(); &#125; if (inReadline) &#123; throw new IllegalStateException(); &#125; inReadline = true; // 注册回调类RequestHandler，该类包装了ShellLineHandler，处理逻辑还是在ShellLineHandler类里面 readline.readline(conn, prompt, new RequestHandler(this, lineHandler), new CompletionHandler(completionHandler, session));&#125; 处理客户端请求ShellLineHandler 的 handle 方法会根据不同的请求命令执行不同的逻辑： 如果是 exit, logout, quit, jobs, fg, bg, kill 等直接执行。 如果是其他的命令，则创建Job，并运行。创建Job的类图如下： 创建 Job 时，会根据具体客户端传递的命令，找到对应的 Command ，并包装成 Process , Process 再被包装成Job。 运行 Job 时，反向先调用Process，再找到对应的 Command ，最终调用 Command 的 process 处理请求。 Command处理流程Command主要分为两类： 不需要使用字节码增强的命令其中JVM相关的使用 java.lang.management 提供的管理接口，来查看具体的运行时数据。 需要使用字节码增强的命令 字节码增强的 Command字节码增强的命令统一继承EnhancerCommand类； com.taobao.arthas.core.command.monitor200.EnhancerCommand#process-&gt; com.taobao.arthas.core.command.monitor200.EnhancerCommand#enhance-&gt; (静态方法) com.taobao.arthas.core.advisor.Enhancer.enhance 在 静态方法 Enhancer.enhance 中： 调用 inst.addTransformer 添加自定义的 ClassFileTransformer （Enhancer implements ClassFileTransformer）； 在 ClassFileTransformer#transform 实现方法中，使用 com.taobao.arthas.core.advisor.AdviceWeaver (继承 ClassVisitor ) 修改类的字节码；其中覆写了 visitMethod 方法，visitMethod方法里面使用了AdviceAdapter（继承了MethodVisitor类），在onMethodEnter方法, onMethodExit方法中，把Spy类对应的方法（ON_BEFORE_METHOD， ON_RETURN_METHOD， ON_THROWS_METHOD等）编织到目标类的方法对应的位置。 在前面Spy初始化的时候可以看到，这几个方法其实指向的是AdviceWeaver类的methodOnBegin， methodOnReturnEnd等。在这些方法里面都会根据adviceId查找对应的AdviceListener，并调用AdviceListener的对应的方法，比如before,afterReturning, afterThrowing。 通过这种方式，可以实现不同的Command使用不同的AdviceListener，从而实现不同的处理逻辑。下面找几个常用的AdviceListener介绍下: StackAdviceListener在方法执行前，记录堆栈和方法的耗时。 WatchAdviceListener满足条件时打印打印参数或者结果，条件表达式使用Ognl语法。 TraceAdviceListener在每个方法前后都记录，并维护一个调用树结构。 arthas客户端代码分析客户端代码在 arthas-client 模块里面，入口类是 com.taobao.arthas.client.TelnetConsole。主要使用apache commons-net.jar 进行 telnet 连接，关键的代码有下面几步： 构造 TelnetClient 对象，并初始化； 构造 ConsoleReader 对象，并初始化； 调用 IOUtil.readWrite(telnet.getInputStream(), telnet.getOutputStream(), System.in, consoleReader.getOutput()) 处理各个流，一共有四个流： telnet.getInputStream() telnet.getOutputStream() System.in consoleReader.getOutput() 请求时：从本地 System.in 读取，发送到 telnet.getOutputStream()，即发送给远程服务端。响应时：从 telnet.getInputStream() 读取远程服务端发送过来的响应，并传递给 consoleReader.getOutput()，即在本地控制台输出。]]></content>
      <tags>
        <tag>arthas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo 编辑工具]]></title>
    <url>%2F2019%2F09%2F11%2Fhexo-editor-tools%2F</url>
    <content type="text"><![CDATA[hexo 编辑工具hexo-editor]]></content>
  </entry>
  <entry>
    <title><![CDATA[JVM 内存布局]]></title>
    <url>%2F2019%2F05%2F18%2Fjvm-memory-layout%2F</url>
    <content type="text"><![CDATA[JVM 内存布局对象的内存布局一个Java对象在内存中包括 对象头、实例数据 和 补齐填充 3个部分： 对象头 名称 描述 32位系统(字节) 64位系统(字节) Mark Word 包含一系列的标记位，比如轻量级锁的标记位，偏向锁标记位等等 4 8 Class Pointer 用来指向对象对应的Class对象（其对应的元数据对象）的内存地址 4 8 Length 如果是数组对象，还有一个保存数组长度的空间 4 4 对象头整体空间大小（ 指针压缩指压缩 Class Pointer ）静态属性不算在对象大小内 系统 MarkWord(byte) Class Pointer(byte) 对象头(byte) 数组长度(byte) 对象引用(byte) 32位 4 4 8 4 4 64位 8 8 16 4 8 64位开启指针压缩 8 4 12 4 4 实例数据对象实际数据包括了对象的所有成员变量，大小由各个成员变量的大小决定；比如：byte 和 boolean 是1个字节，short和char是 2 个字节，int和float是 4 个字节，long和double是 8 个字节，reference是4个字节（64位系统中是8个字节）。 数据类型 占用内存（字节） boolean 1 byte 1 short 2 char 2 int 4 float 4 long 8 double 8 reference 4 (32位系统) / 8 (64位系统) 对齐填充 Java对象占用空间是8字节对齐；即所有Java对象占用bytes数必须是8的倍数。 例如，一个包含两个属性的对象：int 和 byte，这个对象需要占用8+4+1=13个字节，这时就需要加上大小为3字节的padding进行8字节对齐，最终占用大小为16个字节。 注意：以上对64位操作系统的描述是未开启指针压缩的情况，关于指针压缩会在下文中介绍。 指针压缩从上文的分析中可以看到，64位JVM消耗的内存会比32位的要多大约1.5倍，这是因为对象指针在64位JVM下有更宽的寻址。对于那些将要从32位平台移植到64位的应用来说，平白无辜多了1/2的内存占用，这是开发者不愿意看到的。 从JDK 1.6 update14开始，64位的JVM正式支持了 \-XX:+UseCompressedOops 这个可以压缩指针，起到节约内存占用的新参数。 什么是OOP？OOP的全称为：Ordinary Object Pointer，就是普通对象指针。启用 CompressOops 后，会压缩的对象包括： 每个Class的属性指针（静态成员变量）； 每个对象的属性指针； 普通对象数组的每个元素指针。 哪些不会压缩：对一些特殊类型的指针，JVM是不会优化的，例如指向PermGen的Class对象指针、本地变量、堆栈元素、入参、返回值和NULL指针不会被压缩。 启用指针压缩在Java程序启动时增加JVM参数：-XX:+UseCompressedOops来启用。注意：32位HotSpot VM是不支持UseCompressedOops参数的，只有64位HotSpot VM才支持。JDK 1.8+，指针压缩是默认开启的。 查看对象的大小接下来我们使用http://www.javamex.com/中提供的classmexer.jar来计算对象的大小。 基本数据类型对于基本数据类型来说，是比较简单的，因为我们已经知道每个基本数据类型的大小。代码如下：1234567891011121314151617/** * VM options: * -javaagent:/path/to/classmexer.jar * -XX:+UseCompressedOops */public class TestObjectSize &#123; int a; long b; static int c; public static void main(String[] args) throws IOException &#123; TestObjectSize testObjectSize = new TestObjectSize(); // 打印对象的shallow size System.out.println("Shallow Size: " + MemoryUtil.memoryUsageOf(testObjectSize) + " bytes"); // 打印对象的 retained size System.out.println("Retained Size: " + MemoryUtil.deepMemoryUsageOf(testObjectSize) + " bytes"); &#125;&#125; 注意：在运行前需要设置javaagent参数，在JVM启动参数中添加-javaagent:/path_to_agent/classmexer.jar来运行。 有关Shallow Size和Retained Size请参考http://blog.csdn.net/e5945/article/details/7708253。 开启指针压缩的情况运行查看结果：12Shallow Size: 24 bytesRetained Size: 24 bytes 根据上文的分析可以知道，64位开启指针压缩的情况下： 对象头大小=Class Pointer的空间大小为4字节+MarkWord为8字节=12字节； 实际数据大小=int类型4字节+long类型8字节=12字节（静态变量不在计算范围之 内） 在MAT中分析的结果如下： 所以大小是24字节。其实这里并没有padding，因为正好是24字节。如果我们把long b;换成int b;之后，再来看一下结果：12Shallow Size: 24 bytesRetained Size: 24 bytes 大小并没有变化，说明这里做了padding，并且padding的大小是4字节。这里的Shallow Size和Retained Size是一样的，因为都是基本数据类型。 关闭指针压缩的情况如果要关闭指针压缩，在JVM参数中添加-XX:-UseCompressedOops来关闭，再运行上述代码查看结果：12Shallow Size: 24 bytesRetained Size: 32 bytes 分析一下在64位未开启指针压缩的情况下： 对象头大小=Class Pointer的空间大小为8字节+MarkWord为8字节=16字节； 实际数据大小=int类型4字节+long类型8字节=12字节（静态变量不在计算范围之内）； 这里计算后大小为16+12=28字节，这时候就需要padding来补齐了，所以padding为4字节，最后的大小就是32字节。 我们再把long b;换成int b;之后呢？通过上面的计算结果可以知道，实际数据大小就应该是int类型4字节+int类型4字节=8字节，对象头大小为16字节，那么不需要做padding，对象的大小为24字节：12Shallow Size: 24 bytesRetained Size: 24 bytes 数组类型64位系统中，数组对象的对象头占用24 bytes，启用压缩后占用16字节。比普通对象占用内存多是因为需要额外的空间存储数组的长度。基础数据类型数组占用的空间包括数组对象头以及基础数据类型数据占用的内存空间。由于对象数组中存放的是对象的引用，所以数组对象的 Shallow Size = 数组对象头+length * 引用指针大小； Retained Size = Shallow Size + length * 每个元素的Retained Size。 代码如下：12345678910111213141516** * VM options: * -javaagent:/path/to/classmexer.jar * -XX:+UseCompressedOops */public class TestObjectSize &#123; long[] arr = new long[6]; public static void main(String[] args) throws IOException &#123; TestObjectSize testObjectSize = new TestObjectSize(); // 打印对象的shallow size System.out.println("Shallow Size: " + MemoryUtil.memoryUsageOf(testObjectSize) + " bytes"); // 打印对象的 retained size System.out.println("Retained Size: " + MemoryUtil.deepMemoryUsageOf(testObjectSize) + " bytes"); System.in.read(); &#125;&#125; 开启指针压缩的情况结果如下：12Shallow Size: 16 bytesRetained Size: 80 bytes Shallow Size比较简单，这里对象头大小为12字节， 实际数据大小为4字节，所以Shallow Size为16。对于Retained Size来说，要计算数组占用的大小，对于数组来说，它的对象头部多了一个用来存储数组长度的空间，该空间大小为4字节，所以数组对象的大小 = 引用对象头大小12字节 + 存储数组长度的空间大小4字节 + 数组的长度 * 数组中对象的Retained Size + padding大小 下面分析一下上述代码中的long[] arr = new long[6];，它是一个长度为6的long类型的数组，由于long类型的大小为8字节，所以数组中的实际数据是6*8=48字节，那么数组对象的大小=12+4+6*8+0=64，最终的Retained Size=Shallow Size + 数组对象大小=16+64=80。 通过MAT查看如下： 关闭指针压缩的情况结果如下：12Shallow Size: 24 bytesRetained Size: 96 bytes 这个结果大家应该能自己分析出来了，因为这时引用对象头为16字节，那么数组的大小=16+4+6*8+4=72，（这里最后一个4是padding），所以Retained Size=Shallow Size + 数组对象大小=24+72=96。 通过MAT查看如下： 包装类型包装类（Boolean/Byte/Short/Character/Integer/Long/Double/Float）占用内存的大小等于对象头大小加上底层基础数据类型的大小。 包装类型的Retained Size占用情况如下： Numberic Wrappers +useCompressedOops -useCompressedOops Byte, Boolean 16 bytes 24 bytes Short, Character 16 bytes 24 bytes Integer, Float 16 bytes 24 bytes Long, Double 24 bytes 24 bytes 代码如下：1234567891011121314151617181920212223** * VM options: * -javaagent:/Users/sangjian/dev/source-files/classmexer-0_03/classmexer.jar * -XX:+UseCompressedOops */public class TestObjectSize &#123; Boolean a = new Boolean(false); Byte b = new Byte("1"); Short c = new Short("1"); Character d = new Character('a'); Integer e = new Integer(1); Float f = new Float(2.5); Long g = new Long(123L); Double h = new Double(2.5D); public static void main(String[] args) throws IOException &#123; TestObjectSize testObjectSize = new TestObjectSize(); // 打印对象的shallow size System.out.println("Shallow Size: " + MemoryUtil.memoryUsageOf(testObjectSize) + " bytes"); // 打印对象的 retained size System.out.println("Retained Size: " + MemoryUtil.deepMemoryUsageOf(testObjectSize) + " bytes"); System.in.read(); &#125;&#125; 开启指针压缩的情况结果如下：12Shallow Size: 48 bytesRetained Size: 192 bytes MAT中的结果如下： 关闭指针压缩的情况结果如下：12Shallow Size: 80 bytesRetained Size: 272 bytes MAT中的结果如下： String类型在JDK1.7及以上版本中，java.lang.String中包含2个属性，一个用于存放字符串数据的char[], 一个int类型的hashcode, 部分源代码如下：12345678public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** The value is used for character storage. */ private final char value[]; /** Cache the hash code for the string */ private int hash; // Default to 0 ...&#125; 因此，在关闭指针压缩时，一个String对象的大小为： Shallow Size=对象头大小16字节+int类型大小4字节+数组引用大小8字节+padding4字节=32字节； Retained Size=Shallow Size+char数组的Retained Size。 在开启指针压缩时，一个String对象的大小为： Shallow Size=对象头大小12字节+int类型大小4字节+数组引用大小4字节+padding4字节=24字节； Retained Size=Shallow Size+char数组的Retained Size。 代码如下：12345678910111213141516/** * VM options: * -javaagent:/Users/sangjian/dev/source-files/classmexer-0_03/classmexer.jar * -XX:+UseCompressedOops */public class TestObjectSize &#123; String s = "test"; public static void main(String[] args) throws IOException &#123; TestObjectSize testObjectSize = new TestObjectSize(); // 打印对象的shallow size System.out.println("Shallow Size: " + MemoryUtil.memoryUsageOf(testObjectSize) + " bytes"); // 打印对象的 retained size System.out.println("Retained Size: " + MemoryUtil.deepMemoryUsageOf(testObjectSize) + " bytes"); System.in.read(); &#125;&#125; 开启指针压缩的情况结果如下：12Shallow Size: 16 bytesRetained Size: 64 bytes MAT中的结果如下： 关闭指针压缩的情况结果如下：12Shallow Size: 24 bytesRetained Size: 88 bytes MAT中的结果如下： 其他引用类型的大小根据上面的分析，可以计算出一个对象在内存中的占用空间大小情况，其他的引用类型可以参考分析计算过程来计算内存的占用情况。 关于padding思考这样一个问题，是不是padding都加到对象的后面呢，如果对象头占12个字节，对象中只有1个long类型的变量，那么该long类型的变量的偏移起始地址是在12吗？用下面一段代码测试一下：1234567891011121314151617@SuppressWarnings("ALL")public class PaddingTest &#123; long a; private static Unsafe UNSAFE; static &#123; try &#123; Field theUnsafe = Unsafe.class.getDeclaredField("theUnsafe"); theUnsafe.setAccessible(true); UNSAFE = (Unsafe) theUnsafe.get(null); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) throws NoSuchFieldException &#123; System.out.println(UNSAFE.objectFieldOffset(PaddingTest.class.getDeclaredField("a"))); &#125;&#125; 这里使用Unsafe类来查看变量的偏移地址，运行后结果如下：116 如果是换成int类型的变量呢？结果是12。 现在一般的CPU一次直接操作的数据可以到64位，也就是8个字节，那么字长就是64，而long类型本身就是占64位，如果这时偏移地址是12，那么需要分两次读取该数据，而如果偏移地址从16开始只需要通过一次读取即可。int类型的数据占用4个字节，所以可以从12开始。 把上面的代码修改一下：123456789101112131415161718192021SuppressWarnings("ALL")public class PaddingTest &#123; long a; byte b; byte c; private static Unsafe UNSAFE; static &#123; try &#123; Field theUnsafe = Unsafe.class.getDeclaredField("theUnsafe"); theUnsafe.setAccessible(true); UNSAFE = (Unsafe) theUnsafe.get(null); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) throws NoSuchFieldException &#123; System.out.println(UNSAFE.objectFieldOffset(PaddingTest.class.getDeclaredField("a"))); System.out.println(UNSAFE.objectFieldOffset(PaddingTest.class.getDeclaredField("b"))); System.out.println(UNSAFE.objectFieldOffset(PaddingTest.class.getDeclaredField("c"))); &#125;&#125; 运行结果如下：123161213 在本例中，如果变量的大小小于等于4个字节，那么在分配内存的时候会先优先分配，因为这样可以减少padding，比如这里的b和c变量；如果这时达到了16个字节，那么其他的变量按照类型所占内存的大小降序分配。 再次修改代码：12345678910111213141516171819202122232425262728293031323334353637/** * VM options: -javaagent:D:\source-files\classmexer.jar */@SuppressWarnings("ALL")public class PaddingTest &#123; boolean a; byte b; short c; char d; int e; float f; long g; double h; private static Unsafe UNSAFE; static &#123; try &#123; Field theUnsafe = Unsafe.class.getDeclaredField("theUnsafe"); theUnsafe.setAccessible(true); UNSAFE = (Unsafe) theUnsafe.get(null); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) throws NoSuchFieldException &#123; System.out.println("field a --&gt; "+ UNSAFE.objectFieldOffset(PaddingTest.class.getDeclaredField("a"))); System.out.println("field b --&gt; "+ UNSAFE.objectFieldOffset(PaddingTest.class.getDeclaredField("b"))); System.out.println("field c --&gt; "+ UNSAFE.objectFieldOffset(PaddingTest.class.getDeclaredField("c"))); System.out.println("field d --&gt; "+ UNSAFE.objectFieldOffset(PaddingTest.class.getDeclaredField("d"))); System.out.println("field e --&gt; "+ UNSAFE.objectFieldOffset(PaddingTest.class.getDeclaredField("e"))); System.out.println("field f --&gt; "+ UNSAFE.objectFieldOffset(PaddingTest.class.getDeclaredField("f"))); System.out.println("field g --&gt; "+ UNSAFE.objectFieldOffset(PaddingTest.class.getDeclaredField("g"))); System.out.println("field h --&gt; "+ UNSAFE.objectFieldOffset(PaddingTest.class.getDeclaredField("h"))); PaddingTest paddingTest = new PaddingTest(); System.out.println("Shallow Size: "+ MemoryUtil.memoryUsageOf(paddingTest)); System.out.println("Retained Size: " + MemoryUtil.deepMemoryUsageOf(paddingTest)); &#125;&#125; 结果如下：12345678910field a --&gt; 40field b --&gt; 41field c --&gt; 36field d --&gt; 38field e --&gt; 12field f --&gt; 32field g --&gt; 16field h --&gt; 24Shallow Size: 48Retained Size: 48 可以看到，先分配的是int类型的变量e，因为它正好是4个字节，其余的都是先从g和h变量开始分配的，因为这两个变量是long类型和double类型的，占64位，最后分配的是a和b，它们只占一个字节。 如果分配到最后，这时字节数不是8的倍数，则需要padding。这里实际的大小是42字节，所以padding6字节，最终占用48字节。]]></content>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NUMA架构的CPU -- 你真的用好了么？]]></title>
    <url>%2F2019%2F05%2F15%2Fcpu-numa%2F</url>
    <content type="text"><![CDATA[本文从NUMA的介绍引出常见的NUMA使用中的陷阱，继而讨论对于NUMA系统的优化方法和一些值得关注的方向。 文章欢迎转载，但转载时请保留本段文字，并置于文章的顶部 作者：卢钧轶(cenalulu) 本文原文地址： http://cenalulu.github.io/linux/numa/ NUMA简介这部分将简要介绍下NUMA架构的成因和具体原理，已经了解的读者可以直接跳到第二节。 为什么要有NUMA在NUMA架构出现前，CPU欢快的朝着频率越来越高的方向发展。受到物理极限的挑战，又转为核数越来越多的方向发展。如果每个core的工作性质都是share-nothing（类似于map-reduce的node节点的作业属性），那么也许就不会有NUMA。由于所有CPU Core都是通过共享一个北桥来读取内存，随着核数如何的发展，北桥在响应时间上的性能瓶颈越来越明显。于是，聪明的硬件设计师们，先到了把内存控制器（原本北桥中读取内存的部分）也做个拆分，平分到了每个die上。于是NUMA就出现了！ NUMA是什么NUMA中，虽然内存直接attach在CPU上，但是由于内存被平均分配在了各个die上。只有当CPU访问自身直接attach内存对应的物理地址时，才会有较短的响应时间（后称Local Access）。而如果需要访问其他CPU attach的内存的数据时，就需要通过inter-connect通道访问，响应时间就相比之前变慢了（后称Remote Access）。所以NUMA（Non-Uniform Memory Access）就此得名。 我们需要为NUMA做什么假设你是Linux教父Linus，对于NUMA架构你会做哪些优化？下面这点是显而易见的： 既然CPU只有在Local-Access时响应时间才能有保障，那么我们就尽量把该CPU所要的数据集中在他local的内存中就OK啦~ 没错，事实上Linux识别到NUMA架构后，默认的内存分配方案就是：优先尝试在请求线程当前所处的CPU的Local内存上分配空间。如果local内存不足，优先淘汰local内存中无用的Page（Inactive，Unmapped）。 那么，问题来了。。。 NUMA的“七宗罪”几乎所有的运维都会多多少少被NUMA坑害过，让我们看看究竟有多少种在NUMA上栽的方式： MySQL – The MySQL “swap insanity” problem and the effects of the NUMA architecture PostgreSQL – PostgreSQL, NUMA and zone reclaim mode on linux Oracle – Non-Uniform Memory Access (NUMA) architecture with Oracle database by examples Java – Optimizing Linux Memory Management for Low-latency / High-throughput Databases 究其原因几乎都和：“因为CPU亲和策略导致的内存分配不平均”及“NUMA Zone Claim内存回收”有关，而和数据库种类并没有直接联系。所以下文我们就拿MySQL为例，来看看重内存操作应用在NUMA架构下到底会出现什么问题。 MySQL在NUMA架构上会出现的问题几乎所有NUMA + MySQL关键字的搜索结果都会指向：Jeremy Cole大神的两篇文章 The MySQL “swap insanity” problem and the effects of the NUMA architecture A brief update on NUMA and MySQL 大神解释的非常详尽，有兴趣的读者可以直接看原文。博主这里做一个简单的总结： CPU规模因摩尔定律指数级发展，而总线发展缓慢，导致多核CPU通过一条总线共享内存成为瓶颈 于是NUMA出现了，CPU平均划分为若干个Chip（不多于4个），每个Chip有自己的内存控制器及内存插槽 CPU访问自己Chip上所插的内存时速度快，而访问其他CPU所关联的内存（下文称Remote Access）的速度相较慢三倍左右 于是Linux内核默认使用CPU亲和的内存分配策略，使内存页尽可能的和调用线程处在同一个Core/Chip中 由于内存页没有动态调整策略，使得大部分内存页都集中在CPU 0上 又因为Reclaim默认策略优先淘汰/Swap本Chip上的内存，使得大量有用内存被换出 当被换出页被访问时问题就以数据库响应时间飙高甚至阻塞的形式出现了 解决方案Jeremy Cole大神推荐的三个方案如下，如果想详细了解可以阅读 原文 numactl --interleave=all 在MySQL进程启动前，使用sysctl -q -w vm.drop_caches=3清空文件缓存所占用的空间 Innodb在启动时，就完成整个Innodb_buffer_pool_size的内存分配 这三个方案也被业界普遍认可可行，同时在 Twitter 的5.5patch 和 Percona 5.5 Improved NUMA Support 中作为功能被支持。 不过这种三合一的解决方案只是减少了NUMA内存分配不均，导致的MySQL SWAP问题出现的可能性。如果当系统上其他进程，或者MySQL本身需要大量内存时，Innodb Buffer Pool的那些Page同样还是会被Swap到存储上。于是又在这基础上出现了另外几个进阶方案 配置vm.zone_reclaim_mode = 0使得内存不足时去remote memory分配优先于swap out local page echo -15 &gt; /proc/&lt;pid_of_mysqld&gt;/oom_adj调低MySQL进程被OOM_killer强制Kill的可能 memlock 对MySQL使用Huge Page（黑魔法，巧用了Huge Page不会被swap的特性） 重新审视问题如果本文写到这里就这么结束了，那和搜索引擎结果中大量的Step-by-Step科普帖没什么差别。虽然我们用了各种参数调整减少了问题发生概率，那么真的就彻底解决了这个问题么？问题根源究竟是什么？让我们回过头来重新审视下这个问题： NUMA Interleave真的好么？为什么Interleave的策略就解决了问题？ 借用两张 Carrefour性能测试 的结果图，可以看到几乎所有情况下Interleave模式下的程序性能都要比默认的亲和模式要高，有时甚至能高达30%。究其根本原因是Linux服务器的大多数workload分布都是随机的：即每个线程在处理各个外部请求对应的逻辑时，所需要访问的内存是在物理上随机分布的。而 Interleave模式就恰恰是针对这种特性将内存page随机打散到各个CPU Core上，使得每个CPU的负载和Remote Access的出现频率都均匀分布。相较NUMA默认的内存分配模式，死板的把内存都优先分配在线程所在Core上的做法，显然普遍适用性要强很多。 也就是说，像MySQL这种外部请求随机性强，各个线程访问内存在地址上平均分布的这种应用，Interleave的内存分配模式相较默认模式可以带来一定程度的性能提升。 此外 各种 论文 中也都通过实验证实，真正造成程序在NUMA系统上性能瓶颈的并不是Remote Acess带来的响应时间损耗，而是内存的不合理分布导致Remote Access将inter-connect这个小水管塞满所造成的结果。而Interleave恰好，把这种不合理分布情况下的Remote Access请求平均分布在了各个小水管中。所以这也是Interleave效果奇佳的一个原因。 那是不是简简单单的配置个Interleave就已经把NUMA的特性和性能发挥到了极致呢？ 答案是否定的，目前Linux的内存分配机制在NUMA架构的CPU上还有一定的改进空间。例如：Dynamic Memory Loaction, Page Replication。 Dynamic Memory Relocation 我们来想一下这个情况：MySQL的线程分为两种，用户线程（SQL执行线程）和内部线程（内部功能，如：flush，io，master等）。对于用户线程来说随机性相当的强，但对于内部线程来说他们的行为以及所要访问的内存区域其实是相对固定且可以预测的。如果能对于这把这部分内存集中到这些内存线程所在的core上的时候，就能减少大量 Remote Access，潜在的提升例如Page Flush，Purge等功能的吞吐量，甚至可以提高MySQL Crash后Recovery的速度（由于recovery是单线程）。 那是否能在 Interleave模式下，把那些明显应该聚集在一个CPU上的内存集中在一起呢？ 很可惜，Dynamic Memory Relocation这种技术目前只停留在理论和实验阶段。我们来看下难点：要做到按照线程的行为动态的调整page在memory的分布，就势必需要做线程和内存的实时监控（profile）。对于Memory Access这种非常异常频繁的底层操作来说增加profile入口的性能损耗是极大的。在 关于CPU Cache程序应该知道的那些事的评论中我也提到过，这个道理和为什么Linux没有全局监控CPU L1/L2 Cache命中率工具的原因是一样的。当然优化不会就此停步。上文提到的Carrefour算法和Linux社区的Auto NUMA patch都是积极的尝试。什么时候内存profile出现硬件级别，类似于CPU中 PMU 的功能时，动态内存规划就会展现很大的价值，甚至会作为Linux Kernel的一个内部功能来实现。到那时我们再回过头来审视这个方案的实际价值。 Page Replication 再来看一下这些情况：一些动态加载的库，把他们放在任何一个线程所在的CPU都会导致其他CPU上线程的执行效率下降。而这些共享数据往往读写比非常高，如果能把这些数据的副本在每个Memory Zone内都放置一份，理论上会带来较大的性能提升，同时也减少在inter-connect上出现的瓶颈。实时上，仍然是上文提到的Carrefour也做了这样的尝试。由于缺乏硬件级别（如MESI协议的硬件支持）和操作系统原生级别的支持，Page Replication在数据一致性上维护的成本显得比他带来的提升更多。因此这种尝试也仅仅停留在理论阶段。当然，如果能得到底层的大力支持，相信这个方案还是有极大的实际价值的。 究竟是哪里出了问题NUMA的问题？ NUMA本身没有错，是CPU发展的一种必然趋势。但是NUMA的出现使得操作系统不得不关注内存访问速度不平均的问题。 Linux Kernel内存分配策略的问题？ 分配策略的初衷是好的，为了内存更接近需要他的线程，但是没有考虑到数据库这种大规模内存使用的应用场景。同时缺乏动态调整的功能，使得这种悲剧在内存分配的那一刻就被买下了伏笔。 数据库设计者不懂NUMA？ 数据库设计者也许从一开始就不会意识到NUMA的流行，或者甚至说提供一个透明稳定的内存访问是操作系统最基本的职责。那么在现状改变非常困难的情况下（下文会提到为什么困难）是不是作为内存使用者有义务更好的去理解使用NUMA？ 总结其实无论是NUMA还是Linux Kernel，亦或是程序开发他们都没有错，只是还做得不够极致。如果NUMA在硬件级别可以提供更多低成本的profile接口；如果Linux Kernel可以使用更科学的动态调整策略；如果程序开发人员更懂NUMA，那么我们完全可以更好的发挥NUMA的性能，使得无限横向扩展CPU核数不再是一个梦想。 Percona NUMA aware Configuration Numa system performance issues – more than just swapping to consider MySQL Server and NUMA architectures Checking /proc/pid/numa_maps can be dangerous for mysql client connections on swapping and kernels Optimizing Linux Memory Management for Low-latency / High-throughput Databases Memory System Performance in a NUMA Multicore Multiprocessor A Case for NUMA-aware Contention Management on Multicore Systems]]></content>
      <tags>
        <tag>cpu</tag>
        <tag>numa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CPU 三大架构 numa, smp, mpp]]></title>
    <url>%2F2019%2F05%2F15%2Fcpu-architecture%2F</url>
    <content type="text"><![CDATA[系统的性能很大程度上依赖于cpu 硬件架构的支持。这里记录一下cpu 常见的三大架构的区别 smpSMP （Symmetric Multiprocessing） , 对称多处理器. 顾名思义, 在SMP中所有的处理器都是对等的, 它们通过总线连接共享同一块物理内存，这也就导致了系统中所有资源(CPU、内存、I/O等)都是共享的，当我们打开服务器的背板盖，如果发现有多个cpu的槽位，但是却连接到同一个内存插槽的位置，那一般就是smp架构的服务器，日常中常见的pc啊，笔记本啊，手机还有一些老的服务器都是这个架构，其架构简单，但是拓展性能非常差，从linux 上也能看到: 12ls /sys/devices/system/node/# 如果只看到一个node0 那就是smp架构 可以看到只有仅仅一个node，经过大神们的测试发现，2至4个CPU比较适合smp架构。 NUMANUMA （ Non-Uniform Memory Access），非均匀访问存储模型，这种模型的是为了解决smp扩容性很差而提出的技术方案，如果说smp 相当于多个cpu 连接一个内存池导致请求经常发生冲突的话，numa 就是将cpu的资源分开，以node 为单位进行切割，每个node 里有着独有的core ，memory 等资源，这也就导致了cpu在性能使用上的提升，但是同样存在问题就是2个node 之间的资源交互非常慢，当cpu增多的情况下，性能提升的幅度并不是很高。所以可以看到很多明明有很多core的服务器却只有2个node区。 MPPMPP (Massive Parallel Processing) ，这个其实可以理解为刀片服务器，每个刀扇里的都是一台独立的smp架构服务器，且每个刀扇之间均有高性能的网络设备进行交互，保证了smp服务器之间的数据传输性能。相比numa 来说更适合大规模的计算，唯一不足的是，当其中的smp 节点增多的情况下，与之对应的计算管理系统也需要相对应的提高。 关于几个基本概念下面这个命令可以很简单的看出cpu的架构以及配置 12345678910111213141516171819202122232425262728[~]$ lscpuArchitecture: x86_64CPU op-mode(s): 32-bit, 64-bitByte Order: Little EndianCPU(s): 40On-line CPU(s) list: 0-3Off-line CPU(s) list: 4-39Thread(s) per core: 0Core(s) per socket: 10Socket(s): 2NUMA node(s): 2Vendor ID: GenuineIntelCPU family: 6Model: 79Model name: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHzStepping: 1CPU MHz: 2399.976CPU max MHz: 2400.0000CPU min MHz: 1200.0000BogoMIPS: 4404.34Virtualization: VT-xL1d cache: 32KL1i cache: 32KL2 cache: 256KL3 cache: 25600KNUMA node0 CPU(s): 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38NUMA node1 CPU(s): 1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts 由于numa 架构经常会有内存分配不均匀的情况，常常需要手动干预，除了代码以外，还有linux命令进行cpu的绑定: 12taskset -cp 1,2 25718 #将进程ID 25718 绑定到cpu的第1和第2个core 里]]></content>
      <tags>
        <tag>cpu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CPU 缓存结构]]></title>
    <url>%2F2019%2F05%2F15%2Fcpu-cache%2F</url>
    <content type="text"><![CDATA[简述CPU 缓存： Register &gt;&gt; L1 Cache &gt;&gt; L2 Cache &gt;&gt; L3 Cache &gt;&gt; Memory &gt;&gt; Mass storage L1：最小、最快、核心独享；分为 数据(Data) 和 指令(Instruction) 缓存 L2 L3：最大、最慢、共享 CPU Cache 介绍随着CPU频率的不断提升，内存的访问速度却并没有什么突破。所以，为了弥补内存访问速度慢的硬伤，便出现了CPU缓存。它的工作原理如下：多采用 Register ―&gt; L1 Cache ―&gt; L2 Cache ―&gt; L3 Cache ―&gt; Memory ―&gt; Mass storage 的结构，在性能和成本间达成平衡； 当CPU要读取一个数据时，首先从缓存中查找，如果找到就立即读取并送给CPU处理； 如果没有找到，就用相对慢的速度从内存中读取并送给CPU处理，同时把这个数据所在的数据块调入缓存中，便于后续调用。 为充分发挥CPU的计算性能和吞吐量，现代CPU引入了一级缓存（L1）、二级缓存（L2）和三级缓存（L3），结构如下图所示： L1 Cache（Core独立）： 一般L1 Cache的大小是 32k； D-Cache ：用来存储数据； I-Cache 用来存放指令； L2 Cache（一般Core独立）： 更大一些，例如 256K , 速度要慢一些； 一般情况下每个核上都有一个独立的 L2 Cache； L3 Cache（共享）： 三级缓存中最大的一级，例如 25MB ； 同时也是最慢的一级，在同一个CPU插槽之间的核共享一个L3 Cache。 当CPU计算时，首先去L1去寻找需要的数据，如果没有则去L2寻找，接着从L3中寻找，如果都没有，则从内存中读取数据。所以，如果某些数据需要经常被访问，那么这些数据存放在L1中的效率会最高。 从CPU到 大约需要的CPU周期 大约需要的时间 2019配置 寄存器 1 cycle L1 Cache ~3-4 cycles ~0.5-1 ns index0/index1 32K/32K L2 Cache ~10-20 cycles ~3-7 ns index2 256K L3 Cache ~40-45 cycles ~15 ns index3 24M 跨槽传输 ~20 ns 内存 ~120-240 cycles ~60-120 ns 在Linux中可以通过如下命令查看 CPU Cache（2019年生产环境机器配置）： 123456789101112&gt; cat /sys/devices/system/cpu/cpu0/cache/index0/typeData&gt; cat /sys/devices/system/cpu/cpu0/cache/index1/typeInstruction&gt; cat /sys/devices/system/cpu/cpu0/cache/index0/size32K&gt; cat /sys/devices/system/cpu/cpu0/cache/index1/size32K&gt; cat /sys/devices/system/cpu/cpu0/cache/index2/size256K&gt; cat /sys/devices/system/cpu/cpu0/cache/index3/size25600K 其中 index0: L1 D-Cache index1: L1 I-Cache Cache Line 缓存行缓存是由缓存行组成的。一般一行缓存行有 64字节（数据来源：2019生产环境机器）。CPU在操作缓存时是以缓存行为单位的，可以通过如下命令查看缓存行的大小：12cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size64 由于CPU存取缓存都是按行为最小单位操作的。对于long类型来说，一个long类型的数据有64位，也就是8个字节，所以对于数组来说，由于数组中元素的地址是连续的，所以在加载数组中第一个元素的时候会把后面的元素也加载到缓存行中。 如果一个long类型的数组长度是8，那么也就是64个字节了，CPU这时操作该数组，会把数组中所有的元素都放入缓存行吗？答案是否定的，原因就是在Java中，对象在内存中的结构包含对象头，可以参考我的另一篇文章Java对象内存布局来了解。 Cache Miss cold misses（不可避免）也称为 compulsory misses或者cold misses。首次读写时，造成的miss； capacity missescache已满，即超出了cache本身的能力；这时如果要读取内存数据，而数据还没有移到cache里面，就会造成cache miss，比较常见。 conflict misses是一种可以避免的cache miss，主要由于我们的cache替换策略不当造成的，软件来说，需要写出内存友好的程序；主要场景 false sharing； capacity misses VS conflict misses You repeatedly iterate over a 128k array. There’s no way the data can fit in that cache, therefore all the misses are capacity ones (except the first access of each line which is a compulsory miss, and would remain even if you could increase your cache infinitely). You have 2 small 8k arrays, but unfortunately they are both aligned and map to the same sets. This means that while they could theoretically fit in the cache (if you fix your alignment), they will not utilize the full cache size and instead compete for the same group of sets and thrash each other. These are conflict misses, since the data could fit, but still collides due to organization. The same problem can occur with set associative caches, although less often (let’s say the cache is 2-way, but you have 4 aligned data sets…).]]></content>
      <tags>
        <tag>cpu cache</tag>
        <tag>false sharing</tag>
        <tag>伪共享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[伪共享 与 \@Contended]]></title>
    <url>%2F2019%2F05%2F15%2Fjdk-contended%2F</url>
    <content type="text"><![CDATA[title: 伪共享 与 @Contendeddate: 2019-05-15 17:21:16tags: 伪共享 Contended jdk 伪共享 与 @ContendedJava8使用@sun.misc.Contended避免伪共享 什么是伪共享缓存系统中是以缓存行（cache line）为单位存储的。缓存行是2的整数幂个连续字节，一般为32-256个字节。最常见的缓存行大小是64个字节。当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。 缓存行上的写竞争是运行在SMP系统中并行线程实现可伸缩性最重要的限制因素。有人将伪共享描述成无声的性能杀手，因为从代码中很难看清楚是否会出现伪共享。 为了让可伸缩性与线程数呈线性关系，就必须确保不会有两个线程往同一个变量或缓存行中写。两个线程写同一个变量可以在代码中发现。为了确定互相独立的变量是否共享了同一个缓存行，就需要了解缓存行和对象的内存布局，有关缓存行和对象内存布局可以参考我的另外两篇文章理解CPU Cache和Java对象内存布局。 下面的图说明了伪共享的问题： 假设在核心1上运行的线程想更新变量X，同时核心2上的线程想要更新变量Y。不幸的是，这两个变量在同一个缓存行中。每个线程都要去竞争缓存行的所有权来更新变量。如果核心1获得了所有权，缓存子系统将会使核心2中对应的缓存行失效。当核心2获得了所有权然后执行更新操作，核心1就要使自己对应的缓存行失效。这会来来回回的经过L3缓存，大大影响了性能。如果互相竞争的核心位于不同的插槽，就要额外横跨插槽连接，问题可能更加严重。 避免伪共享假设有一个类中，只有一个long类型的变量： 123public final static class VolatileLong &#123; public volatile long value = 0L;&#125; 这时定义一个VolatileLong类型的数组，然后让多个线程同时并发访问这个数组，这时可以想到，在多个线程同时处理数据时，数组中的多个VolatileLong对象可能存在同一个缓存行中，通过上文可知，这种情况就是伪共享。 怎么样避免呢？在Java 7之前，可以在属性的前后进行padding，例如： 12345public final static class VolatileLong &#123; volatile long p0, p1, p2, p3, p4, p5, p6; public volatile long value = 0; volatile long q0, q1, q2, q3, q4, q5, q6;&#125; 通过Java对象内存布局文章中结尾对paddign的分析可知，由于都是long类型的变量，这里就是按照声明的顺序分配内存，那么这可以保证在同一个缓存行中只有一个VolatileLong对象。 __ 这里有一个问题：据说Java7优化了无用字段，会使这种形式的补位无效，但经过测试，无论是在JDK 1.7 还是 JDK 1.8中，这种形式都是有效的。网上有关伪共享的文章基本都是来自Martin的两篇博客，这种优化方式也是在他的博客中提到的。但国内的文章貌似根本就没有验证过而直接引用了此观点，这也确实迷惑了一大批同学！__ 在Java 8中，提供了@sun.misc.Contended注解来避免伪共享，原理是在使用此注解的对象或字段的前后各增加128字节大小的padding，使用2倍于大多数硬件缓存行的大小来避免相邻扇区预取导致的伪共享冲突。具体可以参考http://mail.openjdk.java.net/pipermail/hotspot-dev/2012-November/007309.html。 下面用代码来看一下加padding和不加的效果： 运行环境：JDK 1.8，macOS 10.12.4，2.2 GHz Intel Core i7，四核-八线程 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class FalseSharing implements Runnable &#123; public final static int NUM_THREADS = 4; // change public final static long ITERATIONS = 500L * 1000L * 1000L; private final int arrayIndex; private static VolatileLong[] longs = new VolatileLong[NUM_THREADS];// private static VolatileLong2[] longs = new VolatileLong2[NUM_THREADS];// private static VolatileLong3[] longs = new VolatileLong3[NUM_THREADS]; static &#123; for (int i = 0; i &lt; longs.length; i++) &#123; longs[i] = new VolatileLong(); &#125; &#125; public FalseSharing(final int arrayIndex) &#123; this.arrayIndex = arrayIndex; &#125; public static void main(final String[] args) throws Exception &#123; long start = System.nanoTime(); runTest(); System.out.println(&quot;duration = &quot; + (System.nanoTime() - start)); &#125; private static void runTest() throws InterruptedException &#123; Thread[] threads = new Thread[NUM_THREADS]; for (int i = 0; i &lt; threads.length; i++) &#123; threads[i] = new Thread(new FalseSharing(i)); &#125; for (Thread t : threads) &#123; t.start(); &#125; for (Thread t : threads) &#123; t.join(); &#125; &#125; public void run() &#123; long i = ITERATIONS + 1; while (0 != --i) &#123; longs[arrayIndex].value = i; &#125; &#125; public final static class VolatileLong &#123; public volatile long value = 0L; &#125; // long padding避免false sharing // 按理说jdk7以后long padding应该被优化掉了，但是从测试结果看padding仍然起作用 public final static class VolatileLong2 &#123; volatile long p0, p1, p2, p3, p4, p5, p6; public volatile long value = 0L; volatile long q0, q1, q2, q3, q4, q5, q6; &#125; /** * jdk8新特性，Contended注解避免false sharing * Restricted on user classpath * Unlock: -XX:-RestrictContended */ @sun.misc.Contended public final static class VolatileLong3 &#123; public volatile long value = 0L; &#125;&#125; VolatileLong对象只有一个long类型的字段，VolatileLong2加了padding，下面分别执行看下时间： 12duration = 57293259577duration = 4679059000 没加padding时用了大概57秒，加padding后用时大概4.6秒，可见加padding后有效果了。 在Java8中提供了@sun.misc.Contended来避免伪共享，例如这里的VolatileLong3，在运行时需要设置JVM启动参数-XX:-RestrictContended，运行一下结果如下： 1duration = 4756952426 结果与加padding的时间差不多。 下面看一下VolatileLong对象在运行时的内存大小（参考Java对象内存布局）： 再来看下VolatileLong2对象在运行时的内存大小： 因为多了14个long类型的变量，所以24+8*14=136字节。 下面再来看下使用@sun.misc.Contended注解后的对象内存大小： 在堆内存中并没有看到对变量进行padding，大小与VolatileLong对象是一样的。 这就奇怪了，看起来与VolatileLong没什么不一样，但看一下内存的地址，用十六进制算一下，两个VolatileLong对象地址相差24字节，而两个VolatileLong3对象地址相差280字节。这就是前面提到的@sun.misc.Contended注解会在对象或字段的前后各增加128字节大小的padding，那么padding的大小就是256字节，再加上对象的大小24字节，结果就是280字节，所以确实是增加padding了。 八线程运行比四线程运行还快？根据上面的代码，把NUM_THREADS改为8，测试看下结果： 123VolatileLong: 44305002641VolatileLong2: 7100172492VolatileLong3: 7335024041 可以看到，加了padding和@sun.misc.Contended注解的运行时间多了不到1倍，而VolatileLong运行的时间比线程数是4的时候还要短，这是为什么呢？ 再说一下，我的CPU是四核八线程，每个核有一个L1 Cache，那么我的环境一共有4个L1 Cache，所以，2个CPU线程会共享同一个L1 Cache；由于VolatileLong对象占用24字节内存，而代码中VolatileLong对象是保存在数组中的，所以内存是连续的，2个VolatileLong对象的大小是48字节，这样一来，对于缓存行大小是64字节来说，每个缓存行只能存放2个VolatileLong对象。 通过上面的分析可知，伪共享发生在L3 Cache，如果每个核操作的数据不在同一个缓存行中，那么就会避免伪共享的发生，所以，8个线程的情况下其实是CPU线程共享了L1 Cache，所以执行的时间可能比4线程的情况还要短。下面看下执行时4线程和8线程的CPU使用情况： 可以看到，在4线程时，线程被平均分配到了4个核中，这样一来，L1 Cache肯定是不能共享的，这时会发生伪共享；而8线程时，每个核都使用了2个线程，这时L1 Cache是可以共享的，这在一定程度上能减少伪共享的发生，从而时间会变短（也不一定，但总体来说8线程的情况与4线程的运行时间几乎不会向加padding和注解的方式差那么多）。 在Windows上情况就不太一样了，在双核四线程的CPU上，测试结果并不和mac中一样，在不加padding和注解时，2线程和4线程执行的时间都是将近差了1倍，看下使用2个线程在Windows中执行的时候CPU的使用情况： 虽然只使用了2个线程，但从图像上来看，似乎都在工作，即使把线程数量设置为1也是这种情况。这应该是Windows和UNIX对CPU线程调度的方式不一样，具体我现在也不太清楚他们之间的差别，希望有知道的同学告知，感谢。 @sun.misc.Contended注解上文中将@sun.misc.Contended注解用在了对象上，@sun.misc.Contended注解还可以指定某个字段，并且可以为字段进行分组，下面通过代码来看下： 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * VM Options: * -javaagent:/Users/sangjian/dev/source-files/classmexer-0_03/classmexer.jar * -XX:-RestrictContended */public class ContendedTest &#123; byte a; @sun.misc.Contended(&quot;a&quot;) long b; @sun.misc.Contended(&quot;a&quot;) long c; int d; private static Unsafe UNSAFE; static &#123; try &#123; Field f = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); f.setAccessible(true); UNSAFE = (Unsafe) f.get(null); &#125; catch (NoSuchFieldException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) throws NoSuchFieldException &#123; System.out.println(&quot;offset-a: &quot; + UNSAFE.objectFieldOffset(ContendedTest.class.getDeclaredField(&quot;a&quot;))); System.out.println(&quot;offset-b: &quot; + UNSAFE.objectFieldOffset(ContendedTest.class.getDeclaredField(&quot;b&quot;))); System.out.println(&quot;offset-c: &quot; + UNSAFE.objectFieldOffset(ContendedTest.class.getDeclaredField(&quot;c&quot;))); System.out.println(&quot;offset-d: &quot; + UNSAFE.objectFieldOffset(ContendedTest.class.getDeclaredField(&quot;d&quot;))); ContendedTest contendedTest = new ContendedTest(); // 打印对象的shallow size System.out.println(&quot;Shallow Size: &quot; + MemoryUtil.memoryUsageOf(contendedTest) + &quot; bytes&quot;); // 打印对象的 retained size System.out.println(&quot;Retained Size: &quot; + MemoryUtil.deepMemoryUsageOf(contendedTest) + &quot; bytes&quot;); &#125;&#125; 这里还是使用到了classmexer.jar，可以参考Java对象内存布局中的说明。 这里在变量b和c中使用了@sun.misc.Contended注解，并将这两个变量分为1组，执行结果如下： 123456offset-a: 16offset-b: 152offset-c: 160offset-d: 12Shallow Size: 296 bytesRetained Size: 296 bytes 可见int类型的变量的偏移地址是12，也就是在对象头后面，因为它正好是4个字节，然后是变量a。@sun.misc.Contended注解的变量会加到对象的最后面，这里就是b和c了，那么b的偏移地址是152，之前说过@sun.misc.Contended注解会在变量前后各加128字节，而byte类型的变量a分配完内存后这时起始地址应该是从17开始，因为byte类型占1字节，那么应该补齐到24，所以b的起始地址是24+128=152，而c的前面并不用加128字节，因为b和c被分为了同一组。 我们算一下c分配完内存后，这时的地址应该到了168，然后再加128字节，最后大小就是296。内存结构如下： | d:12~16 | --- | a:16~17 | --- | 17~24 | --- | 24~152 | --- | b:152~160 | --- | c:160~168 | --- | 168~296 | 现在把b和c分配到不同的组中，代码做如下修改： 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * VM Options: * -javaagent:/Users/sangjian/dev/source-files/classmexer-0_03/classmexer.jar * -XX:-RestrictContended */public class ContendedTest &#123; byte a; @sun.misc.Contended(&quot;a&quot;) long b; @sun.misc.Contended(&quot;b&quot;) long c; int d; private static Unsafe UNSAFE; static &#123; try &#123; Field f = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); f.setAccessible(true); UNSAFE = (Unsafe) f.get(null); &#125; catch (NoSuchFieldException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) throws NoSuchFieldException &#123; System.out.println(&quot;offset-a: &quot; + UNSAFE.objectFieldOffset(ContendedTest.class.getDeclaredField(&quot;a&quot;))); System.out.println(&quot;offset-b: &quot; + UNSAFE.objectFieldOffset(ContendedTest.class.getDeclaredField(&quot;b&quot;))); System.out.println(&quot;offset-c: &quot; + UNSAFE.objectFieldOffset(ContendedTest.class.getDeclaredField(&quot;c&quot;))); System.out.println(&quot;offset-d: &quot; + UNSAFE.objectFieldOffset(ContendedTest.class.getDeclaredField(&quot;d&quot;))); ContendedTest contendedTest = new ContendedTest(); // 打印对象的shallow size System.out.println(&quot;Shallow Size: &quot; + MemoryUtil.memoryUsageOf(contendedTest) + &quot; bytes&quot;); // 打印对象的 retained size System.out.println(&quot;Retained Size: &quot; + MemoryUtil.deepMemoryUsageOf(contendedTest) + &quot; bytes&quot;); &#125;&#125; 运行结果如下： 123456offset-a: 16offset-b: 152offset-c: 288offset-d: 12Shallow Size: 424 bytesRetained Size: 424 bytes 可以看到，这时b和c中增加了128字节的padding，结构也就变成了： | d:12~16 | --- | a:16~17 | --- | 17~24 | --- | 24~152 | --- | b:152~160 | --- | 160~288 | --- | c:288~296 | --- | 296~424 |]]></content>
  </entry>
  <entry>
    <title><![CDATA[Disruptor 高并发处理框架？？]]></title>
    <url>%2F2019%2F05%2F15%2Fdisruptor%2F</url>
    <content type="text"><![CDATA[何用官方定位：High Performance Inter-Thread Messaging Library2011年Disruptor论文中的定位：High performance alternative to bounded queues for exchanging data between concurrent threads用于替代应用内的有界队列 疑问：诞生于2011年，在分布式和微服务年代，Disruptor真正的价值体现在哪里？ 何来Disrutpor 的母公司 LMAX，目标作出世界上最快的交易平台（the fastest trading platform in the world），因此需要一个低延迟、高性能的jvm平台（needed to do something special to achieve very low-latency and high-throughput with our Java platform）。 LMAX aims to be the fastest trading platform in the world. Clearly, in order to achieve this we needed to do something special to achieve very low-latency and high-throughput with our Java platform. Performance testing showed that using queues to pass data between stages of the system was introducing latency, so we focused on optimising this area. 使用 Disruptor 并非简单的将原有队列替换为 Disruptor 的环形buffer（magic ring buffer），而是需要在了解Disruptor的是实现原理后，进行一些改造。 有什么大不了 What’s the big deal?并发执行的两个关注点mutual exclusion 相互排斥如何实现或管理资源的竞态更新（contended updates） visibility of change 变化的可见性确保变更对其他线程可见 成本The Cost of LocksLocks provide mutual exclusion and ensure that the visibility of change occurs in an ordered manner. Locks are incredibly expensive because they require arbitration when contended. This arbitration is achieved by a context switch to the operating system kernel which will suspend threads waiting on a lock until it is released. During such a context switch, as well as releasing control to the operating system which may decide to do other house-keeping tasks while it has control, execution context can lose previously cached data and instructions. This can have a serious performance impact on modern processors The Costs of “CAS”A more efficient alternative to the use of locks can be employed for updating memory when the target of the update is a single word. These alternatives are based upon the atomic, or interlocked, instructions implemented in modern processors. These are commonly known as CAS(Compare And Swap) operations, e.g. “lock cmpxchg” on x86. A CAS operation is a special machine-code instruction that allows a word in memory to be conditionally set as an atomic operation. For the “increment a counter experiment” each thread can spin in a loop reading the counter then try to atomically set it to its new incremented value. The old and new values are provided as parameters to this instruction. If, when the operation is executed, the value of the counter matches the supplied expected value, the counter is updated with the new value. If, on the other hand, the value is not as expected, the CAS operation will fail. It is then up to the thread attempting to perform the change to retry, re-reading the counter incrementing from that value and so on until the change succeeds. This CAS approach is significantly more efficient than locks because it does not require a context switch to the kernel for arbitration. However CAS operations are not free of cost. The processor must lock its instruction pipeline to ensure atomicity and employ a memory barrier to make the changes visible to other threads. CAS operations are available in Java by using the java.util.concurrent.Atomic* classes.]]></content>
      <tags>
        <tag>disruptor</tag>
        <tag>ring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL undo log]]></title>
    <url>%2F2019%2F05%2F09%2Fmysql-undo-log%2F</url>
    <content type="text"><![CDATA[日志文件主要用于记录redo log，InnoDB采用循环使用的方式，你可以通过参数指定创建文件的个数和每个文件的大小。默认情况下，日志是以512字节的block单位写入。由于现代文件系统的block size通常设置到4k，InnoDB提供了一个选项，可以让用户将写入的redo日志填充到4KB，以避免read-modify-write的现象；而Percona Server则提供了另外一个选项，支持直接将redo日志的block size修改成指定的值。 从上层的角度来看，InnoDB层的文件，除了redo日志外，基本上具有相当统一的结构，都是固定block大小，普遍使用的btree结构来管理数据。只是针对不同的block的应用场景会分配不同的页类型。通常默认情况下，每个block的大小为 UNIV_PAGE_SIZE，在不做任何配置时值为16kb 作用： 保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读内容： 逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的。什么时候产生： 事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性什么时候释放： 当事务提交之后，undo log并不能立马被删除， 而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。 查询表空间使用情况 show variables like ‘%innodb_data_file_path%’ Undo log (回滚日志)Undo log 是 InnoDB MVCC 事务特性的重要组成部分。Undo log 中保存用于实现 InnoDB 中的事务回滚；对记录做了变更操作时就会产生 undo 记录，Undo 记录默认被记录到系统表空间(ibdata)中，但从5.6开始，也可以使用独立的 Undo 表空间。Undo log = undo log records(对应一个事务) * N 何时记录 Undo log INSERT在事务提交前只对当前事务可见，因此产生的Undo日志可以在事务提交后直接删除 DELETE \ UPDATE需要维护多版本信息在 InnoDB 里，UPDATE 和 DELETE 操作产生的 Undo日志 被归成一类，即 update_undo 数据修改时，需要同时记录 redo log 和 undo log；如果因为某些原因导致事务失败或回滚了，可以借助该undo进行回滚；undo log 和 redo log 记录物理日志不一样，它是逻辑日志。可以认为： 当 delete 一条记录时，undo log 中会记录一条对应的insert记录，反之亦然； 当 update 一条记录时，它记录一条对应相反的 update 记录。 Undo log 中记录什么 存储了老版本的数据，可能包含多个版本的历史数据；An undo log record contains information about how to undo the latest change by a transaction to a clustered index record. 当一个旧的事务需要读取数据时，为了能读取到老版本的数据，需要顺着undo链找到满足其可见性的记录 关联 128 个 rollback segment 一个 rollback segment 有 1024 个 undo slot； 一个 undo slot 对应一个 undo log 一个 事务(dml) 对应一个 undo log InnoDB 最大支持多少个普通事务（user defined） 一个事务仅含 insert 或 update/delete ( innodb_page_size / 16 ) * innodb_rollback_segments * number of undo tablespaces 一个事务 含 一个insert 或 一个update\delete ( innodb_page_size / 16 / 2 ) * innodb_rollback_segments * number of undo tablespaces 一个事务在临时表空间执行 insert ( innodb_page_size / 16 ) * innodb_rollback_segments 一个事务在临时表空间 执行insert 且 update\delete ( innodb_page_size / 16 / 2 ) * innodb_rollback_segments 支持事务数量调整5.5 支持事务数量：5.1+版本，1024 * innodb_rollback_segments8.0 支持事务数量：5.6+版本，增加配置参数 number of undo tablespaces In MySQL 5.6 and MySQL 5.7, the number of undo tablespaces is controlled by the innodb_undo_tablespaces configuration option. In MySQL 8.0, two default undo tablespaces are created when the MySQL instance is initialized, and additional undo tablespaces can be created using CREATE UNDO TABLESPACE syntax. 基本文件结构undo tablesapce \ global temporary tablespace (used for transactions that modify data in user-defined temporary tables)–&gt; rollback segment—-&gt; undo log segment——&gt; undo log——–&gt; undo log record rseg（ rollback segment ）: 回滚段 rseg0：预留在系统表空间ibdata中; rseg1 - rseg32：这32个回滚段存放于临时表的系统表空间中; rseg33 - rseg127: 则根据配置存放到独立undo表空间中（如果没有打开独立Undo表空间，则存放于ibdata中） 如何实现并发写入执行流程创建 undo 物理表空间 srv_undo_tablespaces_init 根据 innodb_undo_tablespaces 参数，调用 srv_undo_tablespace_create 创建默认大小为 10M 的文件； 分别对 undo tablespace 调用 srv_undo_tablespace_open；主要调用fil_space_create 和 fil_node_create 将新建立的 undo tablespace 加入 Innodb 的文件体系； 对 undo tablespace 进行 fsp_header 的初始化1234567891011121314mlog_write_ulint(header + FSP_SPACE_ID, space_id, MLOG_4BYTES, mtr);mlog_write_ulint(header + FSP_NOT_USED, 0, MLOG_4BYTES, mtr);mlog_write_ulint(header + FSP_SIZE, size, MLOG_4BYTES, mtr);mlog_write_ulint(header + FSP_FREE_LIMIT, 0, MLOG_4BYTES, mtr);mlog_write_ulint(header + FSP_SPACE_FLAGS, space-&gt;flags, MLOG_4BYTES, mtr);mlog_write_ulint(header + FSP_FRAG_N_USED, 0, MLOG_4BYTES, mtr);flst_init(header + FSP_FREE, mtr);flst_init(header + FSP_FREE_FRAG, mtr);flst_init(header + FSP_FULL_FRAG, mtr);flst_init(header + FSP_SEG_INODES_FULL, mtr);flst_init(header + FSP_SEG_INODES_FREE, mtr); 生成了 n_undo_tablespaces 个大小为10MB的 undo tablespace 文件，并且已经加入到 innoDB 文件体系，但是里面没有任何类容。 ibdata中system segment header的初始化调用 trx_sys_create_sys_pages-&gt;trx_sysf_create 进行，除初始化transaction system segment 外还会初始化其 header( ibdata page no 5) 信息；老版本代码中，TRX_SYS_OLD_N_RSEGS=256，实际只会有128个，rollback segment slots 都初始化完成(源码所示有256个，实际上最多只会有128个，其中0号solt固定在ibdata中) slot 大小是TRX_SYS_RSEG_SLOT_SIZE设置的大小为8字节，4字节space id ,4字节 page no，它们会指向 rollback segment header所在的位置TRX_SYS_TRX_ID_STORETRX_SYS_FSEG_HEADERTRX_SYS_RSEGS rollback segment header 初始化调用 trx_sys_create_rsegs进行； 关于innodb_undo_logs参数和innodb_rollback_segments参数，他们作用就是设置rollback segment 的个数，本文以128为例。 根据注释和代码innodb_undo_logs已经是个淘汰的参数，应该用innodb_rollback_segments代替。这两个参数默认是就是TRX_SYS_N_RSEGS及 128 其实不用设置的 初始化rollback segments 段 12n_noredo_created = trx_sys_create_noredo_rsegs(n_tmp_rsegs); //创建 32个 临时rollback segments 建立 95个(33-128) 普通rollback segments是 i % n_spaces 的取模方式 n_spaces 为 innodb_undo_tablespaces 参数设置的值，因此每个 rollback segment 是轮序的方式分布到不同的 undo tablespace 中的。 rollback segment header初始化过程建立rollback segment 12block = fseg_create(space, 0, TRX_RSEG + TRX_RSEG_FSEG_HEADER, mtr); //建立一个回滚段，返回段头所在的块 初始化TRX_RSEG_MAX_SIZE和TRX_RSEG_HISTORY_SIZE信息初始化每个undo segment header所在的page no； 相关参数innodb_rollback_segments 每个 undo tablespace 和 global temporary tablespace 分别支持 128 个rollback segmentEach undo tablespace and the global temporary tablespace individually support a maximum of 128 rollback segments. The innodb_rollback_segments variable defines the number of rollback segments. innodb_undo_tablespacesinnodb_undo_tablespaces innodb_page_size问题什么是 purge1 delete语句操作的后，只会对其进行delete mark，这些被标记为删除的记录只能通过purge来进行物理的删除，但是并不回收空间2 undo log，如果undo 没有任何事务再引用，那么也只能通过purge线程来进行物理的删除，但是并不回收空间 purge后空间就释放了吗1 undo page里面可以存放多个undo log日志2 只有当undo page里面的所有undo log日志都被purge掉之后，这个页的空间才可能被释放掉，否则这些undo page可以被重用]]></content>
      <tags>
        <tag>myql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL redo log]]></title>
    <url>%2F2019%2F05%2F09%2Fmysql-redo-log%2F</url>
    <content type="text"><![CDATA[MySQL redo log]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-02-28-narration-of-service-mesh]]></title>
    <url>%2F2019%2F02%2F28%2Fnarration-of-service-mesh%2F</url>
    <content type="text"><![CDATA[服务治理Service Mesh解决系统架构微服务化后的服务间通信和治理问题；适用场景：大规模部署微服务（微服务数&gt;1000）、内部服务异构程度高(交互协议/开发语言类型&gt;5)的场景；第一代：Linkerd 和 Envoy；第二代：Istio 和 Conduit；主要改进集中在更加强大的控制面功能（与之对应的 sidecar proxy 被称之为数据面） 缺点： 网络中多了一跳，增加了性能和延迟的开销； 每个服务都需要sidecar, 这会给本来就复杂的分布式系统更加复杂，尤其是在实施初期，运维对service mesh本身把控能力不足的情况下，往往会使整个系统更加难以管理。 参考：Service Mesh 及其主流开源实现解析 Gateway相比 Service Mesh，只负责进入的请求，不关注对外的请求；粒度可粗可细，粗可到整个api总入口，细可到每个服务实例。 编排框架kubernetes、Mesos、Docker Swarm 容器docker]]></content>
      <tags>
        <tag>kubernetes</tag>
        <tag>service-mesh</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes 的那些事儿]]></title>
    <url>%2F2019%2F02%2F28%2Fnarration-of-kubernetes%2F</url>
    <content type="text"><![CDATA[K8s，编排容器的框架；Master components、Control plane、Pod、Container What is Kubernetes What is编排框架（竞品：Mesos、Docker Swarm），用于调度和惯例容器 Kubernetes is a portable, extensible open-source platform for managing containerized workloads and services, that facilitates both declarative configuration and automation.Kubernetes是一个可移植的、可扩展的开放源码平台，用于管理容器化的工作负载和服务，这有助于实现声明性配置和自动化 What is not 不是PaaS 相同：operate container，and support deployment, scaling, load balancing, logging, and monitoring差异： kubernetes is not monolithic, and these default solutions are optional and pluggable; Kubernetes provides the building blocks for building developer platforms, but preserves user choice and flexibility where it is important. Kubernetes含义源自希腊语中的舵手、飞行员；K8s中的8表示中间8个字母”ubernete”的缩写； The name Kubernetes originates from Greek, meaning helmsman or pilot, and is the root of governor and cybernetic. K8s is an abbreviation derived by replacing the 8 letters “ubernete” with “8”. Kubernetes Components Master Components provide the cluster’s control plane 官方高可用解决方案，实现将 Master Components 部署在集群中的多台机器上### kube-apiserverComponent on the master that exposes the Kubernetes API. It is the front-end for the Kubernetes control plane.It is designed to scale horizontally – that is, it scales by deploying more instances.### etcdConsistent and highly-available key value store used as Kubernetes’ backing store for all cluster data.Always have a backup plan for etcd’s data for your Kubernetes clusteretcd documentation kube-schedulerComponent on the master that watches newly created pods that have no node assigned, and selects a node for them to run on. kube-controller-managerComponent on the master that runs controllers .Logically, each controller is a separate process, but to reduce complexity, they are all compiled into a single binary and run in a single process.These controllers include: Node Controller: Responsible for noticing and responding when nodes go down. Replication Controller: Responsible for maintaining the correct number of pods for every replication controller object in the system. Endpoints Controller: Populates the Endpoints object (that is, joins Services &amp; Pods). Service Account &amp; Token Controllers: Create default accounts and API access tokens for new namespaces. cloud-controller-managerNode ComponentsNode components run on every node, maintaining running pods and providing the Kubernetes runtime environment kubeletAn agent that runs on each node in the cluster. It makes sure that containers are running in a pod. kube-proxykube-proxy enables the Kubernetes service abstraction by maintaining network rules on the host and performing connection forwarding. Container RuntimeThe container runtime is the software that is responsible for running containers. Kubernetes supports several runtimes: Docker, containerd, cri-o, rktlet and any implementation of the Kubernetes CRI (Container Runtime Interface). Addons名词解析ad hoc参考 kubernetes官网 三小时攻克kubernetes（配套git仓库）]]></content>
      <tags>
        <tag>kubernetes</tag>
        <tag>container</tag>
        <tag>orchestrate</tag>
        <tag>容器</tag>
        <tag>编排框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NP问题那些事儿]]></title>
    <url>%2F2019%2F02%2F08%2Fnarration-of-np%2F</url>
    <content type="text"><![CDATA[Polynominal（多项式）类问题Nondeterministic Polynominal（非确定性多项式）类问题NP问题、NPC问题、NPH问题 何去何从多项式时间 和 非多项式时间多项式时间：O(1)、O(log(n))、O(n^a)（对于规模为n的输入，在最坏情况下的运行时间是 O(n^k)，其中k为某一确定常数）非多项式时间：O(a^n)、O(n!)后者比前者复杂许多；时间复杂度排个队：o(1) &lt; o(n) &lt; o(lgn) &lt; o(n^2) &lt; o(n^a) &lt; o(e^n)（a&gt;2,n表示输入的数据个数，o(1)为常数级别） 我们为什么关心P我们认为在多项式时间内可解的问题是易处理的问题，在超多项式时间内解决的问题是不易处理的问题； 多项式时间的那些事儿P类问题Polynominal Time 多项式时间O(n^k)内可以解决的问题 能够在多项式时间内解决的决策问题（可以找到一个能在多项式的时间里解决它的算法） 如 图搜索问题、最短路径问题、最小生成树问题······ NP类问题Nondeterministic Polynomial Time 非确定性多项式时间 在多项式时间内可以被证明；不能在多项式时间内解决或不确定能不能在多项式时间内解决，但能在多项式时间验证的问题。 验证： 给定一个问题的实例、证书（类似于证据），需要验证这个证书是这个问题的正确答案。 如 汉密尔顿路径，实例为G=(V,E)，证书为顶点序列 {v0,v1,v2,v3,….,vk}，我们的目的是要验证这个证书就是这个问题的答案，验证方法为：先遍历一遍这个点序列，看看是不是每个点只出现一次，然后对于(vi,vi+1)是否为G的边，这样就能够验证这个点序列是不是汉密尔顿路径，很显然这个验证过程是多项式时间的，所以汉密尔顿路径是NP问题。 注意：NP问题不是非P类问题，此处不要理解错误 NPC类问题Non-deterministic Polynomial-time Complete Decision Problem if any NP-complete problem can be solved in polynomial time, then every problem in NP has a polynomial-time algorithm. NPC问题的状态是未知的；迄今为止，既没有人找出求解NPC的多项式时间算法，也没有人能够证明对这类不存在多项式时间算法；（也就是 P ≠ NP 问题） 证明一个问题是NPC问题 判定问题与最优化问题最优化问题（Optimization Problem）：每一个可行的解都有一个关联的值，希望找出一个具有最佳值的可行解；判定问题（Decision Problem）：答案是1或0； 几个诱人的NPC问题有几个NPC问题非常诱人，因为它们表面上看起来和我们一直的可以用多项式时间算法解决的问题很相似。下面列出的每一个问题中，一个是可以用多项式时间算法解决的，另一个却是NPC问题； 最短和最长简单路径最短路径（P）：在有向图G=(V,E)中，在O(VE)时间内从单一源顶点开始找到最短路径；最长简单路径 -&gt; 确定是否一个图在给定数量的边中包含一条简单路径（NPC） 其他Halting Problem 图灵停机问题 对于某程序P，给出某输入I，求解此程序P是否会到达终止状态。 证明证明就是构造反例即可：如果存在一个判断停机问题的程序H（H需要的输入是一个程序），我们再构造一个新的程序K，这个程序调用H但是与H的输出正好相反：如果K的输入经H判断为停机，则K不停机；如果K的输入经H判断为不停机，则K停机。现在矛盾出现了：如果我们把K输入K（即用H判断对于程序K，给出输入为K），那么K停机么？如果按逻辑推演，答案应该是：如果K不停机则K停机；如果K停机则K不停机。矛盾出现了。唯一解决矛盾的解释是：不存在这样万能的H。停机问题和说谎者悖论/理发师悖论是一脉相承的，说谎者/理发师悖论归根结底是定义了一个集合S={a|a is not in a}。补上这个漏洞的唯一方法是拒绝集合的自指。同样停机问题也说明了，不存在一个判定一切程序的程序，因为这个程序本身也是程序。 换个说法程序 L： 我能判断所有的程序能否停机。程序 C： 哥们，我是来找茬的。既然有你这么牛逼的程序，利用你，我能这样玩，给我任何一个程序，要是你判断停了，我就死循环，老子就不停了。苏格拉底：（对C说）你把你自己给到自己，即 C(C) 会如何？ 如果 C(C) 停了，根据 C 的内部逻辑， C 被 L 验证为停不了的。 如果 C(C) 停不了，根据 C 的内部逻辑， C 被 L 验证为能停机。 总之，充满矛盾。那么，只能推导出假设的前提是错的：根本没有 L 这种能判断所有程序能否停机的程序。]]></content>
      <tags>
        <tag>np</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 类加载过程]]></title>
    <url>%2F2019%2F01%2F18%2Fjava-class-loading-process%2F</url>
    <content type="text"><![CDATA[Java 类加载过程 = Loading + Linking + Initialization SpecificationThe Java Virtual Machine dynamically loads, links and initializes classes and interfaces. Loadingis the process of finding the binary representation of a class or interface type with a particular name and creating a class or interface from that binary representation. Linkingis the process of taking a class or interface and combining it into the run-time state of the Java Virtual Machine so that it can be executed. Initializationof a class or interface consists of executing the class or interface initialization method &lt;clinit&gt; Creation and Loading 加载 If Class C is not an array class, it is created by loading a binary representation of C using a class loader.Array classes do not have an external binary representation; they are created by the Java Virtual Machine rather than by a class loader. 通过一个类的全限定名获取其定义的二进制字节流； 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构； 在堆中生成一个代表这个类的 java.lang.Class 对象，作为对方法区中这些数据的访问入口； LinkingVerification 验证加载和验证是交叉进行的，验证在各个阶段都是存在的 确保Class文件的字节流信息符合JVM的要求； 4个阶段校验(文件格式校验、元数据校验、字节码校验、符号引用校验)； 验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用 -Xverifynone 参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 Preparation 准备 为类的静态变量(static)分配内存，并将其初始化为默认值； 如果常量无初始值，则默认赋值为java基本数据类型的默认值 类型 描述 byte 用8位补码表示，初始化为0 short 用16位补码表示，初始化为0 int 用32位补码表示，初始化为0 long 用64位补码表示，初始化为0L char 用16位补码表示，初始化为”u0000”，使用UTF-16编码 float 初始化为正0 double 初始化为正0 boolean 初始化为0 returnAddress 初始化为字节码指令的地址,用于配合异常处理特殊指令 Resolution 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程 符号引用（Symbolic References）符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。 直接引用（Direct References）直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那么引用的目标一定是已经存在于内存中。 这一步是可选的。可以在符号引用第一次被使用时完成，即所谓的 延迟解析(late resolution) 。但对用户而言，这一步永远是延迟解析的，即使运行时会执行 early resolution，但程序不会显示的在第一次判断出错误时抛出错误，而会在对应的类第一次主动使用的时候抛出错误！ Initialization 初始化 对类的静态变量，静态代码块执行初始化操作 类的初始化也是延迟的，直到类第一次被主动使用(active use)，JVM 才会初始化类； 类的初始化分两步： 如果基类没有被初始化，初始化基类。 有类构造函数，则执行类构造函数。 类构造函数是由 Java 编译器完成的。它把类成员变量的初始化和 static 区间的代码提取出，放到一个的方法中。这个方法不能被一般的方法访问（注意，static final 成员变量不会在此执行初始化，它一般被编译器生成 constant 值）。同时，中是不会显示的调用基类的的，因为 1 中已经执行了基类的初始化。类的初始化还必须注意线程安全的问题。]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Class Loader]]></title>
    <url>%2F2019%2F01%2F18%2Fjvm-class-loader%2F</url>
    <content type="text"><![CDATA[什么是ClassLoader？做了什么？Tomcat、Spring中的使用方式 JVM Class LoaderClassLoader是什么？负责将 Class 的字节码形式转换成内存形式的 Class 对象。字节码可以来自于磁盘文件 *.class，也可以是 jar 包里的 *.class，也可以来自远程服务器提供的字节流，字节码的本质就是一个字节数组 byte[]，符合java规范的字节数组。 字节码解析一般流程 ClassLoader.load( byte[] ) 大多数字节码加密技术，就是在这个过程中执行的： 对字节码加密：byte[] -&gt; encrypt(byte[])通过定制的ClassLoader读取经过加密的字节码：CustomClassLoader.load( encrypt(byte[]) ) 每个 Class 对象的内部都有一个 classLoader 字段来标识自己是由哪个 ClassLoader 加载的。ClassLoader 在生成 Class 时传入；12345678910public final class Class&lt;T&gt; implements java.io.Serializable, GenericDeclaration, Type, AnnotatedElement &#123; ··· private final ClassLoader classLoader; private Class(ClassLoader loader) &#123; classLoader = loader; &#125; ··· ClassLoader 基础体系JVM 运行实例中会存在多个 ClassLoader，不同的 ClassLoader 会从不同的地方加载字节码文件。它可以从不同的文件目录加载，也可以从不同的 jar 文件中加载，也可以从网络上不同的静态文件服务器来下载字节码再加载。JVM 中内置了三个重要的 ClassLoader，分别是 BootstrapClassLoader、ExtensionClassLoader 和 AppClassLoader。 BootstrapClassLoaderC++ 实现负责加载 JVM 运行时核心类，这些类位于 $JAVA_HOME/lib/rt.jar 文件中，我们常用内置库 java.xxx.* 都在里面，比如 java.util.*、java.io.*、java.nio.*、java.lang.* 等等。这个 ClassLoader 比较特殊，它是由 C 代码实现的，我们将它称之为「根加载器」。 ExtClassLoadersun.misc.Launcher.class 中的静态内部类，Java实现；引导路径：System.getProperty(&quot;java.ext.dirs&quot;)负责加载 JVM 扩展类，比如 swing 系列、内置的 js 引擎、xml 解析器 等等，这些库名通常以 javax 开头，它们的 jar 包位于 $JAVA_HOME/lib/ext/*.jar 中，有很多 jar 包。 AppClassLoadersun.misc.Launcher.class 中的静态内部类，Java实现；引导路径：System.getProperty(&quot;java.class.path&quot;)直接面向我们用户的加载器，它会加载 Classpath 环境变量里定义的路径中的 jar 包和目录。我们自己编写的代码以及使用的第三方 jar 包通常都是由它来加载的。 Launcher 引导类引导路径：System.getProperty(&quot;sun.boot.class.path&quot;) 那些位于网络上静态文件服务器提供的 jar 包和 class文件，jdk 内置了一个 URLClassLoader，用户只需要传递规范的网络路径给构造器，就可以使用 URLClassLoader 来加载远程类库了。URLClassLoader 不但可以加载远程类库，还可以加载本地路径的类库，取决于构造器中不同的地址形式。ExtensionClassLoader 和 AppClassLoader 都是 URLClassLoader 的子类，它们都是从本地文件系统里加载类库。 AppClassLoader 可以由 ClassLoader 类提供的静态方法 getSystemClassLoader() 得到，它就是我们所说的「系统类加载器」，我们用户平时编写的类代码通常都是由它加载的。当我们的 main 方法执行的时候，这第一个用户类的加载器就是 AppClassLoader。 加载器 Launcher 执行顺序12345678910111213141516171819202122232425262728293031323334public Launcher() &#123; Launcher.ExtClassLoader var1; try &#123; var1 = Launcher.ExtClassLoader.getExtClassLoader(); &#125; catch (IOException var10) &#123; throw new InternalError("Could not create extension class loader", var10); &#125; try &#123; // 将 ExtClassLoader 作为 parent 传递给 AppClassLoader this.loader = Launcher.AppClassLoader.getAppClassLoader(var1); &#125; catch (IOException var9) &#123; throw new InternalError("Could not create application class loader", var9); &#125; Thread.currentThread().setContextClassLoader(this.loader); String var2 = System.getProperty("java.security.manager"); if (var2 != null) &#123; SecurityManager var3 = null; if (!"".equals(var2) &amp;&amp; !"default".equals(var2)) &#123; try &#123; var3 = (SecurityManager)this.loader.loadClass(var2).newInstance(); &#125; catch (IllegalAccessException var5) &#123; &#125; catch (InstantiationException var6) &#123; &#125; catch (ClassNotFoundException var7) &#123; &#125; catch (ClassCastException var8) &#123; &#125; &#125; else &#123; var3 = new SecurityManager(); &#125; if (var3 == null) &#123; throw new InternalError("Could not create SecurityManager: " + var2); &#125; System.setSecurityManager(var3); &#125;&#125; 双亲委派 Parents Delegation Model所谓的Parents Delegation Model其实就是一种类加载器之间的层次关系，具体的说就是它规定最顶层的类加载器必须为启动类加载器，其余的类加载器必须有自己的父类加载器，且上下层关系的加载器一般是用组合而不是继承来实现。 某个class loader会优先委派给它的parent classloader加载类； 双亲委派实现方式如果当前类加载器的父类加载器不为空，就先让父类加载器加载 name 对应的类，parent 成员变量就是第二个问题中类加载器初始化时传递的父类加载器，这就解释了 ExtClassLoader 的父类加载器传递的是 null，就会执行 else 的逻辑，调用 findBootstrapClassOrNull() ，而该方法最终为 native 方法 private native Class findBootstrapClass(String name); ，实际上就是调用openjdk中 BootStrap ClassLoader 的实现去加载该类 123456789101112131415161718192021222324252627282930protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. c = findClass(name); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125;&#125; 组合而非继承 值得注意的是图中的 ExtensionClassLoader 的 parent 指针画了虚线，这是因为它的 parent 的值是 null，当 parent 字段是 null 时就表示它的父加载器是「根加载器」。如果某个 Class 对象的 classLoader 属性值是 null，那么就表示这个类也是「根加载器」加载的。注意这里的 parent 不是 super 不是父类，只是 ClassLoader 内部的字段。 动态加载Class.forName我们通常使用 Class.forName 的方式，加载JDBC的驱动类1Class.forName("com.mysql.cj.jdbc.Driver"); Driver类源自 mysql-connector-java 包，6.x.x 以后的版本；在加载 Driver 类后，静态方法会被执行，完成 MySql 的驱动注册；12345678910111213141516171819202122public class Driver extends NonRegisteringDriver implements java.sql.Driver &#123; // // Register ourselves with the DriverManager // static &#123; try &#123; java.sql.DriverManager.registerDriver(new Driver()); &#125; catch (SQLException E) &#123; throw new RuntimeException("Can't register driver!"); &#125; &#125; /** * Construct a new driver and register it with DriverManager * * @throws SQLException * if a database error occurs. */ public Driver() throws SQLException &#123; // Required for Class.forName().newInstance() &#125;&#125; forName 方法同样也是使用调用者 Class 对象的 ClassLoader 来加载目标类。不过 forName 还提供了多参数版本，可以指定使用哪个 ClassLoader 来加载12public static Class&lt;?&gt; forName(String name, boolean initialize, ClassLoader loader); 通过这种形式的 forName 方法可以突破内置加载器的限制，通过使用自定类加载器允许我们自由加载其它任意来源的类库。根据 ClassLoader 的传递性，目标类库传递引用到的其它类库也将会使用自定义加载器加载。 Class Loader 核心方法ClassLoader中三个核心方法： loadClass(...)加载目标类的入口，它首先会查找当前 ClassLoader 以及它的双亲里面是否已经加载了目标类，如果没有找到就会让双亲尝试加载，如果双亲都加载不了，就会调用 findClass(...) 让自定义加载器自己来加载目标类 findClass(...)需要子类来覆盖的，不同的加载器将使用不同的逻辑来获取目标类的字节码。拿到这个字节码之后再调用 defineClass(...) 方法将字节码转换成 Class 对象 defineClass(...)调用 defineClass() 方法将字节码转换成 Class 对象； 其他辅助方法包括但不限于 findLoadedClass(...)充当一个缓存；当请求 loadClass 装入类时，它调用该方法来查看 ClassLoader 是否已装入这个类，这样可以避免重新装入已存在类所造成的麻烦。应首先调用该方法； findSystemClass(...)从本地文件系统装入文件。它在本地文件系统中寻找类文件，如果存在，就使用 defineClass(...) 将原始字节转换成 Class 对象，以将该文件转换成类。当运行 Java 应用程序时，这是 JVM 正常装入类的缺省机制。 resolveClass(...)ClassLoader 可以不完全地（无 link ）装入类，也可以完全地（link）装入类。当编写我们自己的 loadClass 时，可以通过 resolve 参数，决定是否调用 resolveClass(...) 方法；最终通过调用native方法resolve0实现；1private native void resolveClass0(Class&lt;?&gt; c); 自定义 Class Loader12345678910111213141516171819202122232425262728293031323334353637class ClassLoader &#123; // 加载入口，定义了双亲委派规则 Class loadClass(String name) &#123; // 是否已经加载了 Class t = this.findFromLoaded(name); if(t == null) &#123; // 交给双亲 t = this.parent.loadClass(name) &#125; if(t == null) &#123; // 双亲都不行，只能靠自己了 t = this.findClass(name); &#125; return t; &#125; // 交给子类自己去实现 Class findClass(String name) &#123; throw ClassNotFoundException(); &#125; // 组装Class对象 Class defineClass(byte[] code, String name) &#123; return buildClassFromCode(code, name); &#125;&#125;class CustomClassLoader extends ClassLoader &#123; Class findClass(String name) &#123; // 寻找字节码 byte[] code = findCodeFromSomewhere(name); // 组装Class对象 return this.defineClass(code, name); &#125;&#125; Class.forName vs ClassLoader.loadClass这两个方法都可以用来加载目标类，它们之间有一个小小的区别，那就是 Class.forName(...) 方法可以获取原生类型的 Class，而 ClassLoader.loadClass(...) 则会报错。1234567891011Class&lt;?&gt; x = Class.forName("[I");System.out.println(x);x = ClassLoader.getSystemClassLoader().loadClass("[I");System.out.println(x);---------------------class [IException in thread "main" java.lang.ClassNotFoundException: [I... 钻石依赖项目管理上有一个著名的概念叫着「钻石依赖」，是指软件依赖导致同一个软件包的两个版本需要共存而不能冲突。我们平时使用的 maven 是这样解决钻石依赖的，它会从多个冲突的版本中选择一个来使用，如果不同的版本之间兼容性很糟糕，那么程序将无法正常编译运行。Maven 这种形式叫「扁平化」依赖管理。使用 ClassLoader 可以解决钻石依赖问题。不同版本的软件包使用不同的 ClassLoader 来加载，位于不同 ClassLoader 中名称一样的类实际上是不同的类。 应用为甚使用反射加载jdbc驱动1Class.forName("com.mysql.cj.jdbc.Driver"); JDBC 是 Java 的一种规范，通俗一点说就是 JDK 在 java.sql.* 下提供了一系列的接口（interface），但没有提供任何实现（也就是类）。 所以任何人都可以在接口规范之下写自己的 JDBC 实现（如MySQL）。而若调用者也只调用接口上的方法（如我们），那么当未来有任何变更需要时（例如要从 MySQL 迁移至 Oracle ），则理论上不需要对代码做任何修改就能直接切换（可惜SQL语法没能统一规范） 这意味着什么？意味着你的代码中不应该引用任何与实现相关的东西，你的代码只知道 java.sql.* ，而不应该知道 com.mysql.* 或是 com.oracle.* ，以避免或减少未来切换数据源时对代码的变更。 注意，我们使用的所有其他API包括Connection/Statement/ResultSet 等都是java.sql.* 的东西，甚至com.mysql.cj.jdbc.Driver 类也是：1234package com.mysql.jdbc;public class Driver ... implements java.sql.Driver &#123; ...&#125; 因此，直接 import com.mysql.jdbc.Driver，违反了开闭原则（OCP，对扩展开放，对修改关闭）。]]></content>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
        <tag>class loader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git 常见用法]]></title>
    <url>%2F2019%2F01%2F14%2Fgit-base%2F</url>
    <content type="text"><![CDATA[git 命令 图说git工作区(working tree)，暂存区（index）和 branch（commit） 交互式暂存使用交互模式的价值git add 的 INTERACTIVE MODE；包含 status、 diff、 add --patch 等功能，可以方便地构建只包含特定组合和部分文件的提交。在你修改了一大批文件然后决定将这些变更分布在几个各有侧重的提交而不是单个又大又乱的提交时，这些工具非常有用。用这种方法，你可以确保你的提交在逻辑上划分为相应的变更集，以便于供和你一起工作的开发者审阅。 交互模式通过 git add -i 进入交互模式，交互样式如下12345678➜ interactive-folder git:(master) ✗ git add -i staged unstaged path 1: unchanged +1/-1 folder/number1 2: unchanged +2/-2 folder/number2*** Commands *** 1: status 2: update 3: revert 4: add untracked 5: patch 6: diff 7: quit 8: help 如需要将 folder/number1 文件加入到暂存区中，可以执行以下操作：2 -&gt; &#39;enter&#39; -&gt; 1 -&gt; &#39;enter&#39;；其中第一个2表示选择update功能，1表示选择第一个文件；选择 Update 并选择 folder/number1 后，number1文件左侧出现一个 * 号标记，表示文件已经执行对应操作；1234567891011121314151617181920212223➜ interactive-folder git:(master) ✗ git add -i staged unstaged path 1: unchanged +1/-1 folder/number1 2: unchanged +2/-2 folder/number2*** Commands *** 1: status 2: update 3: revert 4: add untracked 5: patch 6: diff 7: quit 8: helpWhat now&gt; 2 staged unstaged path 1: unchanged +1/-1 folder/number1 2: unchanged +2/-2 folder/number2Update&gt;&gt; 1 staged unstaged path* 1: unchanged +1/-1 folder/number1 2: unchanged +2/-2 folder/number2Update&gt;&gt;updated 1 path*** Commands *** 1: status 2: update 3: revert 4: add untracked 5: patch 6: diff 7: quit 8: helpWhat now&gt; Git Commandadd1234git add [--verbose | -v] [--dry-run | -n] [--force | -f] [--interactive | -i] [--patch | -p] [--edit | -e] [--[no-]all | --[no-]ignore-removal | [--update | -u]] [--intent-to-add | -N] [--refresh] [--ignore-errors] [--ignore-missing] [--chmod=(+|-)x] [--] [&lt;pathspec&gt;…] add --patch When you pass this option to add, instead of immediately adding all the changes in the file to the index, it goes through each change and asks you what you want to do 我们通常使用 git add &lt;file&gt; 将文件中的所有修改都添加到 暂存区(index) 中；初次之外，我们可以通过 git add --patch 或 git add -p，让我们可以将同一个文件中的修改进行筛选，并最终放到不同的commit中；通过使用--patch 或简写的 -p 参数，我们可以逐个review文件夹中的文件，并决定每个文件中的每一处修改应如何处置（添加、拒绝或留待处理等）；123456789101112Stage this hunk [y,n,q,a,d,j,J,g,/,e,?]? ?y - stage this hunkn - do not stage this hunkq - quit; do not stage this hunk or any of the remaining onesa - stage this hunk and all later hunks in the filed - do not stage this hunk or any of the later hunks in the fileg - select a hunk to go to/ - search for a hunk matching the given regexj - leave this hunk undecided, see next undecided hunkJ - leave this hunk undecided, see next hunke - manually edit the current hunk? - print help 一个小栗子folder 文件夹下，原有number1和number2两个文件，我们number2文件，第一行由 pre 修改为 post，最后一行由 last 修改为 editLast；在使用 add --patch 操作到 number2 文件时，修改内容被修改为两个 hunk，我们可以针对不同的 hunk进行处理，如此处我们针对第一个hunk执行 y（stage this hunk），第二个hunk执行 n（do not stage this hunk）操作；这样最终只有第一个 pre -&gt; post 的修改会被加入到暂存区（index）中；123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778➜ patch-folder git:(master) ✗ gstOn branch masterChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: folder/number1 modified: folder/number2no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)➜ patch-folder git:(master) ✗ tree.├── folder│ ├── number1│ └── number2└── readme.md1 directory, 3 files➜ patch-folder git:(master) ✗ git add --patch folderdiff --git a/folder/number1 b/folder/number1index 34e9d85..a9a1b1f 100644--- a/folder/number1+++ b/folder/number1@@ -1 +1 @@-o1+po1Stage this hunk [y,n,q,a,d,e,?]? ndiff --git a/folder/number2 b/folder/number2index 0dcbba8..1027bad 100644--- a/folder/number2+++ b/folder/number2@@ -1,4 +1,4 @@-pre+post 1 2 3Stage this hunk [y,n,q,a,d,j,J,g,/,e,?]? ?y - stage this hunkn - do not stage this hunkq - quit; do not stage this hunk or any of the remaining onesa - stage this hunk and all later hunks in the filed - do not stage this hunk or any of the later hunks in the fileg - select a hunk to go to/ - search for a hunk matching the given regexj - leave this hunk undecided, see next undecided hunkJ - leave this hunk undecided, see next hunke - manually edit the current hunk? - print help@@ -1,4 +1,4 @@-pre+post 1 2 3Stage this hunk [y,n,q,a,d,j,J,g,/,e,?]? y@@ -7,4 +7,4 @@ po2 6 7 8-last+editLastStage this hunk [y,n,q,a,d,K,g,/,e,?]? n➜ patch-folder git:(master) ✗ gstOn branch masterChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: folder/number2Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: folder/number1 modified: folder/number2 push12345678$ git push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;$ git push [--all | --mirror | --tags] [--follow-tags] [--atomic] [-n | --dry-run] [--receive-pack=&lt;git-receive-pack&gt;] [--repo=&lt;repository&gt;] [-f | --force] [-d | --delete] [--prune] [-v | --verbose] [-u | --set-upstream] [--push-option=&lt;string&gt;] [--[no-]signed|--sign=(true|false|if-asked)] [--force-with-lease[=&lt;refname&gt;[:&lt;expect&gt;]]] [--no-verify] [&lt;repository&gt; [&lt;refspec&gt;…]] 将本地的master分支推送到origin主机的master分支。如果master不存在，则会被新建。1git push origin master 清空指定远端分支省略本地分支名，则表示删除指定的远程分支，因为这等同于推送一个空的本地分支到远程分支。123$ git push origin :master# 等同于$ git push origin --delete master 推送所有本地分支不管是否存在对应的远程分支，将本地的所有分支都推送到远程主机，这时需要使用–all选项。1$ git push --all origin 强制推送如果远程主机的版本比本地版本更新，推送时Git会报错，要求先在本地做 git pull 合并差异，然后再推送到远程主机。这时，如果你一定要推送，可以使用 --force 选项。1$ git push --force origin Shell上面命令使用 -–force 选项，结果导致在远程主机产生一个”非直进式”的合并(non-fast-forward merge)。除非你很确定要这样做，否则应该尽量避免使用 –-force 选项。 push 的 simple 和 matching 方式simple：默认只推送当前分支matching：推送所有有对应的远程分支的本地分支Git 2.0版本之前，默认采用matching方法，之后改为默认采用simple方式。如果要修改这个设置，可以采用git config命令。123$ git config --global push.default matching# 或者$ git config --global push.default simple fork保持与源项目的更新首先保证本地仓库的upstream是源项目的URL，若没有则添加：1git remote add upstream &#123;URL&#125; submodule Git Submodule 允许一个git仓库，作为另一个git仓库的子目录，并且保持父项目和子项目相互独立。 添加子仓库1$ git submodule add &lt;仓库地址&gt; &lt;本地路径&gt; 新建一个父仓库main，一个子仓库sub。将父仓库克隆到本地。1$ git clone ssh://git@host:port/path/to/main-project.git 进入父仓库，并添加子仓库1$ git submodule add ssh://git@host:port/path/to/sub.git sub-project 添加成功后，父仓库根目录会新增.gitmodule文件。123[submodule &quot;sub-project&quot;] path = sub-project url = ssh://git@host:port/path/to/sub.git 下图中 next文件夹是subModule，next中并不会才能出实际的文件，而是一个commitId 检出包含subModule的项目克隆一个包含子仓库的仓库目录，并不会clone下子仓库的文件，只是会克隆下 .gitmodule 描述文件，需要进一步克隆子仓库文件。12345// 初始化本地配置文件$ git submodule init// 检出父仓库列出的commit$ git submodule update 或者使用组合指令。1$ git submodule update --init --recursive 此时子目录在一个未命名分支（如果原始提交不是master分支），或子仓库有改动并没有检测到。123$ git branch* (HEAD detached at 46a27af) master 删除子仓库 删除.gitsubmodule里相关部分 删除.git/config 文件里相关字段 删除子仓库目录。1$ git rm --cached &lt;本地路径&gt; stashUse git stash when you want to record the current state of the working directory and the index, but want to go back to a clean working directory. The command saves your local modifications away and reverts the working directory to match the HEAD commit. The modifications stashed away by this command can be listed with git stash list, inspected with git stash show, and restored (potentially on top of a different commit) with git stash apply. Calling git stash without any arguments is equivalent to git stash push. A stash is by default listed as “WIP on branchname …”, but you can give a more descriptive message on the command line when you create one. The latest stash you created is stored in refs/stash; older stashes are found in the reflog of this reference and can be named using the usual reflog syntax (e.g. stash@{0} is the most recently created stash, stash@{1} is the one before it, stash@{2.hours.ago} is also possible). Stashes may also be referenced by specifying just the stash index (e.g. the integer n is equivalent to stash@{n}). 1234567891011git stash list [&lt;options&gt;]git stash show [&lt;stash&gt;]git stash drop [-q|--quiet] [&lt;stash&gt;]git stash ( pop | apply ) [--index] [-q|--quiet] [&lt;stash&gt;]git stash branch &lt;branchname&gt; [&lt;stash&gt;]git stash [push [-p|--patch] [-k|--[no-]keep-index] [-q|--quiet] [-u|--include-untracked] [-a|--all] [-m|--message &lt;message&gt;] [--] [&lt;pathspec&gt;...]]git stash cleargit stash create [&lt;message&gt;]git stash store [-m|--message &lt;message&gt;] [-q|--quiet] &lt;commit&gt; stash 常用指令git stash list 列出git stash show 查看git stash apply stash@{2} 恢复指定的stashgit stash 相当于git stash pushgit stash push --keep-index --keep-index 使用这个option时，会stash所有未被添加到index的文件，而不影响已经添加到add中的信息；具体可以参考 默认情况下，储藏列表为展示样式如下，但可以在命令行上给出更具描述性的消息。 stash 使用方式Pulling into a dirty tree当你处于某种状态的时候，你会发现有一些上游的变化可能与正在做的事情有关。当您的本地更改不会与上游的更改冲突时，简单的git pull 将让您向前。但是，有些情况下，本地更改与上游更改相冲突，git pull 拒绝覆盖您的更改。 在这种情况下，您可以将更改隐藏起来，执行 git pull ，然后解压缩，如下所示：123456$ git pull ...file foobar not up to date, cannot merge.$ git stash$ git pull$ git stash pop 工作流中断(Interrupted workflow)需要暂停手中的修改，并在当前分支上，优先执行另一个事情；此时可以使用stash123456# ... hack hack hack ...$ git stash$ edit emergency fix$ git commit -a -m "Emergency Fix"$ git stash pop# ... continue hacking ... 从储藏中创建分支如果储藏了一些工作，暂时不去理会，然后继续在你储藏工作的分支上工作，在重新应用工作时可能会碰到一些问题。如果尝试应用的变更是针对一个在那之后修改过的文件，会碰到一个归并冲突并且必须去化解它。如果你想用更方便的方法来重新检验储藏的变更，可以运行 git stash branch，这会创建一个新的分支，检出储藏工作时的所处的提交，重新应用你的工作，如果成功，将会丢弃储藏。1234567891011121314$ git stash branch testchangesSwitched to a new branch "testchanges"# On branch testchanges# Changes to be committed:# (use "git reset HEAD &lt;file&gt;..." to unstage)## modified: index.html## Changes not staged for commit:# (use "git add &lt;file&gt;..." to update what will be committed)## modified: lib/simplegit.rb#Dropped refs/stash@&#123;0&#125; (f0dfc4d5dc332d1cee34a634182e168c4efc3359) Testing partial commits当我们需要测试部分修改时，可以通过add --patch将部分修改先添加到index中，并使用 stash push --keep-index，将未添加的部分代码stash，用以验证当前的部分代码是否正确；123456789# ... hack hack hack ...$ git add --patch foo # add just first part to the index$ git stash push --keep-index # save all other changes to the stash$ edit/build/test first part$ git commit -m 'First part' # commit fully tested change$ git stash pop # prepare to work on all other changes# ... repeat above five steps until one commit remains ...$ edit/build/test remaining parts$ git commit foo -m 'Remaining parts' cherry-pick将另一个分支的若干个 commit(s)，合并到当前分支上；注意：当执行完 cherry-pick 以后，将会 生成一个新的提交；这个新的提交的哈希值和原来的不同，但标识名 一样；(commit id会变) 12345git cherry-pick [--edit] [-n] [-m parent-number] [-s] [-x] [--ff] [-S[&lt;keyid&gt;]] &lt;commit&gt;... -e, --edit With this option, git cherry-pick will let you edit the commit message prior to committing. cherry-pick 实战 如果在 cherry-pick 过程中，代码存在冲突，可能会出现类似的信息； 1234567[master bf9edd5] second Date: Mon Jan 14 15:01:31 2019 +0800 1 file changed, 1 insertion(+)error: could not apply 380b856... thridhint: after resolving the conflicts, mark the corrected pathshint: with 'git add &lt;paths&gt;' or 'git rm &lt;paths&gt;'hint: and commit the result with 'git commit' git status 查看时，此时需要手工处理标记为 both modified 的文件； 1234567891011On branch masterYou are currently cherry-picking commit 380b856. (fix conflicts and run "git cherry-pick --continue") (use "git cherry-pick --abort" to cancel the cherry-pick operation)Unmerged paths: (use "git add &lt;file&gt;..." to mark resolution) both modified: readme.mdno changes added to commit (use "git add" and/or "git commit -a") 处理完冲突后，git add标记为 both modified 的文件，此时可以使用 cherry-pick --continue 或 cherry-pick --abort 继续或终止 cherry-pick； format-patch什么是 patch如果一个软件有了新版本，我们可以完整地下载新版本的代码进行编译安装。然而，像Linux Kernel这样的大型项目，代码即使压缩，也超过70MB，每次全新下载是有相当大的代价的。然而，每次更新变动的代码可能不超过1MB，因此，我们只要能够有两个版本代码的diff的数据，应该就可以以极低的代价更新程序了。因此，Larry Wall开发了一个工具：patch。它可以根据一个diff文件进行版本更新。 diff 和format-patch的比较： 兼容性：很明显，git diff生成的Patch兼容性强。如果你在修改的代码的官方版本库不是Git管理的版本库，那么你必须使用git diff生成的patch才能让你的代码被项目的维护人接受。 除错功能：对于git diff生成的patch，你可以用git apply –check 查看补丁是否能够干净顺利地应用到当前分支中；如果git format-patch 生成的补丁不能打到当前分支，git am会给出提示，并协助你完成打补丁工作，你也可以使用git am -3进行三方合并，详细的做法可以参考git手册或者《Progit》。从这一点上看，两者除错功能都很强。 版本库信息：由于git format-patch生成的补丁中含有这个补丁开发者的名字，因此在应用补丁时，这个名字会被记录进版本库，显然，这样做是恰当的。因此，目前使用Git的开源社区往往建议大家使用format-patch生成补丁。]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-01-13-jvm-source-code]]></title>
    <url>%2F2019%2F01%2F13%2Fjvm-source-code%2F</url>
    <content type="text"><![CDATA[jdk源码结构12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394.├── ASSEMBLY_EXCEPTION├── LICENSE├── Makefile├── README├── README-builds.html├── THIRD_PARTY_README├── common│ ├── autoconf│ │ ├── Makefile.in│ │ ├── autogen.sh│ │ ├── basics.m4│ │ ├── basics_windows.m4│ │ ├── boot-jdk.m4│ │ ├── bootcycle-spec.gmk.in│ │ ├── build-aux│ │ │ ├── autoconf-config.guess│ │ │ ├── config.guess│ │ │ ├── config.sub│ │ │ ├── install.sh│ │ │ └── pkg.m4│ │ ├── build-performance.m4│ │ ├── builddeps.conf.example│ │ ├── builddeps.conf.nfs.example│ │ ├── builddeps.m4│ │ ├── compare.sh.in│ │ ├── config.h.in│ │ ├── configure│ │ ├── configure.ac│ │ ├── generated-configure.sh│ │ ├── help.m4│ │ ├── hotspot-spec.gmk.in│ │ ├── jdk-options.m4│ │ ├── libraries.m4│ │ ├── platform.m4│ │ ├── source-dirs.m4│ │ ├── spec.gmk.in│ │ ├── spec.sh.in│ │ ├── toolchain.m4│ │ ├── toolchain_windows.m4│ │ └── version-numbers│ ├── bin│ │ ├── boot_cycle.sh│ │ ├── compare-objects.sh│ │ ├── compare.sh│ │ ├── compare_exceptions.sh.incl│ │ ├── hgforest.sh│ │ ├── hide_important_warnings_from_javac.sh│ │ ├── logger.sh│ │ ├── shell-tracer.sh│ │ └── test_builds.sh│ ├── nb_native│ │ └── nbproject│ │ ├── configurations.xml│ │ └── project.xml│ └── src│ └── fixpath.c├── configure├── get_source.sh├── make│ ├── HotspotWrapper.gmk│ ├── Javadoc.gmk│ ├── Jprt.gmk│ ├── Main.gmk│ ├── MakeHelpers.gmk│ ├── common│ │ ├── CORE_PKGS.gmk│ │ ├── IdlCompilation.gmk│ │ ├── JavaCompilation.gmk│ │ ├── MakeBase.gmk│ │ ├── NON_CORE_PKGS.gmk│ │ ├── NativeCompilation.gmk│ │ ├── RMICompilation.gmk│ │ └── support│ │ ├── ListPathsSafely-post-compress.incl│ │ ├── ListPathsSafely-pre-compress.incl│ │ ├── ListPathsSafely-uncompress.sed│ │ └── unicode2x.sed│ ├── devkit│ │ ├── Makefile│ │ └── Tools.gmk│ ├── jprt.properties│ ├── scripts│ │ ├── hgforest.sh│ │ ├── lic_check.sh│ │ ├── normalizer.pl│ │ ├── update_copyright_year.sh│ │ └── webrev.ksh│ └── templates│ ├── bsd-header│ ├── gpl-cp-header│ └── gpl-header└── test └── Makefile]]></content>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 字节码]]></title>
    <url>%2F2019%2F01%2F12%2Fjava-jvm-specification%2F</url>
    <content type="text"><![CDATA[JVM 字节码定义与解析 字节码一览解析字节码解析常量池主要链路1234ClassFileParser::parseClassFile ┗━ ClassFileParser::parse_constant_pool() ┗━ oopFactory::new_constantPool() // 为常量池分配内存 ┗━ ClassFileParser::parse_constant_pool_entries() // 解析常量池 常量池内存分配JVM 解析 constant_pool 部分的信息前，需要先划出一块内存空间，将常量池的结构信息加载进来；会涉及两个问题： 分配多少内存 分配在哪里 JVM 使用专门的 C++ 类 constantPoolOop 保存常量池信息12345678class oopDesc &#123; private: volatile markOop _mark; // 线程锁等标记 union _metadata &#123; wideKlassOop _klass; narrowOop _compressed_klass; &#125; _metadata; // 元数据，自引用&#125;]]></content>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 启动函数]]></title>
    <url>%2F2019%2F01%2F11%2Fspring-boot-run%2F</url>
    <content type="text"><![CDATA[Spring Boot 初始化函数概述 基于 VERSION = 2.1.1.RELEASE SpringApplication 实例化123public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args);&#125; 调用 SpringApplication 的重载 run 方法（args参数类型不同）； 123456789public static ConfigurableApplicationContext run(Class&lt;?&gt; primarySource, String... args) &#123; return run(new Class&lt;?&gt;[] &#123; primarySource &#125;, args);&#125;public static ConfigurableApplicationContext run(Class&lt;?&gt;[] primarySources, String[] args) &#123; return new SpringApplication(primarySources).run(args);&#125; 并创建 SpringApplication 对象； 12345678910public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, "PrimarySources must not be null"); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath(); setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass();&#125; 公有依赖方法 getSpringFactoriesInstances：根据指定的类型查询到全路径类名称并初始化； SpringApplication 构造函数执行以下四个步骤： 推断应用类型WebApplicationType.deduceFromClasspath判断应用类型是 REACTIVE SERVLET NONE 中的哪一种123456789101112131415161718192021222324252627282930313233343536373839404142434445private static final String WEBFLUX_INDICATOR_CLASS = "org." + "springframework.web.reactive.DispatcherHandler";private static final String WEBMVC_INDICATOR_CLASS = "org.springframework." + "web.servlet.DispatcherServlet";private static final String JERSEY_INDICATOR_CLASS = "org.glassfish.jersey.servlet.ServletContainer";private static final String[] SERVLET_INDICATOR_CLASSES = &#123; "javax.servlet.Servlet", "org.springframework.web.context.ConfigurableWebApplicationContext" &#125;; static WebApplicationType deduceFromClasspath() &#123; // 如果仅存在 reactive.DispatcherHandler，则认定为REACTIVE的项目 if (ClassUtils.isPresent(WEBFLUX_INDICATOR_CLASS, null) &amp;&amp; !ClassUtils.isPresent(WEBMVC_INDICATOR_CLASS, null) &amp;&amp; !ClassUtils.isPresent(JERSEY_INDICATOR_CLASS, null)) &#123; return WebApplicationType.REACTIVE; &#125; // 如果不存在 Servlet 和 ConfigurableWebApplicationContext 类，则认定不是 SERVLET 工程 for (String className : SERVLET_INDICATOR_CLASSES) &#123; if (!ClassUtils.isPresent(className, null)) &#123; return WebApplicationType.NONE; &#125; &#125; return WebApplicationType.SERVLET;&#125;public enum WebApplicationType &#123; /** * The application should not run as a web application and should not start an * embedded web server. */ NONE, /** * The application should run as a servlet-based web application and should start an * embedded servlet web server. */ SERVLET, /** * The application should run as a reactive web application and should start an * embedded reactive web server. */ REACTIVE; ...&#125; 设置初始化器(Initializer)12setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); 通过getSpringFactoriesInstances，查询并实例化key为org.springframework.context.ApplicationContextInitializer的对象 Initializer类的功能：在Spring上下文被刷新之前进行初始化的操作。典型地比如在Web应用中，注册Property Sources或者是激活Profiles。Property Sources比较好理解，就是配置文件。Profiles是Spring为了在不同环境下(如DEV，TEST，PRODUCTION等)，加载不同的配置项而抽象出来的一个实体。 设置监听器(Listener)1setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); 通过getSpringFactoriesInstances，查询并实例化key为org.springframework.context.ApplicationListener的对象 推断应用入口类1this.mainApplicationClass = deduceMainApplicationClass(); 利用了jvm的异常机制，抛出一个异常，并在异常栈中，查询有main方法的类；1234567891011121314private Class&lt;?&gt; deduceMainApplicationClass() &#123; try &#123; StackTraceElement[] stackTrace = new RuntimeException().getStackTrace(); for (StackTraceElement stackTraceElement : stackTrace) &#123; if ("main".equals(stackTraceElement.getMethodName())) &#123; return Class.forName(stackTraceElement.getClassName()); &#125; &#125; &#125; catch (ClassNotFoundException ex) &#123; // Swallow and continue &#125; return null;&#125; SpringApplication.run12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); // 获取SpringApplicationRunListeners SpringApplicationRunListeners listeners = getRunListeners(args); // 发出开始执行的事件 listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); // 根据SpringApplicationRunListeners以及参数来准备环境 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); // 准备Banner打印器 - 就是启动Spring Boot的时候打印在console上的ASCII艺术字体 Banner printedBanner = printBanner(environment); // 创建Spring上下文 context = createApplicationContext(); // 准备异常报告器 exceptionReporters = getSpringFactoriesInstances( SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); // Spring上下文前置处理 prepareContext(context, environment, listeners, applicationArguments, printedBanner); // Spring上下文刷新 refreshContext(context); // Spring上下文后置处理 afterRefresh(context, applicationArguments); // 发出结束执行的事件 stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; return context;&#125; 获取SpringApplicationRunListeners通过getSpringFactoriesInstances，查询并实例化key为org.springframework.boot.SpringApplicationRunListener的对象 EventPublishingRunListener 负责发布SpringApplicationEvent事件的，它会利用一个内部的ApplicationEventMulticaster 在上下文实际被刷新之前对事件进行处理。 12345private SpringApplicationRunListeners getRunListeners(String[] args) &#123; Class&lt;?&gt;[] types = new Class&lt;?&gt;[] &#123; SpringApplication.class, String[].class &#125;; return new SpringApplicationRunListeners(logger, getSpringFactoriesInstances( SpringApplicationRunListener.class, types, this, args));&#125; 根据SpringApplicationRunListeners以及参数来准备环境1234567891011121314151617private ConfigurableEnvironment prepareEnvironment( SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments) &#123; // Create and configure the environment // 根据 webApplicationType，创建 StandardServletEnvironment， // StandardReactiveWebEnvironment或StandardEnvironment 的环境变量 ConfigurableEnvironment environment = getOrCreateEnvironment(); configureEnvironment(environment, applicationArguments.getSourceArgs()); listeners.environmentPrepared(environment); bindToSpringApplication(environment); if (!this.isCustomEnvironment) &#123; environment = new EnvironmentConverter(getClassLoader()) .convertEnvironmentIfNecessary(environment, deduceEnvironmentClass()); &#125; ConfigurationPropertySources.attach(environment); return environment;&#125; getOrCreateEnvironment根据 webApplicationType，创建对应的环境变量： StandardServletEnvironment，StandardReactiveWebEnvironment 或 StandardEnvironment ；12345678910111213private ConfigurableEnvironment getOrCreateEnvironment() &#123; if (this.environment != null) &#123; return this.environment; &#125; switch (this.webApplicationType) &#123; case SERVLET: return new StandardServletEnvironment(); case REACTIVE: return new StandardReactiveWebEnvironment(); default: return new StandardEnvironment(); &#125;&#125; configureEnvironment配置环境变量： 配置 Property Sources 配置 Profiles1234567891011protected void configureEnvironment(ConfigurableEnvironment environment, String[] args) &#123; if (this.addConversionService) &#123; ConversionService conversionService = ApplicationConversionService .getSharedInstance(); environment.setConversionService( (ConfigurableConversionService) conversionService); &#125; configurePropertySources(environment, args); configureProfiles(environment, args);&#125; listeners.environmentPrepared;在已注册的监听器上注册environment就绪；广播 Event（ApplicationEnvironmentPreparedEvent）1234public void environmentPrepared(ConfigurableEnvironment environment) &#123; this.initialMulticaster.multicastEvent(new ApplicationEnvironmentPreparedEvent( this.application, this.args, environment));&#125; 创建Spring上下文根据 WebApplicactionType的类型，对应创建： AnnotationConfigApplicationContext AnnotationConfigServletWebServerApplicationContext AnnotationConfigReactiveWebServerApplicationContext12345678910111213141516171819202122232425262728public static final String DEFAULT_CONTEXT_CLASS = "org.springframework.context." + "annotation.AnnotationConfigApplicationContext";public static final String DEFAULT_SERVLET_WEB_CONTEXT_CLASS = "org.springframework.boot." + "web.servlet.context.AnnotationConfigServletWebServerApplicationContext";public static final String DEFAULT_REACTIVE_WEB_CONTEXT_CLASS = "org.springframework." + "boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext";protected ConfigurableApplicationContext createApplicationContext() &#123; Class&lt;?&gt; contextClass = this.applicationContextClass; if (contextClass == null) &#123; try &#123; switch (this.webApplicationType) &#123; case SERVLET: contextClass = Class.forName(DEFAULT_SERVLET_WEB_CONTEXT_CLASS); break; case REACTIVE: contextClass = Class.forName(DEFAULT_REACTIVE_WEB_CONTEXT_CLASS); break; default: contextClass = Class.forName(DEFAULT_CONTEXT_CLASS); &#125; &#125; ... &#125; return (ConfigurableApplicationContext) BeanUtils.instantiateClass(contextClass);&#125; Spring上下文前置处理12345678910111213141516171819202122232425262728293031323334private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; context.setEnvironment(environment); // 为上下文配置Bean生成器以及资源加载器(如果它们非空) ？？ 用途待明确 postProcessApplicationContext(context); // 调用初始化器 applyInitializers(context); // 触发Spring Boot启动过程的contextPrepared事件 listeners.contextPrepared(context); if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // Add boot specific singleton beans // 添加两个Spring Boot中的特殊单例Beans - springApplicationArguments以及springBootBanner ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); beanFactory.registerSingleton("springApplicationArguments", applicationArguments); if (printedBanner != null) &#123; beanFactory.registerSingleton("springBootBanner", printedBanner); &#125; if (beanFactory instanceof DefaultListableBeanFactory) &#123; ((DefaultListableBeanFactory) beanFactory) .setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; // Load the sources // 加载sources - 对于DemoApplication而言，这里的sources集合只包含了它一个class对象 Set&lt;Object&gt; sources = getAllSources(); Assert.notEmpty(sources, "Sources must not be empty"); // 加载动作 - 构造BeanDefinitionLoader并完成Bean定义的加载 load(context, sources.toArray(new Object[0])); // 触发Spring Boot启动过程的contextLoaded事件 listeners.contextLoaded(context);&#125; 执行 applyInitializers(context)调用 ApplicationContextInitializer.initialize(..)适用于执行ConfigurableApplicationContext#refresh()前，需要通过代码执行初始化 ConfigurableApplicationContext的场景； refreshContext(context)调用 AbstractApplicationContext#refresh 方法刷新applicationContext1234567891011121314151617// 增加可能的context配置后，需要刷新applicationContextprivate void refreshContext(ConfigurableApplicationContext context) &#123; refresh(context); if (this.registerShutdownHook) &#123; try &#123; context.registerShutdownHook(); &#125; catch (AccessControlException ex) &#123; // Not allowed in some environments. &#125; &#125;&#125;protected void refresh(ApplicationContext applicationContext) &#123; Assert.isInstanceOf(AbstractApplicationContext.class, applicationContext); ((AbstractApplicationContext) applicationContext).refresh();&#125; context刷新后实现12345// 刷新 applicationContextafterRefresh(context, applicationArguments);// 启动监听器listeners.started(context);callRunners(context, applicationArguments); afterRefresh默认是一个空实现123protected void afterRefresh(ConfigurableApplicationContext context, ApplicationArguments args) &#123;&#125; 启动Runner启动 ApplicationRunner，CommandLineRunner 类型的Runner； ApplicationRunner CommandLineRunner两个Runner的差别是，一个接收参数是原始的 String...，一个是解析后的 ApplicationArguments12345678910111213141516171819202122232425262728293031323334353637/** * Interface used to indicate that a bean should &lt;em&gt;run&lt;/em&gt; when it is contained within * a &#123;@link SpringApplication&#125;. Multiple &#123;@link ApplicationRunner&#125; beans can be defined * within the same application context and can be ordered using the &#123;@link Ordered&#125; * interface or &#123;@link Order @Order&#125; annotation. * @see CommandLineRunner */@FunctionalInterfacepublic interface ApplicationRunner &#123; /** * Callback used to run the bean. * @param args incoming application arguments * @throws Exception on error */ void run(ApplicationArguments args) throws Exception;&#125;/** * Interface used to indicate that a bean should &lt;em&gt;run&lt;/em&gt; when it is contained within * a &#123;@link SpringApplication&#125;. Multiple &#123;@link CommandLineRunner&#125; beans can be defined * within the same application context and can be ordered using the &#123;@link Ordered&#125; * interface or &#123;@link Order @Order&#125; annotation. * &lt;p&gt; * If you need access to &#123;@link ApplicationArguments&#125; instead of the raw String array * consider using &#123;@link ApplicationRunner&#125;. * @see ApplicationRunner */@FunctionalInterfacepublic interface CommandLineRunner &#123; /** * Callback used to run the bean. * @param args incoming main method arguments * @throws Exception on error */ void run(String... args) throws Exception;&#125; Spring启动阶段可执行扩展 初始化器(Initializer) 监听器(Listener) 容器刷新后置Runners(ApplicationRunner或者CommandLineRunner接口的实现类) 启动期间在Console打印Banner的具体实现类 附加getSpringFactoriesInstances获取配置中指定类型的类名列表，并完成实例化；方法入口getSpringFactoriesInstances，从 META-INF/spring.factories 文件中读取 key 为指定类全路径名的配置数据；1234567891011121314151617181920212223242526272829303132private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; ClassLoader classLoader = getClassLoader(); // Use names and ensure unique to protect against duplicates Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;( SpringFactoriesLoader.loadFactoryNames(type, classLoader)); List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances;&#125;private &lt;T&gt; List&lt;T&gt; createSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, ClassLoader classLoader, Object[] args, Set&lt;String&gt; names) &#123; List&lt;T&gt; instances = new ArrayList&lt;&gt;(names.size()); for (String name : names) &#123; try &#123; Class&lt;?&gt; instanceClass = ClassUtils.forName(name, classLoader); Assert.isAssignable(type, instanceClass); Constructor&lt;?&gt; constructor = instanceClass .getDeclaredConstructor(parameterTypes); T instance = (T) BeanUtils.instantiateClass(constructor, args); instances.add(instance); &#125; catch (Throwable ex) &#123; throw new IllegalArgumentException( "Cannot instantiate " + type + " : " + name, ex); &#125; &#125; return instances;&#125;]]></content>
      <tags>
        <tag>spring boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot Annotation]]></title>
    <url>%2F2019%2F01%2F11%2Fspring-boot-annotation%2F</url>
    <content type="text"><![CDATA[spring boot annotation annotation@SpringBootApplication@SpringBootApplication = @SpringBootConfiguration + @EnableAutoConfiguration + @ComponentScan123456789101112@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; // ...&#125; @SpringBootConfiguration实际上和@Configuration有相同的作用，配备了该注解的类就能够以JavaConfig的方式完成一些配置，可以不再使用XML配置。123456@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Configurationpublic @interface SpringBootConfiguration &#123;&#125; @ComponentScan这个注解完成的是自动扫描的功能，相当于Spring XML配置文件中的：1&lt;context:component-scan&gt; 可以使用basePackages属性指定要扫描的包，以及扫描的条件。如果不设置的话，默认扫描@ComponentScan注解所在类的同级类和同级目录下的所有类，所以对于一个Spring Boot项目，一般会把入口类放在顶层目录中，这样就能够保证源码目录下的所有类都能够被扫描到。 1234567@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Repeatable(ComponentScans.class)public @interface ComponentScan &#123; ...&#125; @EnableAutoConfiguration让Spring Boot的配置能够如此简化的关键性注解。123456789101112131415161718192021@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = "spring.boot.enableautoconfiguration"; /** * Exclude specific auto-configuration classes such that they will never be applied. * @return the classes to exclude */ Class&lt;?&gt;[] exclude() default &#123;&#125;; /** * Exclude specific auto-configuration class names such that they will never be * applied. * @return the class names to exclude * @since 1.3.0 */ String[] excludeName() default &#123;&#125;;&#125;]]></content>
      <tags>
        <tag>spring-boot</tag>
        <tag>annotation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JPDA Java调试体系]]></title>
    <url>%2F2019%2F01%2F10%2Fjpda%2F</url>
    <content type="text"><![CDATA[JPDA 概述 Java Platform Debugger ArchitectureJPDA 就是虚拟机的一整套用于调试的工具和接口。 JPDA 是 Java平台调试体系结构的缩写，通过JPDA提供的API，开发人员可以方便灵活的搭建 Java 调试应用程序。 Java 程序都是运行在 Java 虚拟机上的，要调试 Java 程序，事实上就需要向 Java 虚拟机请求当前运行态的状态，并对虚拟机发出一定的指令，设置一些回调等等。 通过 JPDA 这套接口，我们就可以开发自己的调试工具。通过这些 JPDA 提供的接口和协议，调试器开发人员就能根据特定开发者的需求，扩展定制 Java 调试应用程序，开发出吸引开发人员使用的调试工具。前面我们提到的 IDE 调试工具都是基于 JPDA 体系开发的，区别仅仅在于它们可能提供了不同的图形界面、具有一些不同的自定义功能。另外，我们要注意的是，JPDA 是一套标准，任何的 JDK 实现都必须完成这个标准，因此，通过 JPDA 开发出来的调试工具先天具有跨平台、不依赖虚拟机实现、JDK 版本无关等移植优点，因此大部分的调试工具都是基于这个体系的。 JPDA is a multi-tiered debugging architecture that allows tools developers to easily create debugger applications which run portably across platforms.JPDA是一个多层的调试架构，允许开发人员可以便捷的创建跨平台的调试工具。 JPDA 组成部分 JPDA = JVM TI + JWP + JDI可以仅基于其中的某一个模块开发自己的应用（而不是使用完整的三个部分） 1234567891011121314151617Java Platform Debugger Architecture (JPDA) Components Debugger Interfaces / |--------------| / | VM | debuggee ----( |--------------| &lt;------- JVM TI - Java VM Tool Interface \ | back-end | \ |--------------| / | comm channel -( | &lt;--------------- JDWP - Java Debug Wire Protocol（调试通道） \ | / |--------------| / | front-end | debugger ----( |--------------| &lt;------- JDI - Java Debug Interface \ | UI | \ |--------------| 模块 层次 编程语言 作用 JVM TI 底层 C 获取及控制当前虚拟机状态 JDWP 中介层 C 定义 JVMTI 和 JDI 交互的数据格式 JDI 高层 Java 提供 Java API 来远程控制被调试虚拟机 Java Platform Debugger Architecture，JPDA中包含如下组件： JVM TI (Java VM Tool Interface) Java虚拟机工具接口一套由虚拟机直接提供的 native 接口（A native interface implemented by the VM.）； 处于整个 JPDA 体系的最底层：所有调试功能本质上都需要通过 JVMTI 来提供。查看 Java 所有状态。包括但不限于：JVM分析、监控、调试、线程分析以及覆盖率分析等功能。由JVM提供，与具体语言无关；取代了原有的 JVMDI 和 JVMPI； JDWP (Java Debug Wire Protocol) Java调试线协议 ( 一个通道 )为 Java 调试而设计的一个通讯交互协议；定义 debuggee 和 debugger processes 之间传递信息的格式； 在 JPDA 体系中，作为前端（front-end）的调试者（debugger）进程和后端（back-end）的被调试程序（debuggee）进程之间的交互数据的格式就是由 JDWP 来描述的，它详细完整地定义了请求命令、回应数据和错误代码，保证了前端和后端的 JVMTI 和 JDI 的通信通畅。比如在 Sun 公司提供的实现中，它提供了一个名为 jdwp.dll（jdwp.so）的动态链接库文件，这个动态库文件实现了一个 Agent，它会负责解析前端发出的请求或者命令，并将其转化为 JVMTI 调用，然后将 JVMTI 函数的返回值封装成 JDWP 数据发还给后端。 另外，这里需要注意的是 JDWP 本身并不包括传输层的实现，传输层需要独立实现，但是 JDWP 包括了和传输层交互的严格的定义，就是说，JDWP 协议虽然不规定我们是通过 EMS 还是快递运送货物的，但是它规定了我们传送的货物的摆放的方式。在 Sun 公司提供的 JDK 中，在传输层上，它提供了 socket 方式，以及在 Windows 上的 shared memory 方式。当然，传输层本身无非就是本机内进程间通信方式和远端通信方式，用户有兴趣也可以按 JDWP 的标准自己实现。 JDI (Java Debug Interface) Java调试接口三个模块中最高层的接口，在多数的 JDK 中，它是由 Java 语言实现的；在多数的 JDK 中，它是由 Java 语言实现的。 JDI 由针对前端定义的接口组成，通过它，调试工具开发人员就能通过前端虚拟机上的调试器来远程操控后端虚拟机上被调试程序的运行，JDI 不仅能帮助开发人员格式化 JDWP 数据，而且还能为 JDWP 数据传输提供队列、缓存等优化服务。从理论上说，开发人员只需使用 JDWP 和 JVMTI 即可支持跨平台的远程调试，但是直接编写 JDWP 程序费时费力，而且效率不高。因此基于 Java 的 JDI 层的引入，简化了操作，提高了开发人员开发调试程序的效率。 可以理解为 Java 语言实现的 Debug Inteface，Java 程序员可以直接通过接口编写远程调试工具，有很多的IDEA的远程调试功能底层就是通过调用JDI接口实现的。 JVM TIJVM TI (Java VM Tool Interface) JVM 工具接口是 JVM 提供的一个非常强大的对 JVM 操作的工具接口，通过这个接口，我们可以实现对 JVM 多种组件的操作，从 JVM TI (Java VM Tool Interface) 这里我们认识到 JVM TI 的强大，它包括了对虚拟机堆内存、类、线程等各个方面的管理接口。 JVM TI (Java VM Tool Interface) 通过事件机制，通过接口注册各种事件勾子，在 JVM 事件触发时同时触发预定义的勾子，以实现对各个 JVM 事件的感知和反应。 废弃 JPDA补充 JVM TI implementations on multiple VMs (see VM documentation). A back-end which uses JVM TI to implement the debuggee side of JDWP. A front-end which uses the debugger side of JDWP to implement JDI. Two simple example debugger applications which are built on JDI.]]></content>
      <tags>
        <tag>jvm</tag>
        <tag>jpda</tag>
        <tag>jvm ti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MANIFEST of Java Project]]></title>
    <url>%2F2019%2F01%2F09%2Fmanifest-of-java-project%2F</url>
    <content type="text"><![CDATA[MANIFEST属性：Premain-Class，Agent-Class，Launcher-Agent-Class，Boot-Class-Path，Can-Redefine-Classes，Can-Retransform-Classes，Can-Set-Native-Method-Prefix MANIFEST 属性说明Premain-ClassWhen an agent is specified at JVM launch time this attribute specifies the agent class. That is, the class containing the premain method. When an agent is specified at JVM launch time this attribute is required. If the attribute is not present the JVM will abort. Note: this is a class name, not a file name or path. Agent-ClassIf an implementation supports a mechanism to start agents sometime after the VM has started then this attribute specifies the agent class. That is, the class containing the agentmain method. This attribute is required if it is not present the agent will not be started. Note: this is a class name, not a file name or path. Launcher-Agent-ClassIf an implementation supports a mechanism to start an application as an executable JAR then the main manifest may include this attribute to specify the class name of an agent to start before the application main method is invoked. Boot-Class-PathA list of paths to be searched by the bootstrap class loader. Paths represent directories or libraries (commonly referred to as JAR or zip libraries on many platforms). These paths are searched by the bootstrap class loader after the platform specific mechanisms of locating a class have failed. Paths are searched in the order listed. Paths in the list are separated by one or more spaces. A path takes the syntax of the path component of a hierarchical URI. The path is absolute if it begins with a slash character (‘/‘), otherwise it is relative. A relative path is resolved against the absolute path of the agent JAR file. Malformed and non-existent paths are ignored. When an agent is started sometime after the VM has started then paths that do not represent a JAR file are ignored. This attribute is optional. Can-Redefine-ClassesBoolean (true or false, case irrelevant). Is the ability to redefine classes needed by this agent. Values other than true are considered false. This attribute is optional, the default is false. Can-Retransform-ClassesBoolean (true or false, case irrelevant). Is the ability to retransform classes needed by this agent. Values other than true are considered false. This attribute is optional, the default is false. Can-Set-Native-Method-PrefixBoolean (true or false, case irrelevant). Is the ability to set native method prefix needed by this agent. Values other than true are considered false. This attribute is optional, the default is false.]]></content>
  </entry>
  <entry>
    <title><![CDATA[初识 java.lang.instrument 包]]></title>
    <url>%2F2019%2F01%2F07%2Fjava-lang-instrument%2F</url>
    <content type="text"><![CDATA[java.lang.instrument包，VirtualMachine, InstrumentationImpl, ClassFileTransformer，及实现原理；启动Agent的三种方式 命令行启动：-javaagent VM进程启动后运行加载Agent 在可执行的jar包中包含agent 初识 instrumentPackage java.lang.instrument Provides services that allow Java programming language agents to instrument programs running on the JVM. The mechanism for instrumentation is modification of the byte-codes of methods.An agent is deployed as a JAR file. An attribute in the JAR file manifest specifies the agent class which will be loaded to start the agent. Java Instrument能做什么？最大的作用？ 使开发者可以构建一个独立于应用程序的代理程序Agent，用来监控和协助运行在JVM上的程序，更重要的是能够替换和修改某些类的定义； 最大的作用：可以实现一种虚拟机级别支持的AOP实现方式； 在JDK 1.5 、1.6中，Java Instrument做了哪些变动支持？ JDK 1.5：支持 静态 Instrument，就是在JVM启动前静态设置Instrument； JDK 1.6：支持 动态 Instrument，就是在JVM启动后动态设置Instrument；支持本地代码Instrument；支持动态改变classpath； Java Instrument的实现是基于JVM哪种机制？JVM TI是什么，可以做什么？ 基于JVMTI代理程序；JVM TI：一套代理程序机制，为JVM相关工具提供的本地编程接口集合；JVM TI可以支持第三方工具程序以代理的方式连接和访问JVM，并利用JVMTI提供的丰富的编程接口，完成很多跟JVM相关的功能； premain、agentmain方法执行时机？ premain执行时机在JVM启动时，初始化函数eventHandlerVMinit会调用sun.instrument.InstrumentationImpl类的loadClassAndCallPremain方法，执行Premain-Class指定类的premain方法； agentmain执行时机在JVM启动后，通过 com.sun.tools.attach.VirtualMachine.loadAgent 附着一个Instrument，如：vm.loadAgent(jar)，会调用sun.instrument.InstrumentationImpl类的loadClassAndCallAgentmain方法去执行Agentmain-Class指定类的agentmain方法； premain、agentmain方法中两个参数agentArgs、inst代表什么？分别会有什么作用？ agentArgs代理程序命令行中输入参数，随同-javaagent一起传入，与main函数不同的是，这个参数是一个 字符串 而不是一个字符串数组； instjava.lang.instrument.Instrumentation实例，由JVM自动传入，集中了几乎所有功能方法，如：类操作、classpath操作等； java.lang.instrument.ClassFileTransformer是什么，有什么作用？ ClassFileTransformer 当中的 transform 方法可以对类定义进行操作修改； 在类字节码载入JVM前，JVM会调用ClassFileTransformer.transform 方法，从而实现对类定义进行操作修改，实现AOP功能；相对于JDK 动态代理、CGLIB等AOP实现技术，不会生成新类，也不需要原类有接口； 对于agentmain方法执行，如何进行动态attach agent？ 通过VirtualMachine 加载一个 Agent，如：vm.loadAgent(jar)； META-INF/MAINFEST.MF参数清单？ Premain-Class：指定包含premain方法的类名； Agent-Class：指定包含agentmain方法的类名； Boot-Class-Path：指定引导类加载器搜索的路径列表。查找类的特点于平台的机制失败后，引导类加载器会搜索这些路径； Can-Redefine-Class：是否能重新定义此代理所需的类，默认为false； Can-Retransform-Class：是否能重新转换此代理所需的类，默认为false； Can-Set-Native-Method-Prefix：是否能设置此代理所需的本机方法前缀，默认值为false； 两个核心API ClassFileTransformer、Instrumention？ ClassFileTransformer：定义了类加载前的预处理类； Instrumentation：增强器 add/removeTransformer：添加/删除 ClasFileTransformer； retransformerClasses：指定哪些类，在已加载的情况下，重新进行转换处理，即触发重新加载类定义；对于重新加载的类不能修改旧有的类声明，比如：不能增加属性、不能修改方法声明等； redefineClasses：指定哪些类，触发重新加载类定义，与上面不同的是不会重新进行转换处理，而是把处理结果bytecode直接给JVM； getAllLoadedClasses：获取当前已加载的Class集合； getInitiatedClasses：获取由某个特定ClassLoader加载的类定义； getObjectSize：获得一个对象占用的空间大小 appendToBootstrapClassLoaderSearch/appentToSystemClassLoaderSearch：增加BootstrapClassLoader/SystemClassLoader搜索路径； isNativeMethodPrefixSupported/SetNativeMethodPrefix：判断JVM是否支持拦截Native Method； Java Instrument工作原理实现原理 在JVM启动时，通过JVM参数-javaagent，传入agent jar，Instrument Agent被加载； 在Instrument Agent 初始化时，注册了 JVM TI 初始化函数 eventHandlerVMInit； 在JVM启动时，会调用初始化函数eventHandlerVMInit，启动了Instrument Agent，用sun.instrument.InstrumentationImpl类里的方法loadClassAndCallPremain方法去初始化Premain-Class指定类的premain` 方法； 初始化函数eventHandlerVMinit，注册了class解析的ClassFileLoadHook函数； 在解析Class之前，JVM调用 JVM TI 的 ClassFileLoadHook 函数，钩子函数调用sun.instrument.InstrumentationImpl类里的transform方法，通过TransformerManager的transformer方法最终调用我们自定义（Custom）的Transformer类的transform方法； 因为字节码在解析Class之前改的，直接使用修改后的字节码的数据流替代，最后进入Class解析，对整个Class解析无影响； 重新加载Class依然重新走5-6步骤； 支持回调的两个阶段 依赖函数依赖函数 eventHandlerVMInit， eventHandlerClassFileLoadHook说明；12345678910111213141516171819202122232425/* * src/java.instrument/share/native/libinstrument/InvocationAdapter.c * JVMTI callback support * * We have two "stages" of callback support. * At OnLoad time, we install a VMInit handler. * When the VMInit handler runs, we remove the VMInit handler and install a * ClassFileLoadHook handler. */void JNICALLeventHandlerVMInit( jvmtiEnv * jvmtienv, JNIEnv * jnienv, jthread thread) &#123; void JNICALLeventHandlerClassFileLoadHook( jvmtiEnv * jvmtienv, JNIEnv * jnienv, jclass class_being_redefined, jobject loader, const char* name, jobject protectionDomain, jint class_data_len, const unsigned char* class_data, jint* new_class_data_len, unsigned char** new_class_data) &#123; 启动 Agent 的三种方式命令行启动Agent在命令行中增加option：1-javaagent:&lt;jarpath&gt;[=&lt;options&gt;] VM 启动后运行 AgentAgent在可执行的jar包中MANIFEST 中需要包含 Launcher-Agent-Class 编写 Agent在三种启动方式中，都需要预先生成 Agent 的 jar 包。 Agent 的 jar 包的MANIFEST.MF文件中，必须包含 Agent-class 属性，指明 agent class。 agent class必须实现 public static agentmain 方法； Agent 类方法agentmain方法拥有以下两种重构形态，JVM会首先尝试访问双参数的方法，访问失败后，会尝试访问单参数的函数版本；12public static void agentmain(String agentArgs, Instrumentation inst)public static void agentmain(String agentArgs) 如果通过命令行方式启动agent，agent class可能包含 premain 方法；当agent晚于VM启动时，不会访问 premain 方法；agent 通过 agentArgs 参数，传递 option 参数 生成 MANIFESTMANIFEST 文档配置META-INF -&gt; MANIFEST.MF 文件中，12345Agent-Class: $&#123;full-path-of-Agent-class&#125;Can-Redefine-Classes: trueCan-Retransform-Classes: trueManifest-Version: 1.0Permissions: all-permissions 通过 Maven 插件生成12345678910111213141516171819202122232425262728293031323334353637383940&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifestEntries&gt; &lt;Agent-Class&gt;$&#123;full-path-of-Agent-class&#125;&lt;/Agent-Class&gt; &lt;Can-Redefine-Classes&gt;true&lt;/Can-Redefine-Classes&gt; &lt;Can-Retransform-Classes&gt;true&lt;/Can-Retransform-Classes&gt; &lt;Manifest-Version&gt;1.0&lt;/Manifest-Version&gt; &lt;Permissions&gt;all-permissions&lt;/Permissions&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;8&lt;/source&gt; &lt;target&gt;8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 其中 maven-compiler-plugin 的配置不是必须的，但是由于Agent需要区分1.6前或1.6后，所以建议指定jdk的版本；执行 mvn clean package 后，生成的jar包为 \*-jar-with-dependencies.jar 补充 The agentmain method should do any necessary initialization required to start the agent. When startup is complete the method should return. If the agent cannot be started (for example, because the agent class cannot be loaded, or because the agent class does not have a conformant agentmain method), the JVM will not abort. If the agentmain method throws an uncaught exception it will be ignored (but may be logged by the JVM for troubleshooting purposes).]]></content>
      <tags>
        <tag>jvm</tag>
        <tag>javaagent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java动态字节码技术]]></title>
    <url>%2F2019%2F01%2F03%2Fjava-dynamic-bytecode%2F</url>
    <content type="text"><![CDATA[读、写、修改字节码（byte code）；基于 ASM 的 ClassReader， ClassWriter， ClassVisitor 自定义类转换器，供JVM加载重新生成后的字节码（byte code）；通过java类库 instrument，JVM通过加载 ClassFileTransformer.transform() 方法返回的 byte[]，实现重新加载； JVM调用自定义类转换器的实现方式（JVM TI，JPDA组成部分）；基于JVM TI，使用自定义的VM Agent 本文所有jdk文档，均使用jdk10 简单来说动态字节码技术：如何改变原有代码的行为 修改字节码 + 重新加载字节码 读、写、修改字节码1TestClassVisitor 读写字节码常见工具：BCEL、Javassist、ASM（使用Visitor模式接口）、CGLib（底层为ASM实现）此处关注通过ASM对字节码进行读写和修改；实现代码见页尾； ASM 使用方式ASM实现中采用访问者模式（Visitor Pattern），ASM 将对代码的读取和操作都包装成一个访问者，在解析 JVM 加载到的字节码时调用。核心入口为以下三个类：ClassReader， ClassWriter， ClassVisitor ClassReader 是 ASM 代码的入口，通过它解析二进制字节码，实例化时它时，我们需要传入一个 ClassVisitor，在这个 Visitor 里，我们可以实现 visitMethod()/visitAnnotation() 等方法，用以定义对类结构（如方法、字段、注解）的访问方法。 而 ClassWriter 接口继承了 ClassVisitor 接口，我们在实例化类访问器时，将 ClassWriter “注入” 到里面，以实现对类写入的声明。 使用插件获得字节码 Q：如何快速生成asm代码？A：ASM Bytecode Outline 插件，当前较新的版本是 ASM Bytecode Outline 2017 编译后，在指定的类上右键选择 Show bytecode Outline 自定义类转换器1TestTransformer 为实现JVM动态加载修改后的字节码，可以依靠 java 的类库 instrument，通过instrument 类库可以修改已加载的类文件； 版本差别 1.6前 只能在 JVM 刚启动开始加载类时生效 1.6后（含1.6） 支持了在运行时对类定义的修改 使用instrument要使用 instrument 的类修改功能，我们需要实现它的 ClassFileTransformer 接口定义一个类文件转换器。它唯一的一个 transform() 方法会在类文件被加载时调用，在 transform 方法里，我们可以对传入的二进制字节码进行改写或替换，生成新的字节码数组后返回，JVM 会使用 transform 方法返回的字节码数据进行类的加载。 JVM调用类转换器的机制1TestAgent， Attacher 我们可以通过JVM TI 加载修改后的字节码，此处使用 Java Agent 实现 参考 java.lang.instrument, Agent 源码源码汇总TransformTargetTransformTarget 是要被修改的目标类，正常执行时，它会三秒输出一次 “hello”。12345678910111213141516public class TransformTarget &#123; public static void main(String[] args) &#123; while (true) &#123; try &#123; Thread.sleep(3000L); &#125; catch (Exception e) &#123; break; &#125; printSomething(); &#125; &#125; public static void printSomething() &#123; System.out.println("hello"); &#125;&#125; Agent 及打包方式Agent 是执行修改类的主体，它使用 ASM 修改 TransformTarget 类的方法，并使用 instrument 包将修改提交给 JVM。入口类，也是代理的 Agent-Class。1234567891011public class TestAgent &#123; public static void agentmain(String args, Instrumentation inst) &#123; inst.addTransformer(new TestTransformer(), true); try &#123; inst.retransformClasses(TransformTarget.class); System.out.println("Agent Load Done."); &#125; catch (Exception e) &#123; System.out.println("agent load failed!"); &#125; &#125;&#125; 执行字节码修改和转换的类。123456789101112131415161718192021222324252627282930313233343536373839public class TestTransformer implements ClassFileTransformer &#123; public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException &#123; System.out.println("Transforming " + className); ClassReader reader = new ClassReader(classfileBuffer); ClassWriter classWriter = new ClassWriter(ClassWriter.COMPUTE_FRAMES); ClassVisitor classVisitor = new TestClassVisitor(Opcodes.ASM5, classWriter); reader.accept(classVisitor, ClassReader.SKIP_DEBUG); return classWriter.toByteArray(); &#125; class TestClassVisitor extends ClassVisitor implements Opcodes &#123; TestClassVisitor(int api, ClassVisitor classVisitor) &#123; super(api, classVisitor); &#125; @Override public MethodVisitor visitMethod(int access, String name, String desc, String signature, String[] exceptions) &#123; MethodVisitor mv = super.visitMethod(access, name, desc, signature, exceptions); if (name.equals("printSomething")) &#123; mv.visitCode(); Label l0 = new Label(); mv.visitLabel(l0); mv.visitLineNumber(19, l0); mv.visitFieldInsn(Opcodes.GETSTATIC, "java/lang/System", "out", "Ljava/io/PrintStream;"); mv.visitLdcInsn("bytecode replaced!"); mv.visitMethodInsn(Opcodes.INVOKEVIRTUAL, "java/io/PrintStream", "println", "(Ljava/lang/String;)V", false); Label l1 = new Label(); mv.visitLabel(l1); mv.visitLineNumber(20, l1); mv.visitInsn(Opcodes.RETURN); mv.visitMaxs(2, 0); mv.visitEnd(); TransformTarget.printSomething(); &#125; return mv; &#125; &#125;&#125; Agent打包Maven插件12345678910111213141516171819202122232425262728293031&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifestEntries&gt; &lt;Agent-Class&gt;$&#123;full-path-of-Agent-class&#125;&lt;/Agent-Class&gt; &lt;Can-Redefine-Classes&gt;true&lt;/Can-Redefine-Classes&gt; &lt;Can-Retransform-Classes&gt;true&lt;/Can-Retransform-Classes&gt; &lt;Manifest-Version&gt;1.0&lt;/Manifest-Version&gt; &lt;Permissions&gt;all-permissions&lt;/Permissions&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;8&lt;/source&gt; &lt;target&gt;8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; Edit configuration Attacher123456public class Attacher &#123; public static void main(String[] args) throws AttachNotSupportedException, IOException, AgentLoadException, AgentInitializationException &#123; VirtualMachine vm = VirtualMachine.attach("$&#123;TransformTarget进程的PID&#125;"); vm.loadAgent("$&#123;/path/to/TestAgent.jar&#125;"); &#125;&#125; 源码执行方式前置准备打包 Agent； 启动顺序 启动 TransformTarget； 查询 TransformTarget 的进程号，更新 Attacher 中的进程ID并启动；执行结果]]></content>
      <tags>
        <tag>jvm</tag>
        <tag>字节码</tag>
        <tag>bytecode</tag>
        <tag>btrace</tag>
        <tag>visitor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Editor 使用相关]]></title>
    <url>%2F2018%2F12%2F29%2Fhexo-editor%2F</url>
    <content type="text"><![CDATA[HexoEditor基本使用配置HexoEdtor主页 图片本地存储于上传图片快照及上传流程 创建本地存储文件夹1ln -s /tmp/hexoEditor ~/Documents/HexoEditor/picTmp Hexo模式设置 -&gt; Hexo -&gt; Hexo模式预览时是否展示以下Hexo Header信息 shortcutShortCut Key Method explanation Tab tabAdd add indentation Shift - Tab tabSubtract reduce indentation Ctrl - B toggleBlod toggle blod Ctrl - I toggleItalic toggle italic Ctrl - D toggleDelete delete current line Ctrl - ` toggleComment toggle comment Ctrl - L toggleUnOrderedList toggle unordered list Ctrl - Alt - L toggleOrderedList toggle ordered list Ctrl - ] toggleHeader downgrade title Ctrl - [ toggleUnHeader upgrade title Ctrl - = toggleBlockquote add blockquote Ctrl - - toggleUnBlockquote reduce blockquote Ctrl - U drawLink add hyperlink Ctrl - Alt - U drawImageLink add image Ctrl - T drawTable(row col) add table(row column) Ctrl - V pasteOriginContent paste origin content Shift - Ctrl - V pasteContent auto paste content Alt - F formatTables format tables Ctrl - N new md document Ctrl - H new hexo document Ctrl - O open md document Ctrl - S save md document Shift - Ctrl - S save as Alt - Ctrl - S open settings Ctrl - W toggle write mode Ctrl - P toggle preview mode Ctrl - R toggle read mode tip: In mac OS, plase replace Ctrl key with Cmd key.]]></content>
      <tags>
        <tag>hexo</tag>
        <tag>next theme</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 字节码]]></title>
    <url>%2F2018%2F12%2F17%2FJava-byte-code%2F</url>
    <content type="text"></content>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
        <tag>byte code</tag>
        <tag>字节码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C语言 函数指针 & 指针函数]]></title>
    <url>%2F2018%2F12%2F17%2FC-Pointer-Function-and-Function-Pointer%2F</url>
    <content type="text"><![CDATA[C语言中，指针函数（Pointer Function）与函数指针（Function Pointer） 指针函数=返回指针的函数：int *func(int a, int b); 声明的是一个函数； 函数的返回类型是指针 函数指针=指向函数的指针：void (*func)(int a, int b); 声明的是一个指针； 一般指针：指向一个变量的内存地址；函数指针：指向一个函数的首地址； 1234567-- 函数指针的使用方式// 定义一个函数指针 funcvoid (*func)(int a, int b);// 声明一个函数原型 addvoid add(int x, int y);// 为函数指针赋值：将add()函数首地址赋值给func指针func = add;]]></content>
      <tags>
        <tag>C</tag>
        <tag>Function Pointer</tag>
        <tag>Pointer Function</tag>
        <tag>函数指针</tag>
        <tag>指针函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的索引和锁]]></title>
    <url>%2F2018%2F07%2F24%2Findex-and-lock-of-mysql%2F</url>
    <content type="text"><![CDATA[索引通常来说，索引能做什么： 索引可以加快数据库的检索速度 表经常进行INSERT/UPDATE/DELETE操作就不要建立索引了，换言之：索引会降低插入、删除、修改等维护任务的速度。 索引需要占物理和数据空间。 了解过索引的最左匹配原则 知道索引的分类：聚集索引和非聚集索引 Mysql支持Hash索引和B+树索引两种 看起来好像啥都知道，但面试让你说的时候可能就GG了： 使用索引为什么可以加快数据库的检索速度啊？ 为什么说索引会降低插入、删除、修改等维护任务的速度。 索引的最左匹配原则指的是什么？ Hash索引和B+树索引有什么区别？主流的使用哪一个比较多？InnoDB存储都支持吗？ 聚集索引和非聚集索引有什么区别？ …….. 聊聊索引的基础知识首先Mysql的基本存储结构是页(记录都存在页里边)： 各个数据页可以组成一个双向链表 而每个数据页中的记录又可以组成一个单向链表 每个数据页都会为存储在它里边儿的记录生成一个页目录，在通过主键查找某条记录的时候可以在页目录中使用二分法快速定位到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定的记录 以其他列(非主键)作为搜索条件：只能从最小记录开始依次遍历单链表中的每条记录。 所以说，如果我们写select * from user where username = &#39;anocelot&#39;这样没有进行任何优化的sql语句，默认会这样做： 定位到记录所在的页 最左匹配原则–需要遍历双向链表，找到所在的页 从所在的页内中查找相应的记录 由于不是根据主键查询，只能遍历所在页的单链表了 很明显，在数据量很大的情况下这样查找会很慢！ 索引提高检索速度索引做了些什么可以让我们查询加快速度呢？ 其实就是将无序的数据变成有序(相对)： 要找到id为8的记录简要步骤： 很明显的是：没有用索引我们是需要遍历双向链表来定位对应的页，现在通过“目录”就可以很快地定位到对应的页上了！ 其实底层结构就是B+树，B+树作为树的一种实现，能够让我们很快地查找出对应的记录。 索引降低增删改的速度B+树是平衡树的一种。 平衡树：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。 如果一棵普通的树在极端的情况下，是能退化成链表的(树的优点就不复存在了) B+树是平衡树的一种，是不会退化成链表的，树的高度都是相对比较低的(基本符合矮矮胖胖(均衡)的结构)【这样一来我们检索的时间复杂度就是O(logn)】！从上一节的图我们也可以看见，建立索引实际上就是建立一颗B+树。 B+树是一颗平衡树，如果我们对这颗树增删改的话，那肯定会破坏它的原有结构。 要维持平衡树，就必须做额外的工作。正因为这些额外的工作开销，导致索引会降低增删改的速度 哈希索引除了B+树之外，还有一种常见的是哈希索引。 哈希索引就是采用一定的哈希算法，把键值换算成新的哈希值，检索时不需要类似B+树那样从根节点到叶子节点逐级查找，只需一次哈希算法即可立刻定位到相应的位置，速度非常快。 本质上就是把键值换算成新的哈希值，根据这个哈希值来定位。 看起来哈希索引很牛逼啊，但其实哈希索引有好几个局限(根据他本质的原理可得)： 哈希索引也没办法利用索引完成排序 不支持最左匹配原则 在有大量重复键值情况下，哈希索引的效率也是极低的—-&gt;哈希碰撞问题。 不支持范围查询 InnoDB支持哈希索引吗？主流的还是使用B+树索引比较多，对于哈希索引，InnoDB是自适应哈希索引的（hash索引的创建由InnoDB存储引擎引擎自动优化创建，我们干预不了）！ 聚集和非聚集索引简单概括： 聚集索引就是以主键创建的索引 非聚集索引就是以非主键创建的索引 区别： 聚集索引在叶子节点存储的是表中的数据 非聚集索引在叶子节点存储的是主键和索引列 使用非聚集索引查询出数据时，拿到叶子上的主键再去查到想要查找的数据。(拿到主键再查找这个过程叫做回表) 非聚集索引也叫做二级索引，不用纠结那么多名词，将其等价就行了~ 非聚集索引在建立的时候也未必是单列的，可以多个列来创建索引。 此时就涉及到了哪个列会走索引，哪个列不走索引的问题了(最左匹配原则–&gt;后面有说) 创建多个单列(非聚集)索引的时候，会生成多个索引树(所以过多创建索引会占用磁盘空间) 在创建多列索引中也涉及到了一种特殊的索引–&gt;覆盖索引 我们前面知道了，如果不是聚集索引，叶子节点存储的是主键+列值 最终还是要“回表”，也就是要通过主键再查找一次。这样就会比较慢 覆盖索引就是把要查询出的列和索引是对应的，不做回表操作！ 比如说： 现在我创建了索引(username,age)，在查询数据的时候：select username , age from user where username = &#39;anocelot&#39; and age = 20。 很明显地知道，我们上边的查询是走索引的，并且，要查询出的列在叶子节点都存在！所以，就不用回表了~ 所以，能使用覆盖索引就尽量使用吧~ 索引最左匹配原则最左匹配原则： 索引可以简单如一个列(a)，也可以复杂如多个列(a, b, c, d)，即联合索引。 如果是联合索引，那么key也由多个列组成，同时，索引只能用于查找key是否存在（相等），遇到范围查询(&gt;、&lt;、between、like左匹配)等就不能进一步匹配了，后续退化为线性查找。 因此，列的排列顺序决定了可命中索引的列数。 例子： 如有索引(a, b, c, d)，查询条件a = 1 and b = 2 and c &gt; 3 and d = 4，则会在每个节点依次命中a、b、c，无法命中d。(很简单：索引命中只能是相等的情况，不能是范围匹配) =、in自动优化顺序不需要考虑=、in等的顺序，mysql会自动优化这些条件的顺序，以匹配尽可能多的索引列。 例子： 如有索引(a, b, c, d)，查询条件c &gt; 3 and b = 2 and a = 1 and d &lt; 4与a = 1 and c &gt; 3 and b = 2 and d &lt; 4等顺序都是可以的，MySQL会自动优化为a = 1 and b = 2 and c &gt; 3 and d &lt; 4，依次命中a、b、c。 索引总结索引在数据库中是一个非常重要的知识点！上面谈的其实就是索引最基本的东西，要创建出好的索引要顾及到很多的方面： 最左前缀匹配原则。这是非常重要、非常重要、非常重要（重要的事情说三遍）的原则，MySQL会一直向右匹配直到遇到范围查询（&gt;,&lt;,BETWEEN,LIKE）就停止匹配。 尽量选择区分度高的列作为索引，区分度的公式是 COUNT(DISTINCT col) / COUNT(*)。表示字段不重复的比率，比率越大我们扫描的记录数就越少。 索引列不能参与计算，尽量保持列“干净”。比如，FROM_UNIXTIME(create_time) = &#39;2016-06-06&#39; 就不能使用索引，原因很简单，B+树中存储的都是数据表中的字段值，但是进行检索时，需要把所有元素都应用函数才能比较，显然这样的代价太大。所以语句要写成 ： create_time = UNIX_TIMESTAMP(&#39;2016-06-06&#39;)。 尽可能的扩展索引，不要新建立索引。比如表中已经有了a的索引，现在要加（a,b）的索引，那么只需要修改原来的索引即可。 单个多列组合索引和多个单列索引的检索查询效果不同，因为在执行SQL时，MySQL只能使用一个索引，会从多个单列索引中选择一个限制最为严格的索引。 二、锁 在mysql中的锁看起来是很复杂的，因为有一大堆的东西和名词：排它锁，共享锁，表锁，页锁，间隙锁，意向排它锁，意向共享锁，行锁，读锁，写锁，乐观锁，悲观锁，死锁。这些名词有的博客又直接写锁的英文的简写—&gt;X锁，S锁，IS锁，IX锁，MMVC… 锁的相关知识又跟存储引擎，索引，事务的隔离级别都是关联的…. 为什么需要学习数据库锁知识不少人在开发的时候，应该很少会注意到这些锁的问题，也很少会给程序加锁(除了库存这些对数量准确性要求极高的情况下) 一般也就听过常说的乐观锁和悲观锁，了解过基本的含义之后就没了 定心丸：即使我们不会这些锁知识，我们的程序在一般情况下还是可以跑得好好的。因为这些锁数据库隐式帮我们加了 对于UPDATE、DELETE、INSERT语句，InnoDB会自动给涉及数据集加排他锁（X) MyISAM在执行查询语句SELECT前，会自动给涉及的所有表加读锁，在执行更新操作（UPDATE、DELETE、INSERT等）前，会自动给涉及的表加写锁，这个过程并不需要用户干预 只会在某些特定的场景下才需要手动加锁，学习数据库锁知识就是为了: 能让我们在特定的场景下派得上用场 更好把控自己写的程序 在跟别人聊数据库技术的时候可以搭上几句话 构建自己的知识库体系！在面试的时候不虚 表锁简单介绍首先，从锁的粒度，我们可以分成两大类： 表锁 开销小，加锁快；不会出现死锁；锁定力度大，发生锁冲突概率高，并发度最低 行锁 开销大，加锁慢；会出现死锁；锁定粒度小，发生锁冲突的概率低，并发度高 不同的存储引擎支持的锁粒度是不一样的： InnoDB行锁和表锁都支持！ MyISAM只支持表锁！ InnoDB只有通过索引条件检索数据才使用行级锁，否则，InnoDB将使用表锁 也就是说，InnoDB的行锁是基于索引的！ 表锁下又分为两种模式： 表读锁（Table Read Lock） 表写锁（Table Write Lock） 从下图可以清晰看到，在表读锁和表写锁的环境下：读读不阻塞，读写阻塞，写写阻塞！ 读读不阻塞：当前用户在读数据，其他的用户也在读数据，不会加锁 读写阻塞：当前用户在读数据，其他的用户不能修改当前用户读的数据，会加锁！ 写写阻塞：当前用户在修改数据，其他的用户不能修改当前用户正在修改的数据，会加锁！ 从上面已经看到了：读锁和写锁是互斥的，读写操作是串行。 如果某个进程想要获取读锁，同时另外一个进程想要获取写锁。在mysql里边，写锁是优先于读锁的！ 写锁和读锁优先级的问题是可以通过参数调节的：max_write_lock_count和low-priority-updates 值得注意的是： The LOCAL modifier enables nonconflicting INSERT statements (concurrent inserts) by other sessions to execute while the lock is held. (See Section 8.11.3, “Concurrent Inserts”.) However, READ LOCAL cannot be used if you are going to manipulate the database using processes external to the server while you hold the lock. For InnoDB tables, READ LOCAL is the same as READ MyISAM可以支持查询和插入操作的并发进行。可以通过系统变量concurrent_insert来指定哪种模式，在MyISAM中它默认是：如果MyISAM表中没有空洞（即表的中间没有被删除的行），MyISAM允许在一个进程读表的同时，另一个进程从表尾插入记录。 但是InnoDB存储引擎是不支持的！ 行锁细讲上边简单讲解了表锁的相关知识，我们使用Mysql一般是使用InnoDB存储引擎的。InnoDB和MyISAM有两个本质的区别： InnoDB支持行锁 InnoDB支持事务 从上面也说了：我们是很少手动加表锁的。表锁对我们程序员来说几乎是透明的，即使InnoDB不走索引，加的表锁也是自动的！ 我们应该更加关注行锁的内容，因为InnoDB一大特性就是支持行锁！ InnoDB实现了以下两种类型的行锁。 共享锁（S锁）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。 也叫做读锁：读锁是共享的，多个客户可以同时读取同一个资源，但不允许其他客户修改。 排他锁（X锁)：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。 也叫做写锁：写锁是排他的，写锁会阻塞其他的写锁和读锁。 看完上面的有没有发现，在一开始所说的：X锁，S锁，读锁，写锁，共享锁，排它锁其实总共就两个锁，只不过它们有多个名字罢了~~~ Intention locks do not block anything except full table requests (for example, LOCK TABLES … WRITE). The main purpose of intention locks is to show that someone is locking a row, or going to lock a row in the table. 另外，为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁： 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。 意向锁也是数据库隐式帮我们做了，不需要程序员操心！ 参考资料： MVCC和事务的隔离级别数据库事务有不同的隔离级别，不同的隔离级别对锁的使用是不同的，锁的应用最终导致不同事务的隔离级别 MVCC(Multi-Version Concurrency Control)多版本并发控制，可以简单地认为：MVCC就是行级锁的一个变种(升级版)。 事务的隔离级别就是通过锁的机制来实现，只不过隐藏了加锁细节 在表锁中我们读写是阻塞的，基于提升并发性能的考虑，MVCC一般读写是不阻塞的(所以说MVCC很多情况下避免了加锁的操作) MVCC实现的读写不阻塞正如其名：多版本并发控制—&gt;通过一定机制生成一个数据请求时间点的一致性数据快照（Snapshot)，并用这个快照来提供一定级别（语句级或事务级）的一致性读取。从用户的角度来看，好像是数据库可以提供同一数据的多个版本。 快照有两个级别： 语句级 针对于Read committed隔离级别 事务级别 针对于Repeatable read隔离级别 我们在初学的时候已经知道，事务的隔离级别有4种： Read uncommitted：会出现脏读，不可重复读，幻读 Read committed：会出现不可重复读，幻读 Repeatable read：会出现幻读(但在Mysql实现的Repeatable read配合gap锁不会出现幻读！) Serializable：串行，避免以上的情况！ Read uncommitted会出现的现象—&gt;脏读：一个事务读取到另外一个事务未提交的数据 例子：A向B转账，A执行了转账语句，但A还没有提交事务，B读取数据，发现自己账户钱变多了！B跟A说，我已经收到钱了。A回滚事务【rollback】，等B再查看账户的钱时，发现钱并没有多。 出现脏读的本质就是因为操作(修改)完该数据就立马释放掉锁，导致读的数据就变成了无用的或者是错误的数据。 Read committed避免脏读的做法其实很简单： 就是把释放锁的位置调整到事务提交之后，此时在事务提交前，其他进程是无法对该行数据进行读取的，包括任何操作 但Read committed出现的现象—&gt;不可重复读：一个事务读取到另外一个事务已经提交的数据，也就是说一个事务可以看到其他事务所做的修改 注：A查询数据库得到数据，B去修改数据库的数据，导致A多次查询数据库的结果都不一样【危害：A每次查询的结果都是受B的影响的，那么A查询出来的信息就没有意思了】 上面也说了，Read committed是语句级别的快照！每次读取的都是当前最新的版本！ Repeatable read避免不可重复读是事务级别的快照！每次读取的都是当前事务的版本，即使被修改了，也只会读取当前事务版本的数据。 呃…如果还是不太清楚，我们来看看InnoDB的MVCC是怎么样的吧(摘抄《高性能MySQL》) 至于虚读(幻读)：是指在一个事务内读取到了别的事务插入的数据，导致前后读取不一致。 注：和不可重复读类似，但虚读(幻读)会读到其他事务的插入的数据，导致前后读取不一致 MySQL的Repeatable read隔离级别加上GAP间隙锁已经处理了幻读了。 乐观锁和悲观锁无论是Read committed还是Repeatable read隔离级别，都是为了解决读写冲突的问题。 单纯在Repeatable read隔离级别下我们来考虑一个问题： 此时，用户李四的操作就丢失掉了： 丢失更新：一个事务的更新覆盖了其它事务的更新结果。 (ps:暂时没有想到比较好的例子来说明更新丢失的问题，虽然上面的例子也是更新丢失，但一定程度上是可接受的..不知道有没有人能想到不可接受的更新丢失例子呢…) 解决的方法： 使用Serializable隔离级别，事务是串行执行的！ 乐观锁 悲观锁 乐观锁是一种思想，具体实现是，表中有一个版本字段，第一次读的时候，获取到这个字段。处理完业务逻辑开始更新的时候，需要再次查看该字段的值是否和第一次的一样。如果一样更新，反之拒绝。之所以叫乐观，因为这个模式没有从数据库加锁，等到更新的时候再判断是否可以更新。 悲观锁是数据库层面加锁，都会阻塞去等待锁。 悲观锁所以，按照上面的例子。我们使用悲观锁的话其实很简单(手动加行锁就行了)： select * from xxxx for update 在select 语句后边加了 for update相当于加了排它锁(写锁)，加了写锁以后，其他的事务就不能对它修改了！需要等待当前事务修改完之后才可以修改. 也就是说，如果张三使用select ... for update，李四就无法对该条记录修改了~ 乐观锁乐观锁不是数据库层面上的锁，是需要自己手动去加的锁。一般我们添加一个版本字段来实现： 具体过程是这样的： 张三select * from table —&gt;会查询出记录出来，同时会有一个version字段 李四select * from table —&gt;会查询出记录出来，同时会有一个version字段 李四对这条记录做修改：update A set Name=lisi,version=version+1 where ID=#{id} and version=#{version}，判断之前查询到的version与现在的数据的version进行比较，同时会更新version字段 此时数据库记录如下： 张三也对这条记录修改：update A set Name=lisi,version=version+1 where ID=#{id} and version=#{version}，但失败了！因为当前数据库中的版本跟查询出来的版本不一致！ 间隙锁GAP当我们用范围条件检索数据而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合范围条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”。InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁。 值得注意的是：间隙锁只会在Repeatable read隔离级别下使用~ 例子：假如emp表中只有101条记录，其empid的值分别是1,2,…,100,101 1Select * from emp where empid &gt; 100 for update; 上面是一个范围查询，InnoDB不仅会对符合条件的empid值为101的记录加锁，也会对empid大于101（这些记录并不存在）的“间隙”加锁。 InnoDB使用间隙锁的目的有两个： 为了防止幻读(上面也说了，Repeatable read隔离级别下再通过GAP锁即可避免了幻读) 满足恢复和复制的需要 MySQL的恢复机制要求：在一个事务未提交前，其他并发事务不能插入满足其锁定条件的任何记录，也就是不允许出现幻读 2.5死锁并发的问题就少不了死锁，在MySQL中同样会存在死锁的问题。 但一般来说MySQL通过回滚帮我们解决了不少死锁的问题了，但死锁是无法完全避免的，可以通过以下的经验参考，来尽可能少遇到死锁： 1）以固定的顺序访问表和行。比如对两个job批量更新的情形，简单方法是对id列表先排序，后执行，这样就避免了交叉等待锁的情形；将两个事务的sql顺序调整为一致，也能避免死锁。 2）大事务拆小。大事务更倾向于死锁，如果业务允许，将大事务拆小。 3）在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁概率。 4）降低隔离级别。如果业务允许，将隔离级别调低也是较好的选择，比如将隔离级别从RR调整为RC，可以避免掉很多因为gap锁造成的死锁。 5）为表添加合理的索引。可以看到如果不走索引将会为表的每一行记录添加上锁，死锁的概率大大增大。 锁总结上面说了一大堆关于MySQL数据库锁的东西，现在来简单总结一下。 表锁其实我们程序员是很少关心它的： 在MyISAM存储引擎中，当执行SQL语句的时候是自动加的。 在InnoDB存储引擎中，如果没有使用索引，表锁也是自动加的。 现在我们大多数使用MySQL都是使用InnoDB，InnoDB支持行锁： 共享锁–读锁–S锁 排它锁–写锁–X锁 在默认的情况下，select是不加任何行锁的事务可以通过以下语句显示给记录集加共享锁或排他锁。 共享锁（S）：SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE。 排他锁（X)：SELECT * FROM table_name WHERE ... FOR UPDATE。 InnoDB基于行锁还实现了MVCC多版本并发控制，MVCC在隔离级别下的Read committed和Repeatable read下工作。MVCC能够实现读写不阻塞！ InnoDB实现的Repeatable read隔离级别配合GAP间隙锁已经避免了幻读！ 乐观锁其实是一种思想，正如其名：认为不会锁定的情况下去更新数据，如果发现不对劲，才不更新(回滚)。在数据库中往往添加一个version字段来实现。 悲观锁用的就是数据库的行锁，认为数据库会发生并发冲突，直接上来就把数据锁住，其他事务不能修改，直至提交了当前事务]]></content>
  </entry>
  <entry>
    <title><![CDATA[树]]></title>
    <url>%2F2018%2F07%2F16%2Ftree-algorithms%2F</url>
    <content type="text"><![CDATA[二叉查找树(BST，Binary Search Tree)，平衡二叉查找树(AVL)，红黑树(RBT)，B~/B+/B*树(B-tree) 动态结构：相比静态查找结构，在 插入 和 删除 时代价更低； 查找的时间复杂度大体维持在 O(log(N)) 数量级上 应用场景 AVL树：最早的平衡二叉树之一。应用相对其他数据结构比较少。windows对进程地址空间的管理用到了AVL树。 红黑树：平衡二叉树，广泛用在C++的STL中。如map和set都是用红黑树实现的 B/B+树：用在磁盘文件组织 数据索引和数据库索引。 Trie树(字典树)：用在统计和排序大量字符串，如自动机。 那些树二叉查找树 BSTBinary Search Tree相比静态查找结构，插入和删除的代价更低； 查找代价任何一个数据的查找过程都需要从根结点出发，沿某一个路径朝叶子结点前进。因此查找中数据比较次数与树的形态密切相关。当树中每个结点左右子树高度大致相同时，树高为 logN 。则平均查找长度与 logN 成正比，查找的平均时间复杂度在 O(logN) 数量级上。当先后插入的关键字有序时，BST 退化成 单支树结构 。此时树高N。平均查找长度为 (N+1)/2，查找的平均时间复杂度在 O(N) 数量级上。 插入代价新结点插入到树的叶子上，完全不需要改变树中原有结点的组织结构。插入一个结点的代价与查找一个不存在的数据的代价完全相同。 删除代价删除操作的时间复杂度最大不会超过 O(logN)。当删除一个结点 P，首先需要定位到这个结点 P，这个过程需要一个查找的代价。然后稍微改变一下树的形态。如果被删除结点的左、右子树只有一个存在，则改变形态的代价仅为 O(1)。如果被删除结点的左、右子树均存在，只需要将当P的左孩子的右孩子的右孩子的…的右叶子结点与 P 互换，在改变一些左右子树即可。 BST 效率 查找最好时间复杂度 O(logN)；最坏时间复杂度 O(N)； 插入删除操作算法简单，时间复杂度与查找差不多 平衡二叉查找树 AVL为什么需要AVL 由于 二叉查找树BST 不够平衡，所以在 最差 情况下查找的时间复杂度为 O(N)，劣化为顺序查找效率 什么是AVLAVL 树是根据它的发明者 G.M. Adelson-Velsky 和 E.M. Landis 命名的。它是最先发明的自平衡二叉查找树，也被称为高度平衡树； AVL = BST + 树中任何节点的两个子树的高度最大差别为1 操作 查找代价AVL是严格平衡的BST（平衡因子不超过1）。那么查找过程与BST一样，只是AVL不会出现最差情况的BST(单支树)。因此查找效率最好，最坏情况都是O(logN)数量级的。 插入代价AVL必须要保证严格平衡(|bf|=1)，那么每一次插入数据使得AVL中某些结点的平衡因子超过1就必须进行旋转操作。事实上，AVL的每一次插入结点操作最多只需要旋转1次(单旋转或双旋转)。因此，总体上插入操作的代价仍然在O(logN)级别上(插入结点需要首先查找插入的位置)。 删除代价：AVL删除结点的算法可以参见BST的删除结点，但是删除之后必须检查从删除结点开始到根结点路径上的所有结点的平衡因子。因此删除的代价稍微要大一些。每一次删除操作最多需要O(logN)次旋转。因此，删除操作的时间复杂度为O(logN)+O(logN)=O(2logN) AVL 效率查找的时间复杂度维持在O(logN)，不会出现最差情况AVL树在执行每个插入操作时最多需要1次旋转，其时间复杂度在O(logN)左右。AVL树在执行删除时代价稍大，执行每个删除操作的时间复杂度需要O(2logN)。 红黑树 Red-Black Tree 红黑树 = 不那么严格的 AVL]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[synology-ali-dns-report]]></title>
    <url>%2F2018%2F06%2F24%2Fsynology-ali-dns-report%2F</url>
    <content type="text"><![CDATA[Synology使用aliyun DDNS常见python和php两个版本；个人比较喜欢php版本，不需要ssh登录盒子，系统升级的时候也不需要做额外的配置； php版本安装php运行环境需要安装以下应用： 配置 Web Station 需要使用 PHP 7.0 web目录上传PHP脚本创建aliyunddns文件夹 ddns.php123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&lt;?php ########################################################## 阿里云DDNS ## 阿里云DNS解析API封装PHP版(支持群晖DDNS接口) ## 作者 XOEO QQ 6308532 ########################################################## include "function.php"; $info = explode("&amp;", $_SERVER["QUERY_STRING"]); if ($info == '') &#123; exit("badauth"); &#125; $AccessKeyId = $info[0]; $Secret = $info[1]; $DomainName = $info[2]; $UpdateIP = $info[3]; $HostName = ''; $arr = explode(".",$DomainName); $count = count($arr); switch($count) &#123; case 2: $HostName = 'www'; break; case 1: exit("badsys"); break; case 3: $HostName = $arr[0]; $DomainName = $arr[1].'.'.$arr[2]; break; &#125; $Data = AliYunDDNS::SendAPI(AliYunDDNS::DescribeDomainRecords($AccessKeyId, $DomainName), $Secret); $xml = simplexml_load_string($Data); $PageNumber = $xml-&gt;PageNumber; $PageSize = $xml-&gt;PageSize; $TotalCount = $xml-&gt;TotalCount; $DomainRecords = $xml-&gt;DomainRecords; if (($PageNumber == '') and ($DomainRecords == '')) &#123; exit("badauth"); &#125; $boExist = false; foreach ($DomainRecords-&gt;children() as $key =&gt; $value) &#123; $RR = $value-&gt;RR; $Type = $value-&gt;Type; $RecordId = $value-&gt;RecordId; $RecordValue = $value-&gt;Value; if ((strcasecmp($Type, 'A') == 0) and (strcasecmp($RR, $HostName) == 0)) &#123; $boExist = true; if (strcasecmp($RecordValue, $UpdateIP) &lt;&gt; 0) &#123; $Data = AliYunDDNS::SendAPI(AliYunDDNS::UpdateDomainRecord($AccessKeyId, $UpdateIP, $RR, $RecordId), $Secret); $xml = simplexml_load_string($Data); $retRecordId = $xml-&gt;RecordId; if (strcasecmp($retRecordId,$RecordId) == 0) &#123; echo "good"; &#125; else &#123; echo "nochg ".$UpdateIP; &#125; &#125; else &#123; echo "nochg ".$UpdateIP; &#125; &#125; &#125; if (!$boExist) &#123; echo "nohost"; &#125;?&gt; function.php123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115&lt;?php########################################################## 阿里云DDNS ## 阿里云DNS解析API封装PHP版(支持群晖DDNS接口) ## 作者:XOEO QQ 6308532 ########################################################## class AliYunDDNS &#123; function GetUTCTime() &#123; date_default_timezone_set('UTC'); return date('Y-m-d\TH:i:s\Z', time()); &#125; function Create_Guid() &#123; if (function_exists ( 'com_create_guid' )) &#123; return com_create_guid (); &#125; else &#123; $charid = strtoupper ( md5 ( uniqid ( rand (), true ) ) ); $hyphen = chr ( 45 ); $uuid = '' . substr ( $charid, 0, 8 ) . $hyphen . substr ( $charid, 8, 4 ) . $hyphen . substr ( $charid, 12, 4 ) . $hyphen . substr ( $charid, 16, 4 ) . $hyphen . substr ( $charid, 20, 12 ); return $uuid; &#125; &#125; function GetSignature($str, $key) &#123; $signature = ""; if (function_exists('hash_hmac')) &#123; $signature = base64_encode(hash_hmac("sha1", $str, $key, true)); &#125; return $signature; &#125; function ProcessEncodeStr($str) &#123; $tmp = str_replace('+','%20',$str); $tmp = str_replace('*','%2A',$tmp); $tmp = str_replace('@','%40',$tmp); return str_replace('%7E','~',$tmp); &#125; function percentEncode($str) &#123; return Self::ProcessEncodeStr(urlencode(mb_convert_encoding($str, "UTF-8"))); &#125; function SendAPI($str, $Secret) &#123; $Signature = 'GET&amp;'.Self::percentEncode('/').'&amp;'.Self::percentEncode($str); $Signature = Self::getSignature($Signature, $Secret.'&amp;'); $GetString = "http://dns.aliyuncs.com/?"; $GetString = $GetString.$str.'&amp;Signature='.Self::percentEncode($Signature); return GetURL($GetString); &#125; function DescribeDomainRecords($AccessKeyId, $DomainName) &#123; $str = 'AccessKeyId='.$AccessKeyId.'&amp;'; $str = $str.'Action=DescribeDomainRecords&amp;'; $str = $str.'DomainName='.$DomainName.'&amp;'; $str = $str.'Format=xml&amp;'; $str = $str.'SignatureMethod=HMAC-SHA1&amp;'; $str = $str.'SignatureNonce='.strtolower(Self::Create_Guid()).'&amp;'; $str = $str.'SignatureVersion=1.0&amp;'; $str = $str.'Timestamp='.Self::percentEncode(Self::GetUTCTime()).'&amp;'; $str = $str.'Version=2015-01-09'; return $str; &#125; function UpdateDomainRecord($AccessKeyId, $Value, $HostName, $RecordId) &#123; $str = 'AccessKeyId='.$AccessKeyId.'&amp;'; $str = $str.'Action=UpdateDomainRecord&amp;'; $str = $str.'Format=xml&amp;'; $str = $str.'Line=default&amp;'; $str = $str.'Priority=1&amp;'; $str = $str.'RR='.Self::percentEncode($HostName).'&amp;'; $str = $str.'RecordId='.$RecordId.'&amp;'; $str = $str.'SignatureMethod=HMAC-SHA1&amp;'; $str = $str.'SignatureNonce='.strtolower(Self::Create_Guid()).'&amp;'; $str = $str.'SignatureVersion=1.0&amp;'; $str = $str.'TTL=600&amp;'; $str = $str.'Timestamp='.Self::percentEncode(Self::GetUTCTime()).'&amp;'; $str = $str.'Type=A&amp;'; $str = $str.'Value='.Self::percentEncode($Value).'&amp;'; $str = $str.'Version=2015-01-09'; return $str; &#125; &#125; function GetURL($url) &#123; $ch = curl_init(); curl_setopt($ch, CURLOPT_URL, $url); curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1); curl_setopt($ch, CURLOPT_HEADER, 0); $ret = curl_exec($ch); curl_close($ch); return $ret; &#125; function getClientIp()&#123; $socket = socket_create(AF_INET, SOCK_STREAM, 6); $ret = socket_connect($socket,'ns1.dnspod.net',6666); $buf = socket_read($socket, 16); socket_close($socket); return $buf; &#125; ?&gt; update.php1234567891011121314&lt;?php########################################################## 阿里云DDNS ## 阿里云DNS解析API封装PHP版(支持群晖DDNS接口) ## 作者:XOEO QQ 6308532 ########################################################## include "function.php"; $AccessKeyId = "$&#123;yourAcessKeyId&#125;"; $Secret = "$&#123;yourSecret&#125;"; $info = explode("&amp;", $_SERVER["QUERY_STRING"]); $HostName = explode("=",$info[0])[1]; $MYIP = explode("=",$info[1])[1]; echo GetURL("http://".$_SERVER['SERVER_NAME']."/aliyunddns/ddns.php?".$AccessKeyId."&amp;".$Secret."&amp;".$HostName."&amp;".$MYIP /*getClientIp()*/);?&gt; 配置DDNS 控制面板 -&gt; 外部访问 -&gt; DDNS 服务提供商选择已配置的aliyun；主机名称配置自己的域名，比如我自己的demo.anocelot.cn；其余项目（用户名/电子邮件，密码/秘钥）可以随意填写； python版本]]></content>
      <tags>
        <tag>synology</tag>
        <tag>dns</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[narration-of-regex]]></title>
    <url>%2F2018%2F06%2F20%2Fnarration-of-regex%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[OSX的那些事儿]]></title>
    <url>%2F2018%2F06%2F20%2Fnarration-of-osx%2F</url>
    <content type="text"><![CDATA[Bash~/.bash_profile~/.bashrc~/.bash_logout .bash_profile: 每次用户登录系统时读取，其中的所有命令都会被bash执行.bashrc: 在shell中键入bash命令启动一个新的shell时读取.bash_logout: 退出shell时被读取 Shell类型是否为登录Shell（login shell），是否为交互式Shell（interactive shell） 交互式Shell：没有非选项参数，没有-c，标准输入和标准输出与终端相连的，或者用-i参数启动的Bash实例。可以通过探测PS1变量是否设置或者$-返回值中是否包含字幕i来判定。什么是没有非选项参数？比如bash ~/myscript/clear_temp_files.sh这样执行的Shell脚本的Bash实例，就不是交互式Shell，因为脚本的路径，就是非选项参数。-c又是干什么的？就是使用一个字符串作为Bash的传入参数，比如bash -c ‘ls -ahl’，这种Shell进程也不算是交互式Shell。 登录Shell：第0个参数以-号开头的Bash实例（登录后，执行echo $0可见 - 开头），或者用-login参数启动的Bash Shell非登录Shell的用途比如一个用Linux搭建一个ftp服务器，并且创建了很多的ftp用户，那么就可以将这些用户的默认shell改为nologin，这样一来，这些虽然是Linux上的用户可是却无法登录进Linux主机，只能登录ftp服务器了，保证了安全性。 登录shell时文件的加载顺序 /etc/profile ~/.bash_profile ~/.bash_login ~/.profile 安装zsh后安装了zsh之后默认启动执行脚本变为了～/.zshrc可以考虑在其中添加12source ~/.bash_profilesource ~/.bashrc]]></content>
      <tags>
        <tag>osx</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[uml的那些事儿]]></title>
    <url>%2F2018%2F03%2F24%2Fnarration-of-uml%2F</url>
    <content type="text"><![CDATA[文章摘要 类图 序列图对象图包图部署图用例图状态机图活动图]]></content>
      <tags>
        <tag>uml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 源码一小堆儿]]></title>
    <url>%2F2018%2F03%2F21%2Fspring-source-index%2F</url>
    <content type="text"><![CDATA[获取ApplicationContext的两种方式 实现 ApplicationContextAware 接口 通过 @Autowired 或 @Resource 注解标注让Spring进行自动注入]]></content>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Webflow 那些事儿]]></title>
    <url>%2F2018%2F03%2F20%2Fspring-web-flow%2F</url>
    <content type="text"></content>
      <tags>
        <tag>spring</tag>
        <tag>spring webflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[distributed transaction]]></title>
    <url>%2F2018%2F03%2F20%2Fdistributed-transaction%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Unix Inode]]></title>
    <url>%2F2018%2F03%2F17%2Funix-inode%2F</url>
    <content type="text"><![CDATA[转自: It is all about the inode An inode is a data structure in UNIX operating systems that contains important information pertaining to files within a file system. When a file system is created in UNIX, a set amount of inodes is created, as well. Usually, about 1 percent of the total file system disk space is allocated to the inode table. Sometimes, people interchange the terms inode and inumber. The terms are similar and do correspond to each other, but they don’t refer to the same things. Inode refers to the data structure; the inumber is actually the identification number of the inode—hence the term inode number, or inumber. The inumber is only one important item of information for a file. Some of the other attributes in an inode are discussed in the next section. The inode table contains a listing of all inode numbers for the respective file system. When users search for or access a file, the UNIX system searches through the inode table for the correct inode number. When the inode number is found, the command in question can access the inode and make the appropriate changes if applicable. Take, for example, editing a file with vi. When you type vi &lt;filename&gt;, the inode number is found in the inode table, allowing you to open the inode. Some attributes are changed during the edit session of vi, and when you have finished and typed :wq, the inode is closed and released. This way, if two users were to try to edit the same file, the inode would already have beenassigned to another user ID (UID) in the edit session, and the second editor wouldhave to wait for the inode to be released. The inode structureThe inode structure is relatively straightforward for seasoned UNIX developers or administrators, but there may still be some surprising information you don’t already know about the insides of the inode. The following definitions provide just some of the important information contained in the inode that UNIX users employ constantly: Inode number Mode information to discern file type and also for the stat C function Number of links to the file UID of the owner Group ID (GID) of the owner Size of the file Actual number of blocks that the file uses Time last modified Time last accessed Time last changed Basically, the inode contains all information about a file outside of the actual name of the file and the actual data content of the file. The full inode structure can be found in the header file /usr/include/jfs/ino.h in AIX or on the Web at http://publib.boulder.ibm.com/infocenter/systems/index.jsp?topic=/com.ibm.aix.files/doc/aixfiles/inode.h.htm. The information listed above is important to files and is used heavily in UNIX. Without with this information, a file would appear corrupt and unusable. Directories and files may appear different on UNIX systems compared to other operating systems, but they aren’t. In UNIX, directories are actually files that have a few additional settings in their inodes. A directory is basically a file containing other files. Also, the mode information has flags set to inform the system that the file is actually a directory. Working with inodesKnowing how to work with inodes in UNIX can save a lot of time and frustration. You can use the following commands to alleviate some of the headaches you may have when you don’t know about inodes. The df commandAs mentioned earlier, when you create a file system in UNIX, about 1 percent of the total disk space is allocated to the inode table. Every time you create a file in the file system, an inode is allocated to the file. Typically, there is an adequate number of inodes associated with a file system, but running out of inodes is always a possibility. To monitor this, you can view the output of the df. Using the df command, you can look at all mounted file systems or specific file systems. In this view, you can see the number of inodes used already in the respective file system as well as the percentage used overall in the file system, as Listing 1 shows. Listing 1. Using df to monitor inode use1234567# df -k|head -6Filesystem 1024-blocks Free %Used Iused %Iused Mounted on/dev/hd4 229376 138436 40% 4730 13% //dev/hd2 8028160 962692 89% 110034 33% /usr/dev/hd9var 1835008 366400 81% 25829 24% /var/dev/hd3 524288 523564 1% 98 1% /tmp/dev/hd1 32768 32416 2% 5 1% /home If for some reason a file system did reach 100 percent of its inodes used, you won’t be able to create additional files, devices, directories, and so on in the file system. One solution is to add more space to the file system through the smitty chfs command, as shown in Figure 1. Another solution is to create smaller inode extents. IBM AIX 5L now allows for inode extends smaller than the default sizeof 16KB on enhanced journal file systems. Please keep in mind, though, that if you use this option in AIX 5L, the file system will not be accessible from previous versions of AIX. Figure 1. The result of the smitty chfs commandView image at full size istat and statA quick way to examine an inode in AIX is by using the istat command. With this command, you can find the inumber of the specific file as well as other inode items like permissions; file type; UID; GID; number of links (not symbolic links); file size; and time stamps for last updated, last modified, and last accessed. Listing 2 shows inode information for the file /usr/bin/ksh in AIX. Listing 2. Inode information for /usr/bin/ksh12345678# istat /usr/bin/kshInode 18150 on device 10/8 FileProtection: r-xr-xr-xOwner: 2(bin) Group: 2(bin)Link count: 5 Length 237804 bytesLast updated: Wed Oct 24 17:37:10 EDT 2007Last modified: Wed Apr 18 23:58:06 EDT 2007Last accessed: Mon Apr 28 11:25:35 EDT 2008 In addition to showing the standard information from istat, you now know what the inumber is for /usr/bin/ksh. If you also find the logical volume in which the file resides, you can display even more information. One way to find this information is by looking at the mounted file system in which the file resides with the df command: 123# df /usr/binFilesystem 512-blocks Free %Used Iused %Iused Mounted on/dev/hd2 16056320 1925384 89% 110034 33% /usr The file /usr/bin/ksh resides in the directory /usr/bin. Looking at the output of the df command, you can tell that the directory /usr/bin is contained in the /usr file system and that the /usr file system is inside the logical volume /dev/hd2. Now that you know both the inumber and the logical volume name, using istat with both items of information as arguments, you can determine the hexadecimal addresses of the disk blocks that make up the file, as shown in Listing 3. Listing 3. Determining the hexadecimal addresses of the file blocks123456789101112# istat 18150 /dev/hd2Inode 18150 on device 10/8 FileProtection: r-xr-xr-xOwner: 2(bin) Group: 2(bin)Link count: 5 Length 237804 bytesLast updated: Wed Oct 24 17:37:10 EDT 2007Last modified: Wed Apr 18 23:58:06 EDT 2007Last accessed: Mon Apr 28 11:44:20 EDT 2008Block pointers (hexadecimal):11620 ef8c0 Linux has its own version of istat: stat. The Linux stat command shows similar informationand also includes some switches not available in the AIX istat command: 12345678# stat /bin/bash File: /bin/bash Size: 722684 Blocks: 1432 IO Block: 4096 regular file Device: fd00h/64768d Inode: 12799859 Links: 1 Access: (0755/-rwxr-xr-x) Uid: ( 0/ root) Gid: ( 0/ root) Access: 2008-04-06 19:13:50.000000000 -0400 Modify: 2006-07-12 03:11:53.000000000 -0400 Change: 2007-11-22 04:05:30.000000000 -0500 The ls commandAt one time or another in your career, you’ve had to worry about removing or managing files with dashes or other special characters in the file name or file names that appear not to have a file name at all. Most likely, someone mistakenly named the respective file. Because most commands in UNIX include switches, or options, that begin either with a hyphen (-) or a double hyphen (--), it can be difficult to manipulate these files with commonly used commands such as rm, mv, and cp. Thankfully, there are options in commands to show the inumber of the inode associated with the file in question. The ls command has such an option: 123# ls - -- -p fileA fileB fileC fileD fileE fileF fileG fileH fileI fileJ fileK fileL` Using the ls -i command, you can view the inumber next to the file name, as shown in Listing 4. Now that you know the inumber, you can easily manipulate the file. Listing 4. Viewing the inumber of the file1234# ls –i38988 38991 -p 38984 fileC 38982 fileF 38977 fileI 38978 fileL38989 - 38980 fileA 38986 fileD 38983 fileG 38987 fileJ38990 -- 38979 fileB 38976 fileE 38985 fileH 38981 fileK The find commandUsing the UNIX find command, you can finish what you started with the ls command. Now that you know the inumber for the respective files that you must manipulate, you can start! To remove the file that looks like it has no name, simply use find with the -inum switch to locate the inumber and file. Then, when the file has been found, use find with the -exec switch to remove the file: 1# find . -inum 38988 -exec rm &#123;&#125; \; To rename the file, do the same again, but this time use mv rather than rm:1# find . -inum 38989 -exec mv &#123;&#125; fileM \; To verify that you’re getting the expected results, simply use the ls -i command again: 1234# ls -i38990 -- 38979 fileB 38976 fileE 38985 fileH 38981 fileK38991 -p 38984 fileC 38982 fileF 38977 fileI 38978 fileL38980 fileA 38986 fileD 38983 fileG 38987 fileJ 38989 fileM The fsck commandUnfortunately, hardware doesn’t last forever, and systems can fail over years of continued use. When this happens and the operating system shuts down abnormally because of a power failure or another issue, you may encounter files when you bring the system back up that were open during the crash andnow need assistance. During times like this, you may run into messages that inodes need to be repaired or that an error exists. If this happens, the fsck command can be a lifesaver! Rather thanrestoring the system or even rebuilding the operating system, you can use fsck to repair file systems or correct damaged inodes. The following command attempts to repair the logical volume /dev/hd1:1# fsck –p /dev/hd1 –y By using the fsck command, you can narrow the search for damaged inodes, as well. If you’re searching for a specific inode, you can use the -ii-NodeNumber switch with fsck. ConclusionFiles and directories would be nearly useless in UNIX without the helping hand of the inode. Hopefully, after reading this article, you understand inodes better, their importance to AIX, and also how to manage them. You may never look at df the same way again.]]></content>
      <tags>
        <tag>unix</tag>
        <tag>inode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发(concurrent) VS 并行(parallel)]]></title>
    <url>%2F2018%2F03%2F17%2Fconcurrent-vs-parallel%2F</url>
    <content type="text"><![CDATA[Erlang 之父 Joe Armstrong 的图说下并发(Concurrent)与并行(Parallel) 并发(Concurrent)：两队轮流使用一个咖啡机 并行(Parallel)：两队分别使用咖啡机]]></content>
      <tags>
        <tag>concurrent</tag>
        <tag>parallel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[G1 那些事儿]]></title>
    <url>%2F2018%2F03%2F17%2Fjvm-g1%2F</url>
    <content type="text"><![CDATA[key wordG1, RSets, CSetsfor Hotspot JVM 简单说说G1是什么？G1目标 减少fullgc 为什么叫做garbage first G1的基础是region，在执行gc时，G1首先找出那些region几乎是空的，优先回收；因此称为 Garbage First 有什么不同(对比Serial,Parallel,CMS) Serial,Parallel,CMS G1 堆空间是连续的，分为新生代，survivor和老年代 region概念，每个region是2的幂次方（2-32MB），平均2000个region 各代是连续的 对象写入region，region可能属于新生代，也可能属于老年代 各代大小固定 动态决定哪些region属于新生代、哪些属于老年代 每次处理一个分代 每次处理若干个region，且不影响其余region 相关的commandThis is the complete list of G1 GC switches. Remember to use the best practices outlined above. Option and Default Value Description -XX:+UseG1GC Use the Garbage First (G1) Collector -XX:MaxGCPauseMillis=n Sets a target for the maximum GC pause time. This is a soft goal, and the JVM will make its best effort to achieve it. -XX:InitiatingHeapOccupancyPercent=n Percentage of the (entire) heap occupancy to start a concurrent GC cycle. It is used by GCs that trigger a concurrent GC cycle based on the occupancy of the entire heap, not just one of the generations (e.g., G1). A value of 0 denotes ‘do constant GC cycles’. The default value is 45. -XX:NewRatio=n Ratio of new/old generation sizes. The default value is 2. -XX:SurvivorRatio=n Ratio of eden/survivor space size. The default value is 8. -XX:MaxTenuringThreshold=n Maximum value for tenuring threshold. The default value is 15. -XX:ParallelGCThreads=n Sets the number of threads used during parallel phases of the garbage collectors. The default value varies with the platform on which the JVM is running. -XX:ConcGCThreads=n Number of threads concurrent garbage collectors will use. The default value varies with the platform on which the JVM is running. -XX:G1ReservePercent=n Sets the amount of heap that is reserved as a false ceiling to reduce the possibility of promotion failure. The default value is 10. -XX:G1HeapRegionSize=n With G1 the Java heap is subdivided into uniformly sized regions. This sets the size of the individual sub-divisions. The default value of this parameter is determined ergonomically based upon heap size. The minimum value is 1Mb and the maximum value is 32Mb. 最佳实践 Best practices 不要设置新生代大小(Do not set young generation size by -Xmn) G1 will no longer respect the pause time target for collections. So in essence, setting the young generation size disables the pause time goal. G1 is no longer able to expand and contract the young generation space as needed. Since the size is fixed, no changes can be made to the size. GC暂停时间不是100%能保证的(Response Time Metrics)Instead of using average response time (ART) as a metric to set the XX:MaxGCPauseMillis=, consider setting value that will meet the goal 90% of the time or more. This means 90% of users making a request will not experience a response time higher than the goal. Remember, the pause time is a goal and is not guaranteed to always be met. 晋升失败以及如何避免(Evacuation Failure)如果GC的晋升过程中遇到堆区域溢出（使用-XX:+PrintGCDetails看到to-space overflow），可以通过下面几种方式避免： 增加-XX:G1ReservePercent=n，缺省值是10。这可以增加可用的to-space内存 使用-XX:ConcGCThreads=n增加标记线程数目 CMS vs G1CMS：old generation 是一个连续空间，只有发生full gc时才会进行压缩 看图说话CMS 堆结构（Heap Structure） G1 堆结构（Heap Structure） CMS step缺点：不支持压缩（compact） 两次stw：Initial Mark, Remark The CMS collector performs the following phases on the old generation of the heap: Phase Description (1) Initial Mark (Stop the World Event) Objects in old generation are “marked” as reachable including those objects which may be reachable from young generation. Pause times are typically short in duration relative to minor collection pause times. (2) Concurrent Marking Traverse the tenured generation object graph for reachable objects concurrently while Java application threads are executing. Starts scanning from marked objects and transitively marks all objects reachable from the roots. The mutators are executing during the concurrent phases 2, 3, and 5 and any objects allocated in the CMS generation during these phases (including promoted objects) are immediately marked as live. (3) Remark (Stop the World Event) Finds objects that were missed by the concurrent mark phase due to updates by Java application threads to objects after the concurrent collector had finished tracing that object. (4) Concurrent Sweep Collects the objects identified as unreachable during marking phases. The collection of a dead object adds the space for the object to a free list for later allocation. Coalescing of dead objects may occur at this point. Note that live objects are not moved. (5) Resetting Prepare for next concurrent collection by clearing data structures. G1 stepThe G1 collector performs the following phases on the old generation of the heap. Note that some phases are part of a young generation collection. Phase Description (1) Initial Mark (Stop the World Event) This is a stop the world event. With G1, it is piggybacked on a normal young GC. Mark survivor regions (root regions) which may have references to objects in old generation. (2) Root Region Scanning Scan survivor regions for references into the old generation. This happens while the application continues to run. The phase must be completed before a young GC can occur. (3) Concurrent Marking Find live objects over the entire heap. This happens while the application is running. This phase can be interrupted by young generation garbage collections. (4) Remark (Stop the World Event) Completes the marking of live object in the heap. Uses an algorithm called snapshot-at-the-beginning (SATB) which is much faster than what was used in the CMS collector. (5) Cleanup (Stop the World Event and Concurrent) 1 Performs accounting on live objects and completely free regions. (Stop the world) 2 Scrubs the Remembered Sets. (Stop the world) 3 Reset the empty regions and return them to the free list. (Concurrent) (*) Copying (Stop the World Event) These are the stop the world pauses to evacuate or copy live objects to new unused regions. This can be done with young generation regions which are logged as [GC pause (young)]. Or both young and old generation regions which are logged as [GC Pause (mixed)] ref Oracle Getting Started with the G1 Garbage Collector The G1 Garbage Collector 用于替代CMS 压缩空余空间时必满延长中断时间 无需牺牲吞吐量 The Garbage-First (G1) collector is a server-style garbage collector, targeted for multi-processor machines with large memories. It meets garbage collection (GC) pause time goals with a high probability, while achieving high throughput. The G1 garbage collector is fully supported in Oracle JDK 7 update 4 and later releases. The G1 collector is designed for applications that: Can operate concurrently with applications threads like the CMS collector. Compact free space without lengthy GC induced pause times. Need more predictable GC pause durations. Do not want to sacrifice a lot of throughput performance. Do not require a much larger Java heap. G1 is planned as the long term replacement for the Concurrent Mark-Sweep Collector (CMS). Comparing G1 with CMS, there are differences that make G1 a better solution. One difference is that G1 is a compacting collector. G1 compacts sufficiently to completely avoid the use of fine-grained free lists for allocation, and instead relies on regions. This considerably simplifies parts of the collector, and mostly eliminates potential fragmentation issues. Also, G1 offers more predictable garbage collection pauses than the CMS collector, and allows users to specify desired pause targets. G1 vs Serial,Parallel,CMS Serial,Parallel,CMS G1 all structure the heap into three sections: young generation, old generation, and permanent generation of a fixed memory size partitioned into a set of equal-sized heap regions, each a contiguous range of virtual memory. Certain region sets are assigned the same roles (eden, survivor, old) as in the older collectors, but there is not a fixed size for them 固定大小的三个分区 分为一组相同大小的region，region用于组成分代eden、survisor、old，每个分代没有固定的大小 用户指定中断时间(pause time) G1在指定时间内，标记并优先回收存活数据（liveness object）较少的region G1会将几个region中幸存的数据合并拷贝到一个region，达到释放region的目的 G1 is not a real-time collector（大概吧🙂 在指定的时间内，能收集多少是多少） GC对比 CMS：不进行压缩（compact） ParallelOld：只能进行全堆压缩（while-heap compaction），会导致中断时间变长 When performing garbage collections, G1 operates in a manner similar to the CMS collector. G1 performs a concurrent global marking phase to determine the liveness of objects throughout the heap. After the mark phase completes, G1 knows which regions are mostly empty. It collects in these regions first, which usually yields a large amount of free space. This is why this method of garbage collection is called Garbage-First. As the name suggests, G1 concentrates its collection and compaction activity on the areas of the heap that are likely to be full of reclaimable objects, that is, garbage. G1 uses a pause prediction model to meet a user-defined pause time target and selects the number of regions to collect based on the specified pause time target. The regions identified by G1 as ripe for reclamation are garbage collected using evacuation. G1 copies objects from one or more regions of the heap to a single region on the heap, and in the process both compacts and frees up memory. This evacuation is performed in parallel on multi-processors, to decrease pause times and increase throughput. Thus, with each garbage collection, G1 continuously works to reduce fragmentation, working within the user defined pause times. This is beyond the capability of both the previous methods. CMS (Concurrent Mark Sweep ) garbage collector does not do compaction. ParallelOld garbage collection performs only whole-heap compaction, which results in considerable pause times. It is important to note that G1 is not a real-time collector. It meets the set pause time target with high probability but not absolute certainty. Based on data from previous collections, G1 does an estimate of how many regions can be collected within the user specified target time. Thus, the collector has a reasonably accurate model of the cost of collecting the regions, and it uses this model to determine which and how many regions to collect while staying within the pause time target. Note: G1 has both concurrent (runs along with application threads, e.g., refinement, marking, cleanup) and parallel (multi-threaded, e.g., stop the world) phases. Full garbage collections are still single threaded, but if tuned properly your applications should avoid full GCs. G1 Footprint（🙂 这个是占用空间的意思吧） 相比CMS或ParallelOldGC，G1的进程（JVM process size）会大些。因为需要存储记录region信息的RSets和CSets RSets: 每个region一个，记录region中的对象引用（object reference）内存占用小于5%； CSets: 记录将被回收的region（will be collected in a GC）内存占用小于1%； If you migrate from the ParallelOldGC or CMS collector to G1, you will likely see a larger JVM process size. This is largely related to “accounting” data structures such as Remembered Sets and Collection Sets. Remembered Sets or RSets track object references into a given region. There is one RSet per region in the heap. The RSet enables the parallel and independent collection of a region. The overall footprint impact of RSets is less than 5%. Collection Sets or CSets the set of regions that will be collected in a GC. All live data in a CSet is evacuated (copied/moved) during a GC. Sets of regions can be Eden, survivor, and/or old generation. CSets have a less than 1% impact on the size of the JVM. 哪些情况，我们适合换到G1 如果遇到这些情况，我们可以考虑迁移到GC full gc 耗时过长或太频繁 对象分配的速度差距较大 不希望GC暂停时间超过0.5-1秒 The first focus of G1 is to provide a solution for users running applications that require large heaps with limited GC latency. This means heap sizes of around 6GB or larger, and stable and predictable pause time below 0.5 seconds. Applications running today with either the CMS or the ParallelOldGC garbage collector would benefit switching to G1 if the application has one or more of the following traits. Full GC durations are too long or too frequent. The rate of object allocation rate or promotion varies significantly. Undesired long garbage collection or compaction pauses (longer than 0.5 to 1 second) Note: If you are using CMS or ParallelOldGC and your application is not experiencing long garbage collection pauses, it is fine to stay with your current collector. Changing to the G1 collector is not a requirement for using the latest JDK.]]></content>
      <tags>
        <tag>jvm</tag>
        <tag>gc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jvm 异常]]></title>
    <url>%2F2018%2F03%2F15%2Fjvm-memory-error%2F</url>
    <content type="text"><![CDATA[OutOfMemoryError 堆溢出123456789101112131415/** * VM Args: -Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError */public class HeapOOM &#123; static class OOMObject &#123; &#125; public static void main(String[] args) &#123; List&lt;OOMObject&gt; list = new ArrayList&lt;&gt;(); while (true) &#123; list.add(new OOMObject()); &#125; &#125;&#125; 运行结果 12345678910java.lang.OutOfMemoryError: Java heap spaceDumping heap to java_pid36288.hprof ...Heap dump file created [29130720 bytes in 0.332 secs]Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at java.base/java.util.Arrays.copyOf(Arrays.java:3719) at java.base/java.util.Arrays.copyOf(Arrays.java:3688) at java.base/java.util.ArrayList.grow(ArrayList.java:237) at java.base/java.util.ArrayList.grow(ArrayList.java:242) at java.base/java.util.ArrayList.add(ArrayList.java:467) at java.base/java.util.ArrayList.add(ArrayList.java:480) 虚拟机栈与本地方法栈溢出 线程请求的栈深度 &gt; 虚拟机允许的最大深度 –&gt; StackOverFlowError 虚拟机在扩展栈是无法申请到足够的内存空间 –&gt; OutOfMemoryError -Xss设置栈内存容量；Hotspot中-Xoss参数无效 12345678910111213141516171819202122/** * VM Args: -Xss144k */public class JavaVMStackSOF &#123; private int stackLength = 1; public void stackLeak() &#123; stackLength++; stackLeak(); &#125; public static void main(String[] args) &#123; JavaVMStackSOF oom = new JavaVMStackSOF(); try &#123; oom.stackLeak(); &#125; catch (Throwable e) &#123; System.out.printf(&quot;stack length:&quot; + oom.stackLength); throw e; &#125; &#125;&#125; 运行结果 12345678910stack length:495Exception in thread &quot;main&quot; java.lang.StackOverflowError at JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:9) at JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:10) at JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:10) at JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:10) at JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:10) at JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:10) at JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:10) ······· at JavaVMStackSOF.main(JavaVMStackSOF.java:16) 常量池内存溢出123456789101112131415/** * VM Args: -Xmx20m */public class RuntimeConstantPoolOOm &#123; public static void main(String[] args) &#123; // 保持对字符串的引用，防止被GC List&lt;String&gt; list = new ArrayList&lt;&gt;(); int i = 0; // 1.8后 字符串常量池位于堆中 while (true) &#123; list.add(String.valueOf(i++).intern()); &#125; &#125;&#125; 常量数量过多，导致堆溢出（1.8后不再有permGen）12345678Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at java.base/java.util.Arrays.copyOf(Arrays.java:3719) at java.base/java.util.Arrays.copyOf(Arrays.java:3688) at java.base/java.util.ArrayList.grow(ArrayList.java:237) at java.base/java.util.ArrayList.grow(ArrayList.java:242) at java.base/java.util.ArrayList.add(ArrayList.java:467) at java.base/java.util.ArrayList.add(ArrayList.java:480) at RuntimeConstantPoolOOm.main(RuntimeConstantPoolOOm.java:13) String intern() StringBuilder创建的字符串在Java Heap上；intern()方法的字符串 1.6：首次遇到的字符串实例复制到永久代，返回永久代中这个字符串的引用 1.7：不会复制实例，只在常量池（Constant Pool）中记录首次出现的实例的引用 1.7后，intern()的实现不会再复制实例，只是在常量池中记录首次出现的实例引用；因此intern()返回的引用和由StringBuilder创建的字符串上是同一个 12345678910public class RuntimeConstantPoolOOm &#123; public static void main(String[] args) &#123; // after 1.7: false (java在本次StringBuilder前，已经存在于虚拟机中，intern返回的jvm中第一次定义predef这个的地址) String ori = &quot;gaova&quot;; String target = new StringBuilder(&quot;gao&quot;).append(&quot;va&quot;).toString(); System.out.println(target.intern() == target); // false gaova首次出现的堆地址 != 通过StringBuilder新定义字符串的堆地址 System.out.println(ori == target.intern()); // true gaova首次出现的堆地址 == gaova首次出现的堆地址(intern获得，记录在常量池中的地址信息) &#125;&#125; 方法区溢出 1.8后，方法区（Method Area）从永久代（permGen）移入元空间（Metaspace）；因此，1.8后的方法区溢出实际为Metaspce区溢出：java.lang.OutOfMemoryError: Metaspace 123456789101112131415161718192021/** * 设置Metaspace区的初始和最大内存均为10m * VM Args: -XX:MetaspaceSize=10m -XX:MaxMetaspaceSize=10m */public class JavaMethodAreaOOM &#123; static class OOMObject &#123; &#125; public static void main(String[] args) &#123; while (true) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(OOMObject.class); enhancer.setUseCache(false); enhancer.setCallback( (MethodInterceptor) (obj, method, args1, proxy) -&gt; proxy.invokeSuper(obj, args1)); enhancer.create(); &#125; &#125;&#125; 溢出12345678[2.541s][info][gc,metaspace,freelist] Metaspace (data) allocation failed for size 42[2.541s][info][gc,metaspace,freelist] All Metaspace:[2.541s][info][gc,metaspace,freelist] data space: Chunk accounting: used in chunks 9266K + unused in chunks 72K + capacity in free chunks 5K = 9344K capacity in allocated chunks 9339K[2.541s][info][gc,metaspace,freelist] class space: Chunk accounting: used in chunks 825K + unused in chunks 33K + capacity in free chunks 3K = 862K capacity in allocated chunks 859K[2.541s][info][gc,metaspace,freelist] Total fragmentation waste (words) doesn&apos;t count free space[2.541s][info][gc,metaspace,freelist] data: 11 specialized(s) 24, 28 small(s) 47, 80 medium(s) 164, large count 1[2.541s][info][gc,metaspace,freelist] class: 11 specialized(s) 0, 8 small(s) 0, 14 medium(s) 6, large count 1java.lang.OutOfMemoryError: Metaspace 直接内存溢出 直接内存溢出的特点Heap Dump文件中不会看到明显异常；此时可以检查是否有直接使用NIO的地方 属于C Heap，可以通过参数-XX:MaxDirectMemorySize指定。如果不指定，该参数的默认值为Xmx的值减去1个Survior区的值。如设置启动参数-Xmx20M -Xmn10M -XX：SurvivorRatio=8,那么申请20M-1M=19M的DirectMemory是没有问题的。 1234567891011/** * VM Args: -Xmx20m -XX:MaxDirectMemorySize=10M -Xlog:gc* */public class DirectMemoryOOM &#123; private static final int _1MB = 1024 * 1024; public static void main(String[] args) &#123; ByteBuffer.allocateDirect(11 * _1MB); &#125;&#125; 12345678910111213141516171819202122232425262728293031[0.016s][info][gc,heap] Heap region size: 1M[0.020s][info][gc ] Using G1[0.020s][info][gc,heap,coops] Heap address: 0x00000007bec00000, size: 20 MB, Compressed Oops mode: Zero based, Oop shift amount: 3[0.317s][info][gc,start ] GC(0) Pause Full (System.gc())[0.317s][info][gc,phases,start] GC(0) Phase 1: Mark live objects[0.320s][info][gc,stringtable ] GC(0) Cleaned string and symbol table, strings: 3056 processed, 15 removed, symbols: 22759 processed, 0 removed[0.320s][info][gc,phases ] GC(0) Phase 1: Mark live objects 3.421ms[0.320s][info][gc,phases,start] GC(0) Phase 2: Compute new object addresses[0.321s][info][gc,phases ] GC(0) Phase 2: Compute new object addresses 0.881ms[0.321s][info][gc,phases,start] GC(0) Phase 3: Adjust pointers[0.323s][info][gc,phases ] GC(0) Phase 3: Adjust pointers 1.495ms[0.323s][info][gc,phases,start] GC(0) Phase 4: Move objects[0.324s][info][gc,phases ] GC(0) Phase 4: Move objects 1.116ms[0.324s][info][gc,task ] GC(0) Using 4 workers of 4 to rebuild remembered set[0.326s][info][gc,heap ] GC(0) Eden regions: 3-&gt;0(2)[0.326s][info][gc,heap ] GC(0) Survivor regions: 0-&gt;0(0)[0.326s][info][gc,heap ] GC(0) Old regions: 0-&gt;2[0.326s][info][gc,heap ] GC(0) Humongous regions: 0-&gt;0[0.326s][info][gc,metaspace ] GC(0) Metaspace: 4904K-&gt;4904K(1056768K)[0.326s][info][gc ] GC(0) Pause Full (System.gc()) 2M-&gt;1M(8M) 9.001ms[0.326s][info][gc,cpu ] GC(0) User=0.01s Sys=0.00s Real=0.01sException in thread &quot;main&quot; java.lang.OutOfMemoryError: Direct buffer memory at java.base/java.nio.Bits.reserveMemory(Bits.java:187) at java.base/java.nio.DirectByteBuffer.&lt;init&gt;(DirectByteBuffer.java:123) at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:310) at DirectMemoryOOM.main(DirectMemoryOOM.java:11)[0.858s][info][gc,heap,exit ] Heap[0.858s][info][gc,heap,exit ] garbage-first heap total 8192K, used 1036K [0x00000007bec00000, 0x00000007bed00040, 0x00000007c0000000)[0.858s][info][gc,heap,exit ] region size 1024K, 1 young (1024K), 0 survivors (0K)[0.858s][info][gc,heap,exit ] Metaspace used 5212K, capacity 5244K, committed 5376K, reserved 1056768K[0.858s][info][gc,heap,exit ] class space used 472K, capacity 492K, committed 512K, reserved 1048576K]]></content>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[String#intern的那些事儿]]></title>
    <url>%2F2018%2F03%2F15%2Fstring-intern%2F</url>
    <content type="text"><![CDATA[引言在 JAVA 语言中有8中基本类型和一种比较特殊的类型String。这些类型为了使他们在运行过程中速度更快，更节省内存，都提供了一种常量池的概念。常量池就类似一个JAVA系统级别提供的缓存。 8种基本类型的常量池都是系统协调的，String类型的常量池比较特殊。它的主要使用方法有两种： 直接使用双引号声明出来的String对象会直接存储在常量池中。 如果不是用双引号声明的String对象，可以使用String提供的intern方法。intern 方法会从字符串常量池中查询当前字符串是否存在，若不存在就会将当前字符串放入常量池中 接下来我们主要来谈一下String#intern方法。 一, intern 的实现原理首先深入看一下它的实现原理。 1，JAVA 代码123456789101112131415161718192021222324/** * Returns a canonical representation for the string object. * &lt;p&gt; * A pool of strings, initially empty, is maintained privately by the * class &lt;code&gt;String&lt;/code&gt;. * &lt;p&gt; * When the intern method is invoked, if the pool already contains a * string equal to this &lt;code&gt;String&lt;/code&gt; object as determined by * the &#123;@link #equals(Object)&#125; method, then the string from the pool is * returned. Otherwise, this &lt;code&gt;String&lt;/code&gt; object is added to the * pool and a reference to this &lt;code&gt;String&lt;/code&gt; object is returned. * &lt;p&gt; * It follows that for any two strings &lt;code&gt;s&lt;/code&gt; and &lt;code&gt;t&lt;/code&gt;, * &lt;code&gt;s.intern()&amp;nbsp;==&amp;nbsp;t.intern()&lt;/code&gt; is &lt;code&gt;true&lt;/code&gt; * if and only if &lt;code&gt;s.equals(t)&lt;/code&gt; is &lt;code&gt;true&lt;/code&gt;. * &lt;p&gt; * All literal strings and string-valued constant expressions are * interned. String literals are defined in section 3.10.5 of the * &lt;cite&gt;The Java&amp;trade; Language Specification&lt;/cite&gt;. * * @return a string that has the same contents as this string, but is * guaranteed to be from a pool of unique strings. */ public native String intern(); String#intern方法中看到，这个方法是一个 native 的方法，但注释写的非常明了。“如果常量池中存在当前字符串, 就会直接返回当前字符串. 如果常量池中没有此字符串, 会将此字符串放入常量池中后, 再返回”。 2，native 代码在 jdk7后，oracle 接管了 JAVA 的源码后就不对外开放了，根据 jdk 的主要开发人员声明 openJdk7 和 jdk7 使用的是同一分主代码，只是分支代码会有些许的变动。所以可以直接跟踪 openJdk7 的源码来探究 intern 的实现。 ####native实现代码:\openjdk7\jdk\src\share\native\java\lang\String.c 1234Java_java_lang_String_intern(JNIEnv *env, jobject this) &#123; return JVM_InternString(env, this); &#125; \openjdk7\hotspot\src\share\vm\prims\jvm.h 12345/* * java.lang.String */ JNIEXPORT jstring JNICALL JVM_InternString(JNIEnv *env, jstring str); \openjdk7\hotspot\src\share\vm\prims\jvm.cpp 123456789// String support /////////////////////////////////////////////////////////////////////////// JVM_ENTRY(jstring, JVM_InternString(JNIEnv *env, jstring str)) JVMWrapper(&quot;JVM_InternString&quot;); JvmtiVMObjectAllocEventCollector oam; if (str == NULL) return NULL; oop string = JNIHandles::resolve_non_null(str); oop result = StringTable::intern(string, CHECK_NULL); return (jstring) JNIHandles::make_local(env, result); JVM_END \openjdk7\hotspot\src\share\vm\classfile\symbolTable.cpp 1234567891011oop StringTable::intern(Handle string_or_null, jchar* name, int len, TRAPS) &#123; unsigned int hashValue = java_lang_String::hash_string(name, len); int index = the_table()-&gt;hash_to_index(hashValue); oop string = the_table()-&gt;lookup(index, name, len, hashValue); // Found if (string != NULL) return string; // Otherwise, add to symbol to table return the_table()-&gt;basic_add(index, string_or_null, name, len, hashValue, CHECK_NULL); &#125; \openjdk7\hotspot\src\share\vm\classfile\symbolTable.cpp 1234567891011oop StringTable::lookup(int index, jchar* name, int len, unsigned int hash) &#123; for (HashtableEntry&lt;oop&gt;* l = bucket(index); l != NULL; l = l-&gt;next()) &#123; if (l-&gt;hash() == hash) &#123; if (java_lang_String::equals(l-&gt;literal(), name, len)) &#123; return l-&gt;literal(); &#125; &#125; &#125; return NULL; &#125; 它的大体实现结构就是:JAVA 使用 jni 调用c++实现的StringTable的intern方法, StringTable的intern方法跟Java中的HashMap的实现是差不多的, 只是不能自动扩容。默认大小是1009。 要注意的是，String的String Pool是一个固定大小的Hashtable，默认值大小长度是1009，如果放进String Pool的String非常多，就会造成Hash冲突严重，从而导致链表会很长，而链表长了后直接会造成的影响就是当调用String.intern时性能会大幅下降（因为要一个一个找）。 在 jdk6中StringTable是固定的，就是1009的长度，所以如果常量池中的字符串过多就会导致效率下降很快。在jdk7中，StringTable的长度可以通过一个参数指定： -XX:StringTableSize=99991 二，jdk6 和 jdk7 下 intern 的区别相信很多 JAVA 程序员都做做类似 String s = new String(&quot;abc&quot;)这个语句创建了几个对象的题目。 这种题目主要就是为了考察程序员对字符串对象的常量池掌握与否。上述的语句中是创建了2个对象，第一个对象是”abc”字符串存储在常量池中，第二个对象在JAVA Heap中的 String 对象。 来看一段代码： 1234567891011public static void main(String[] args) &#123; String s = new String(&quot;1&quot;); s.intern(); String s2 = &quot;1&quot;; System.out.println(s == s2); String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;); s3.intern(); String s4 = &quot;11&quot;; System.out.println(s3 == s4);&#125; 打印结果是 jdk6 下false false jdk7 下false true 具体为什么稍后再解释，然后将s3.intern();语句下调一行，放到String s4 = &quot;11&quot;;后面。将s.intern(); 放到String s2 = &quot;1&quot;;后面。是什么结果呢 1234567891011public static void main(String[] args) &#123; String s = new String(&quot;1&quot;); String s2 = &quot;1&quot;; s.intern(); System.out.println(s == s2); String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;); String s4 = &quot;11&quot;; s3.intern(); System.out.println(s3 == s4);&#125; 打印结果为： jdk6 下false false jdk7 下false false ####1，jdk6中的解释 注：图中绿色线条代表 string 对象的内容指向。 黑色线条代表地址指向。 如上图所示。首先说一下 jdk6中的情况，在 jdk6中上述的所有打印都是 false 的，因为 jdk6中的常量池是放在 Perm 区中的，Perm 区和正常的 JAVA Heap 区域是完全分开的。上面说过如果是使用引号声明的字符串都是会直接在字符串常量池中生成，而 new 出来的 String 对象是放在 JAVA Heap 区域。所以拿一个 JAVA Heap 区域的对象地址和字符串常量池的对象地址进行比较肯定是不相同的，即使调用String.intern方法也是没有任何关系的。 ####2，jdk7中的解释 再说说 jdk7 中的情况。这里要明确一点的是，在 Jdk6 以及以前的版本中，字符串的常量池是放在堆的 Perm 区的，Perm 区是一个类静态的区域，主要存储一些加载类的信息，常量池，方法片段等内容，默认大小只有4m，一旦常量池中大量使用 intern 是会直接产生java.lang.OutOfMemoryError: PermGen space错误的。 所以在 jdk7 的版本中，字符串常量池已经从 Perm 区移到正常的 Java Heap 区域了。为什么要移动，Perm 区域太小是一个主要原因，当然据消息称 jdk8 已经直接取消了 Perm 区域，而新建立了一个元区域。应该是 jdk 开发者认为 Perm 区域已经不适合现在 JAVA 的发展了。 正式因为字符串常量池移动到 JAVA Heap 区域后，再来解释为什么会有上述的打印结果。 在第一段代码中，先看 s3和s4字符串。String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;);，这句代码中现在生成了2最终个对象，是字符串常量池中的“1” 和 JAVA Heap 中的 s3引用指向的对象。中间还有2个匿名的new String(&quot;1&quot;)我们不去讨论它们。此时s3引用对象内容是”11”，但此时常量池中是没有 “11”对象的。 接下来s3.intern();这一句代码，是将 s3中的“11”字符串放入 String 常量池中，因为此时常量池中不存在“11”字符串，因此常规做法是跟 jdk6 图中表示的那样，在常量池中生成一个 “11” 的对象，关键点是 jdk7 中常量池不在 Perm 区域了，这块做了调整。常量池中不需要再存储一份对象了，可以直接存储堆中的引用。这份引用指向 s3 引用的对象。 也就是说引用地址是相同的。 最后String s4 = &quot;11&quot;; 这句代码中”11”是显示声明的，因此会直接去常量池中创建，创建的时候发现已经有这个对象了，此时也就是指向 s3 引用对象的一个引用。所以 s4 引用就指向和 s3 一样了。因此最后的比较 s3 == s4 是 true。 再看 s 和 s2 对象。 String s = new String(&quot;1&quot;); 第一句代码，生成了2个对象。常量池中的“1” 和 JAVA Heap 中的字符串对象。s.intern(); 这一句是 s 对象去常量池中寻找后发现 “1” 已经在常量池里了。 接下来String s2 = &quot;1&quot;; 这句代码是生成一个 s2的引用指向常量池中的“1”对象。 结果就是 s 和 s2 的引用地址明显不同。图中画的很清晰。 来看第二段代码，从上边第二幅图中观察。第一段代码和第二段代码的改变就是 s3.intern(); 的顺序是放在String s4 = &quot;11&quot;;后了。这样，首先执行String s4 = &quot;11&quot;;声明 s4 的时候常量池中是不存在“11”对象的，执行完毕后，“11“对象是 s4 声明产生的新对象。然后再执行s3.intern();时，常量池中“11”对象已经存在了，因此 s3 和 s4 的引用是不同的。 第二段代码中的 s 和 s2 代码中，s.intern();，这一句往后放也不会有什么影响了，因为对象池中在执行第一句代码String s = new String(&quot;1&quot;);的时候已经生成“1”对象了。下边的s2声明都是直接从常量池中取地址引用的。 s 和 s2 的引用地址是不会相等的。 ####小结从上述的例子代码可以看出 jdk7 版本对 intern 操作和常量池都做了一定的修改。主要包括2点： 将String常量池 从 Perm 区移动到了 Java Heap区 String#intern 方法时，如果存在堆中的对象，会直接保存对象的引用，而不会重新创建对象。 三，使用 intern1,intern 正确使用例子接下来我们来看一下一个比较常见的使用String#intern方法的例子。 代码如下： 123456789101112131415161718static final int MAX = 1000 * 10000;static final String[] arr = new String[MAX];public static void main(String[] args) throws Exception &#123; Integer[] DB_DATA = new Integer[10]; Random random = new Random(10 * 10000); for (int i = 0; i &lt; DB_DATA.length; i++) &#123; DB_DATA[i] = random.nextInt(); &#125; long t = System.currentTimeMillis(); for (int i = 0; i &lt; MAX; i++) &#123; //arr[i] = new String(String.valueOf(DB_DATA[i % DB_DATA.length])); arr[i] = new String(String.valueOf(DB_DATA[i % DB_DATA.length])).intern(); &#125; System.out.println((System.currentTimeMillis() - t) + &quot;ms&quot;); System.gc();&#125; 运行的参数是：-Xmx2g -Xms2g -Xmn1500M 上述代码是一个演示代码，其中有两条语句不一样，一条是使用 intern，一条是未使用 intern。结果如下图 2160ms 826ms 通过上述结果，我们发现不使用 intern 的代码生成了1000w 个字符串，占用了大约640m 空间。 使用了 intern 的代码生成了1345个字符串，占用总空间 133k 左右。其实通过观察程序中只是用到了10个字符串，所以准确计算后应该是正好相差100w 倍。虽然例子有些极端，但确实能准确反应出 intern 使用后产生的巨大空间节省。 细心的同学会发现使用了 intern 方法后时间上有了一些增长。这是因为程序中每次都是用了 new String 后，然后又进行 intern 操作的耗时时间，这一点如果在内存空间充足的情况下确实是无法避免的，但我们平时使用时，内存空间肯定不是无限大的，不使用 intern 占用空间导致 jvm 垃圾回收的时间是要远远大于这点时间的。 毕竟这里使用了1000w次intern 才多出来1秒钟多的时间。 2，intern 不当使用看过了 intern 的使用和 intern 的原理等，我们来看一个不当使用 intern 操作导致的问题。 在使用 fastjson 进行接口读取的时候，我们发现在读取了近70w条数据后，我们的日志打印变的非常缓慢，每打印一次日志用时30ms左右，如果在一个请求中打印2到3条日志以上会发现请求有一倍以上的耗时。在重新启动 jvm 后问题消失。继续读取接口后，问题又重现。接下来我们看一下出现问题的过程。 ####1，根据 log4j 打印日志查找问题原因 在使用log4j#info打印日志的时候时间非常长。所以使用 housemd 软件跟踪 info 方法的耗时堆栈。 trace SLF4JLogger. trace AbstractLoggerWrapper: trace AsyncLogger 123org/apache/logging/log4j/core/async/AsyncLogger.actualAsyncLog(RingBufferLogEvent) sun.misc.Launcher$AppClassLoader@109aca82 1 1ms org.apache.logging.log4j.core.async.AsyncLogger@19de86bb org/apache/logging/log4j/core/async/AsyncLogger.location(String) sun.misc.Launcher$AppClassLoader@109aca82 1 30ms org.apache.logging.log4j.core.async.AsyncLogger@19de86bb org/apache/logging/log4j/core/async/AsyncLogger.log(Marker, String, Level, Message, Throwable) sun.misc.Launcher$AppClassLoader@109aca82 1 61ms org.apache.logging.log4j.core.async.AsyncLogger@19de86bb 代码出在 AsyncLogger.location 这个方法上. 里边主要是调用了 return Log4jLogEvent.calcLocation(fqcnOfLogger);和Log4jLogEvent.calcLocation() Log4jLogEvent.calcLocation()的代码如下: 12345678910111213141516171819202122public static StackTraceElement calcLocation(final String fqcnOfLogger) &#123; if (fqcnOfLogger == null) &#123; return null; &#125; final StackTraceElement[] stackTrace = Thread.currentThread().getStackTrace(); boolean next = false; for (final StackTraceElement element : stackTrace) &#123; final String className = element.getClassName(); if (next) &#123; if (fqcnOfLogger.equals(className)) &#123; continue; &#125; return element; &#125; if (fqcnOfLogger.equals(className)) &#123; next = true; &#125; else if (NOT_AVAIL.equals(className)) &#123; break; &#125; &#125; return null; &#125; 经过跟踪发现是 Thread.currentThread().getStackTrace(); 的问题。 ####2, 跟踪Thread.currentThread().getStackTrace()的 native 代码，验证String#intern Thread.currentThread().getStackTrace();native的方法: 123456789101112131415161718192021222324252627public StackTraceElement[] getStackTrace() &#123; if (this != Thread.currentThread()) &#123; // check for getStackTrace permission SecurityManager security = System.getSecurityManager(); if (security != null) &#123; security.checkPermission( SecurityConstants.GET_STACK_TRACE_PERMISSION); &#125; // optimization so we do not call into the vm for threads that // have not yet started or have terminated if (!isAlive()) &#123; return EMPTY_STACK_TRACE; &#125; StackTraceElement[][] stackTraceArray = dumpThreads(new Thread[] &#123;this&#125;); StackTraceElement[] stackTrace = stackTraceArray[0]; // a thread that was alive during the previous isAlive call may have // since terminated, therefore not having a stacktrace. if (stackTrace == null) &#123; stackTrace = EMPTY_STACK_TRACE; &#125; return stackTrace; &#125; else &#123; // Don&apos;t need JVM help for current thread return (new Exception()).getStackTrace(); &#125; &#125; private native static StackTraceElement[][] dumpThreads(Thread[] threads); 下载 openJdk7的源码查询 jdk 的 native 实现代码，列表如下【这里因为篇幅问题，不详细罗列涉及到的代码，有兴趣的可以根据文件名称和行号查找相关代码】： \openjdk7\jdk\src\share\native\java\lang\Thread.c\openjdk7\hotspot\src\share\vm\prims\jvm.h line:294:\openjdk7\hotspot\src\share\vm\prims\jvm.cpp line:4382-4414:\openjdk7\hotspot\src\share\vm\services\threadService.cpp line:235-267:\openjdk7\hotspot\src\share\vm\services\threadService.cpp line:566-577:\openjdk7\hotspot\src\share\vm\classfile\javaClasses.cpp line:1635-[1651,1654,1658]: 完成跟踪了底层的 jvm 源码后发现，是下边的三条代码引发了整个程序的变慢问题。 123oop classname = StringTable::intern((char*) str, CHECK_0); oop methodname = StringTable::intern(method-&gt;name(), CHECK_0); oop filename = StringTable::intern(source, CHECK_0); 这三段代码是获取类名、方法名、和文件名。因为类名、方法名、文件名都是存储在字符串常量池中的，所以每次获取它们都是通过String#intern方法。但没有考虑到的是默认的 StringPool 的长度是1009且不可变的。因此一旦常量池中的字符串达到的一定的规模后，性能会急剧下降。 ####3,fastjson 不当使用 String#intern 导致这个 intern 变慢的原因是因为 fastjson 对String#intern方法的使用不当造成的。跟踪 fastjson 中的实现代码发现， ####com.alibaba.fastjson.parser.JSONScanner#scanFieldSymbol() 123456if (ch == &apos;\&quot;&apos;) &#123; bp = index; this.ch = ch = buf[bp]; strVal = symbolTable.addSymbol(buf, start, index - start - 1, hash); break;&#125; ####com.alibaba.fastjson.parser.SymbolTable#addSymbol(): 1234567891011/** * Constructs a new entry from the specified symbol information and next entry reference. */public Entry(char[] ch, int offset, int length, int hash, Entry next)&#123; characters = new char[length]; System.arraycopy(ch, offset, characters, 0, length); symbol = new String(characters).intern(); this.next = next; this.hashCode = hash; this.bytes = null;&#125; fastjson 中对所有的 json 的 key 使用了 intern 方法，缓存到了字符串常量池中，这样每次读取的时候就会非常快，大大减少时间和空间。而且 json 的 key 通常都是不变的。这个地方没有考虑到大量的 json key 如果是变化的，那就会给字符串常量池带来很大的负担。 这个问题 fastjson 在1.1.24版本中已经将这个漏洞修复了。程序加入了一个最大的缓存大小，超过这个大小后就不会再往字符串常量池中放了。 [1.1.24版本的com.alibaba.fastjson.parser.SymbolTable#addSymbol() Line:113]代码 12345public static final int MAX_SIZE = 1024;if (size &gt;= MAX_SIZE) &#123; return new String(buffer, offset, len);&#125; 这个问题是70w 数据量时候的引发的，如果是几百万的数据量的话可能就不只是30ms 的问题了。因此在使用系统级提供的String#intern方式一定要慎重！ 五，总结本文大体的描述了 String#intern和字符串常量池的日常使用，jdk 版本的变化和String#intern方法的区别，以及不恰当使用导致的危险等内容，让大家对系统级别的 String#intern有一个比较深入的认识。让我们在使用和接触它的时候能避免出现一些 bug，增强系统的健壮性。 引用：以下是几个比较关键的几篇博文。感谢！ Save Memory by Using String Intern in Java Java String array: is there a size of method? Understanding String Table Size in HotSpot How is Java’s String#intern() method implemented? JDK7里的String.intern的变化]]></content>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM的Heap Memory和Native Memory]]></title>
    <url>%2F2018%2F03%2F12%2Fjvm-heap-memory-vs-native-memory%2F</url>
    <content type="text"><![CDATA[Jvm 内存划分1.8前，permGen仍未移除前 jvm管理的内存可以总体划分为两部分 Heap Memory供Java应用程序使用；Heap Memory及其内部各组成的大小可以通过JVM的一系列命令行参数来控制 Native Memory也称为C-Heap，是供JVM自身进程使用的；Native Memory没有相应的参数来控制大小，其大小依赖于操作系统进程的最大值（对于32位系统就是3~4G，各种系统的实现并不一样），以及生成的Java字节码大小、创建的线程数量、维持java对象的状态信息大小（用于GC）以及一些第三方的包，比如JDBC驱动使用的native内存。 Native Memory 存储的内容 管理java heap的状态数据（用于GC）; JNI调用，也就是Native Stack; JIT（即使编译器）编译时使用Native Memory，并且JIT的输入（Java字节码）和输出（可执行代码）也都是保存在Native Memory； NIO direct buffer。对于IBM JVM和Hotspot，都可以通过-XX:MaxDirectMemorySize来设置nio直接缓冲区的最大值。默认是64M。超过这个时，会按照32M自动增大。 对于IBM的JVM某些版本实现，类加载器和类信息都是保存在Native Memory中的。 Native Memory 溢出简单理解 java process memory = java heap + native memory 因此内存溢出时，首先要区分是堆内存溢出还是本地内存溢出。Native Memory本质上就是因为耗尽了进程地址空间。对于 HotSpot jvm来书，不断的分配直接内存，会导致如下错误信息：Allocated 1953546760 bytes of native memory before running out Direct Buffer DirectBuffer对象的数据实际是保存在native heap中，但是引用保存在HeapBuffer中。 DirectBuffer访问更快，避免了从HeapBuffer还需要从java堆拷贝到本地堆，操作系统直接访问的是DirectBuffer。另外，DirectBuffer的引用是直接分配在堆得Old区的，因此其回收时机是在FullGC时。因此，需要避免频繁的分配DirectBuffer，这样很容易导致Native Memory溢出。 线程这里所说的线程指程序执行过程中的一个线程实体。JVM 允许一个应用并发执行多个线程。Hotspot JVM 中的 Java 线程与原生操作系统线程有直接的映射关系。当线程本地存储、缓冲区分配、同步对象、栈、程序计数器等准备好以后，就会创建一个操作系统原生线程。Java 线程结束，原生线程随之被回收。操作系统负责调度所有线程，并把它们分配到任何可用的 CPU 上。当原生线程初始化完毕，就会调用 Java 线程的 run() 方法。run() 返回时，被处理未捕获异常，原生线程将确认由于它的结束是否要终止 JVM 进程（比如这个线程是最后一个非守护线程）。当线程结束时，会释放原生线程和 Java 线程的所有资源。 Jvm 系统线程如果使用 jconsole 或者其它调试器，很多线程在后台运行。这些后台线程与触发 public static void main(String[])函数的主线程以及主线程创建的其他线程一起运行。Hotspot JVM 后台运行的系统线程主要有下面几个： 线程 用途 虚拟机线程（VM thread） 这个线程等待 JVM 到达安全点操作出现。这些操作必须要在独立的线程里执行，因为当堆修改无法进行时，线程都需要 JVM 位于安全点。这些操作的类型有：stop-the-world 垃圾回收、线程栈 dump、线程暂停、线程偏向锁（biased locking）解除。 周期性任务线程 这线程负责定时器事件（也就是中断），用来调度周期性操作的执行。 GC 线程 这些线程支持 JVM 中不同的垃圾回收活动。 编译器线程 这些线程在运行时将字节码动态编译成本地平台相关的机器码。 信号分发线程 这个线程接收发送到 JVM 的信号并调用适当的Jvm方法处理。 线程相关组件每个运行的线程 都 包含 下面这些组件 线程计数器（Program Counter Register） 本地方法栈（Native Stack） 栈（Stack） 栈帧（Frame） 程序计数器（Program Counter Register） 一块较小的内存地址。可以看做当前锁执行的字节码的行号指示器； PC 指当前指令（或操作码）的地址，本地指令除外。如果当前方法是 native 方法，那么PC 的值为 undefined。所有的 CPU 都有一个 PC，典型状态下，每执行一条指令 PC 都会自增，因此 PC 存储了指向下一条要被执行的指令地址。JVM 用 PC 来跟踪指令执行的位置，PC 将实际上是指向方法区（Method Area）的一个内存地址。 由于Java虚拟机的多线程是通过线程轮流切换并分配处理器的执行时间的方式实现，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个核）都只会执行一条线程中的指令。 本地方法栈（Native Stack）并非所有的 JVM 实现都支持本地（native）方法，那些提供支持的 JVM 一般都会为每个线程创建本地方法栈。如果 JVM 用 C-linkage 模型实现 JNI（Java Native Invocation），那么本地栈就是一个 C 的栈。在这种情况下，本地方法栈的参数顺序、返回值和典型的 C 程序相同。本地方法一般来说可以（依赖 JVM 的实现）反过来调用 JVM 中的 Java 方法。这种 native 方法调用 Java 会发生在栈（一般是 Java 栈）上；线程将离开本地方法栈，并在 Java 栈上开辟一个新的栈帧。 虚拟机栈 vs 本地方法栈 虚拟机栈：为虚拟机执行Java方法服务（字节码） 本地方法栈：虚拟机使用到的Native方法服务 栈（Stack） 描述Java方法执行的内存模型：每个方法在执行时都会创建一个栈帧（Stack Frame）用于存储：局部变量表、操作数栈、动态链接、方法出口等每个方法从调用直至执行完成的过程，对应一个栈帧在虚拟机栈中入栈到出栈的过程； 每个线程拥有自己的栈，栈包含每个方法执行的栈帧。栈是一个后进先出（LIFO）的数据结构，因此当前执行的方法在栈的顶部。每次方法调用时，一个新的栈帧创建并压栈到栈顶。当方法正常返回或抛出未捕获的异常时，栈帧就会出栈。除了栈帧的压栈和出栈，栈不能被直接操作。所以可以在堆上分配栈帧，并且不需要连续内存。 栈的限制栈可以是动态分配也可以固定大小。 如果线程请求一个超过允许范围的空间，就会抛出一个StackOverflowError 如果线程需要一个新的栈帧，但是没有足够的内存可以分配，就会抛出一个 OutOfMemoryError。 栈帧（Frame）每次方法调用都会新建一个新的栈帧并把它压栈到栈顶。当方法正常返回或者调用过程中抛出未捕获的异常时，栈帧将出栈。更多关于异常处理的细节，可以参考下面的异常信息表章节。 每个栈帧包含： 局部变量数组 返回值 操作数栈 类当前方法的运行时常量池引用 局部变量数组（Local Variable）局部变量数组包含了方法执行过程中的所有变量，包括 this 引用、所有方法参数、其他局部变量。对于类方法（也就是静态方法），方法参数从下标 0 开始，对于对象方法，位置0保留为 this。有下面这些局部变量： boolean byte char long short int float double reference returnAddress 除了 long 和 double 类型以外，所有的变量类型都占用局部变量数组的一个位置。long 和 double 需要占用局部变量数组两个连续的位置，因为它们是 64 位双精度，其它类型都是 32 位单精度。 操作数栈（Operand Variable）操作数栈在执行字节码指令过程中被用到，这种方式类似于原生 CPU 寄存器。大部分 JVM 字节码把时间花费在操作数栈的操作上：入栈、出栈、复制、交换、产生消费变量的操作。因此，局部变量数组和操作数栈之间的交换变量指令操作通过字节码频繁执行。比如，一个简单的变量初始化语句将产生两条跟操作数栈交互的字节码。 1int i; 被编译成下面的字节码： 120: iconst_0 // Push 0 to top of the operand stack1: istore_1 // Pop value from top of operand stack and store as local variable 1 动态链接 每个栈帧都有一个运行时常量池的引用 这个引用指向栈帧当前运行方法所在类的常量池。通过这个引用支持动态链接（dynamic linking）。 C/C++ 代码一般被编译成对象文件，然后多个对象文件被链接到一起产生可执行文件或者 dll。在链接阶段，每个对象文件的符号引用被替换成了最终执行文件的相对偏移内存地址。在 Java中，链接阶段是运行时动态完成的。 当 Java 类文件编译时，所有变量和方法的引用都被当做符号引用存储在这个类的常量池中。符号引用是一个逻辑引用，实际上并不指向物理内存地址。JVM 可以选择符号引用解析的时机，一种是当类文件加载并校验通过后，这种解析方式被称为饥饿方式。另外一种是符号引用在第一次使用的时候被解析，这种解析方式称为惰性方式。无论如何 ，JVM 必须要在第一次使用符号引用时完成解析并抛出可能发生的解析错误。绑定是将对象域、方法、类的符号引用替换为直接引用的过程。绑定只会发生一次。一旦绑定，符号引用会被完全替换。如果一个类的符号引用还没有被解析，那么就会载入这个类。每个直接引用都被存储为相对于存储结构（与运行时变量或方法的位置相关联的）偏移量。 线程共享类的元数据, 字符串池, 类的静态变量将会从永久代移除, 放入Java heap或者native memory. 其中建议JVM的实现中将类的元数据放入 native memory, 将字符串池和类的静态变量放入java堆中. 这样可以加载多少类的元数据就不在由MaxPermSize控制, 而由系统的实际可用空间来控制. 内存管理（Memory Management）对象和数组永远不会显式回收，而是由垃圾回收器自动回收。通常，过程是这样的： 新的对象和数组被创建并放入老年代。 Minor垃圾回收将发生在新生代。依旧存活的对象将从 eden 区移到 survivor 区。 Major垃圾回收一般会导致应用进程暂停，它将在三个区内移动对象。仍然存活的对象将被从新生代移动到老年代。 每次进行老年代回收时也会进行永久代回收。它们之中任何一个变满时，都会进行回收。 堆（Heap）堆被用来在运行时分配类实例、数组。不能在栈上存储数组和对象。因为栈帧被设计为创建以后无法调整大小。栈帧只存储指向堆中对象或数组的引用。与局部变量数组（每个栈帧中的）中的原始类型和引用类型不同，对象总是存储在堆上以便在方法结束时不会被移除。对象只能由垃圾回收器移除。 非堆内存（No-Heap Memory，Native Memory）1.8永久代废弃前 永久代，包括： 方法区（Method Area） 驻留字符串（interned strings） 代码缓存（Code Cache）：用于编译和存储那些被 JIT 编译器编译成原生代码的方法。 1.8后： 方法区（Method Area）、符号引用（Symbols）移入Metaspace； Interned Strings、class statics（静态变量），移入Java Heap 方法区（Method Area） Classloader 引用 运行时常量池（Runtime Constant Pool） 数值型常量 字段引用 方法引用 属性 字段数据 针对每个字段的信息 字段名 类型 修饰符 属性（Attribute） 方法数据 每个方法 方法名 返回值类型 参数类型（按顺序） 修饰符 属性 方法代码（Method Code） 每个方法 字节码 操作数栈大小 局部变量大小 局部变量表 异常表 每个异常处理器 开始点 结束点 异常处理代码的程序计数器（PC）偏移量 被捕获的异常类对应的常量池下标 类文件结构编译后的类文件包含下面的结构：123456789101112131415161718ClassFile &#123; u4 magic; u2 minor_version; u2 major_version; u2 constant_pool_count; cp_info contant_pool[constant_pool_count – 1]; u2 access_flags; u2 this_class; u2 super_class; u2 interfaces_count; u2 interfaces[interfaces_count]; u2 fields_count; field_info fields[fields_count]; u2 methods_count; method_info methods[methods_count]; u2 attributes_count; attribute_info attributes[attributes_count];&#125; 变量 描述 magic, minor_version, major_version 类文件的版本信息和用于编译这个类的 JDK 版本。 constant_pool 类似于符号表，尽管它包含更多数据。下面有更多的详细描述。 access_flags 提供这个类的描述符列表。 this_class 提供这个类全名的常量池(constant_pool)索引，比如org/jamesdbloom/foo/Bar。 super_class 提供这个类的父类符号引用的常量池索引。 interfaces 指向常量池的索引数组，提供那些被实现的接口的符号引用。 fields 提供每个字段完整描述的常量池索引数组。 methods 指向constant_pool的索引数组，用于表示每个方法签名的完整描述。如果这个方法不是抽象方法也不是 native 方法，那么就会显示这个函数的字节码。 attributes 不同值的数组，表示这个类的附加信息，包括 RetentionPolicy.CLASS 和 RetentionPolicy.RUNTIME 注解。 MetaSpace替换PermGen永久代 permanent generation 1.8后移除； Hotspot Jvm 是一片连续的堆空间，在JVM启动之前通过在命令行设置参数-XX:MaxPermSize来设定永久代最大可分配的内存空间，默认大小是64M（64位JVM由于指针膨胀，默认是85M）。 垃圾收集是和老年代(old generation)捆绑在一起的，gc会同时触发永久代和老年代的垃圾收集 永久代的参数-XX:PermSize和-XX：MaxPermSize 永久代存了什么： interned-strings：会导致大量的性能问题和OOM错误 Method Area 类的元数据信息（metadata）还在，只不过不再是存储在连续的堆空间上，而是移动到叫做“Metaspace”的本地内存（Native memory）中 永久代移除的意义由于类的元数据可以在本地内存(native memory)之外分配，所以其最大可利用空间是整个系统内存的可用空间。这样，你将不再会遇到OOM错误，溢出的内存会涌入到交换空间。最终用户可以为类元数据指定最大可利用的本地内存空间，JVM也可以增加本地内存空间来满足类元数据信息的存储。 永久代的移除并不意味者类加载器泄露的问题就没有了。因此，你仍然需要监控你的消费和计划，因为内存泄露会耗尽整个本地内存，导致内存交换(swapping)，这样只会变得更糟。 Metaspace 和它的内存分配 Metaspace VM利用内存管理技术来管理Metaspace。这使得由不同的垃圾收集器来处理类元数据的工作，现在仅仅由Metaspace VM在Metaspace中通过C++来进行管理。Metaspace背后的一个思想是，类和它的元数据的生命周期是和它的类加载器的生命周期一致的. 只要类的类加载器是存活的，在Metaspace中的类元数据也是存活的，不能被释放。 对于术语“Metaspace”。更正式的，每个类加载器存储区叫做“a Metaspace”。这些 Metaspaces 一起总体称为”the Metaspace”。仅仅当类加载器不在存活，被垃圾收集器声明死亡后，该类加载器对应的 Metaspace 空间才可以回收。Metaspace 空间没有迁移和压缩。但是元数据会被扫描是否存在Java引用。 Metaspace VM使用一个块分配器(chunking allocator)来管理Metaspace空间的内存分配。块的大小依赖于类加载器的类型。其中有一个全局的可使用的块列表（a global free list of chunks）。当类加载器需要一个块的时候，类加载器从全局块列表中取出一个块，添加到它自己维护的块列表中。当类加载器死亡，它的块将会被释放，归还给全局的块列表。块（chunk）会进一步被划分成blocks,每个block存储一个元数据单元(a unit of metadata)。Chunk中Blocks的分配线性的（pointer bump）。这些chunks被分配在内存映射空间(memory mapped(mmapped) spaces)之外。在一个全局的虚拟内存映射空间（global virtual mmapped spaces）的链表，当任何虚拟空间变为空时，就将该虚拟空间归还回操作系统。 Metaspace在JDK8中，classe metadata(the virtual machines internal presentation of Java class)，被存储在叫做Metaspace的native memory。一些新的flags被加入： -XX:MetaspaceSize：class metadata的初始空间配额，以bytes为单位，达到该值就会触发垃圾收集进行类型卸载，同时GC会对该值进行调整：如果释放了大量的空间，就适当的降低该值；如果释放了很少的空间，那么在不超过MaxMetaspaceSize（如果设置了的话），适当的提高该值。 -XX:MaxMetaspaceSize：可以为class metadata分配的最大空间。默认是没有限制的。 -XX:MinMetaspaceFreeRatio：在GC之后，最小的Metaspace剩余空间容量的百分比，减少为class metadata分配空间导致的垃圾收集 -XX:MaxMetaspaceFreeRatio：在GC之后，最大的Metaspace剩余空间容量的百分比，减少为class metadata释放空间导致的垃圾收集 默认情况下，class metadata的分配仅受限于可用的native memory总量。可以使用MaxMetaspaceSize来限制可为class metadata分配的最大内存。当class metadata的使用的内存达到MetaspaceSize(32位clientVM默认12Mbytes,32位ServerVM默认是16Mbytes)时就会对死亡的类加载器和类进行垃圾收集。设置MetaspaceSize为一个较高的值可以推迟垃圾收集的发生。 Native Heap，就是C-Heap 对于32位的JVM，C-Heap的容量 = 4G - Java Heap-PermGen； 对于64位的JVM，C-Heap的容量 = 物理服务器的总RAM + 虚拟内存 - Java Heap-PermGen 在JDK8，Native Memory，包括Metaspace和C-Heap。 IBM的J9和Oracle的JRockit(收购BEA公司的JVM)都没有永久代的概念，而Oracle移除HotSpot中的永久代的原因之一是为了与JRockit合并，以充分利用各自的特点。 Direct Memory属于C Heap，可以通过参数-XX:MaxDirectMemorySize指定。如果不指定，该参数的默认值为Xmx的值减去1个Survior区的值。如设置启动参数-Xmx20M -Xmn10M -XX：SurvivorRatio=8,那么申请20M-1M=19M的DirectMemory是没有问题的。 123456789101112131415/*VM Args: -Xmx20M -Xmn10M -XX:MaxDirectMemorySize=10M*/public class DirectMemoryOOM &#123; private static final int _1MB = 1024 * 1024; public static void main(String[] args)&#123; ByteBuffer.allocateDirect(11*_1MB); &#125;&#125;Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Direct buffer memoryat java.nio.Bits.reserveMemory(Bits.java:658)at java.nio.DirectByteBuffer.&lt;init&gt;(DirectByteBuffer.java:123)at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:311)at DirectMemoryOOM.main(DirectMemoryOOM.java:16) 修改上面的代码：12345678910111213141516171819202122/*VM Args: -Xmx20M -Xmn10M -XX:MaxDirectMemorySize=10M -XX:+PrintGCDetails*/public class DirectMemoryOOM &#123; private static final int _1MB = 1024 * 1024; public static void main(String[] args)&#123; ByteBuffer.allocateDirect(10*_1MB); ByteBuffer.allocateDirect(_1MB); &#125;&#125;[GC (System.gc()) [PSYoungGen: 983K-&gt;632K(9216K)] 983K-&gt;640K(19456K), 0.0039667 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (System.gc()) [PSYoungGen: 632K-&gt;0K(9216K)] [ParOldGen: 8K-&gt;505K(10240K)] 640K-&gt;505K(19456K), [Metaspace: 2520K-&gt;2520K(1056768K)], 0.0073120 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] Heap PSYoungGen total 9216K, used 82K [0x00000000ff600000, 0x0000000100000000, 0x0000000100000000) eden space 8192K, 1% used [0x00000000ff600000,0x00000000ff614968,0x00000000ffe00000) from space 1024K, 0% used [0x00000000ffe00000,0x00000000ffe00000,0x00000000fff00000) to space 1024K, 0% used [0x00000000fff00000,0x00000000fff00000,0x0000000100000000) ParOldGen total 10240K, used 505K [0x00000000fec00000, 0x00000000ff600000, 0x00000000ff600000) object space 10240K, 4% used [0x00000000fec00000,0x00000000fec7e6c8,0x00000000ff600000) Metaspace used 2527K, capacity 4486K, committed 4864K, reserved 1056768K class space used 271K, capacity 386K, committed 512K, reserved 1048576K 先申请10M，再申请1M，此时会发现JVM不会出现OOM的现象。 可以发现发生了一个FullGC，FullGC后面的system关键字代表这一次FullGC是由System.gc()引起的。 DirectBuffer的GC规则与堆对象的回收规则是一样的，只有垃圾对象才会被回收，而判定是否为垃圾对象依然是根据引用树中的存活节点来判定。在垃圾收集时，虽然虚拟机会对DirectMemory进行回收，但是DirectMemory却不像新生代和老年代那样，发现空间不足了就通知收集器进行垃圾回收，它只能等待老年代满了后FullGC，然后“顺便地”帮它清理掉内存中废弃的对象。否则，只能等到抛出内存溢出异常时，在catch块里调用System.gc()。]]></content>
      <tags>
        <tag>jvm</tag>
        <tag>heap memory</tag>
        <tag>native memory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql mvcc]]></title>
    <url>%2F2018%2F03%2F11%2Fmysql-mvcc%2F</url>
    <content type="text"><![CDATA[mysql官方：InnoDB Multi-VersioningMysql中的MVCC轻松理解MYSQL MVCC 实现机制 MVCC：多版本并发控制技术（Multi-Version Concurrency Control） 一、MVCC简介MVCC (Multiversion Concurrency Control)，即多版本并发控制技术,它使得大部分支持行锁的事务引擎，不再单纯的使用行锁来进行数据库的并发控制，取而代之的是把数据库的行锁与行的多个版本结合起来，只需要很小的开销,就可以实现非锁定读，从而大大提高数据库系统的并发性能 读锁：也叫共享锁、S锁，若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S 锁。这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。 写锁：又称排他锁、X锁。若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务不能再对A加任何锁，直到T释放A上的锁。这保证了其他事务在T释放A上的锁之前不能再读取和修改A。 表锁：操作对象是数据表。Mysql大多数锁策略都支持(常见mysql innodb)，是系统开销最低但并发性最低的一个锁策略。事务t对整个表加读锁，则其他事务可读不可写，若加写锁，则其他事务增删改都不行。 行级锁：操作对象是数据表中的一行。是MVCC技术用的比较多的，但在MYISAM用不了，行级锁用mysql的储存引擎实现而不是mysql服务器。但行级锁对系统开销较大，处理高并发较好。 二、MVCC实现原理innodb MVCC主要是为Repeatable-Read事务隔离级别做的。在此隔离级别下，A、B客户端所示的数据相互隔离，互相更新不可见了解innodb的行结构、Read-View的结构对于理解innodb mvcc的实现由重要意义innodb存储的最基本row中包含一些额外的存储信息 DATA_TRX_ID，DATA_ROLL_PTR，DB_ROW_ID，DELETE BIT 6字节的DATA_TRX_ID 标记了最新更新这条行记录的transaction id，每处理一个事务，其值自动+1 7字节的DATA_ROLL_PTR 指向当前记录项的rollback segment的undo log记录，找之前版本的数据就是通过这个指针 6字节的DB_ROW_ID，当由innodb自动产生聚集索引时，聚集索引包括这个DB_ROW_ID的值，否则聚集索引中不包括这个值.，这个用于索引当中 DELETE BIT位用于标识该记录是否被删除，这里的不是真正的删除数据，而是标志出来的删除。真正意义的删除是在commit的时候 具体的执行过程 begin-&gt;用排他锁锁定该行-&gt;记录redo log-&gt;记录undo log-&gt;修改当前行的值，写事务编号，回滚指针指向undo log中的修改前的行 上述过程确切地说是描述了UPDATE的事务过程，其实undo log分insert和update undo log，因为insert时，原始的数据并不存在，所以回滚时把insert undo log丢弃即可，而update undo log则必须遵守上述过程 下面分别以select、delete、 insert、 update语句来说明SELECT Innodb检查每行数据，确保他们符合两个标准： InnoDB只查找版本早于当前事务版本的数据行(也就是数据行的版本必须小于等于事务的版本)，这确保当前事务读取的行都是事务之前已经存在的，或者是由当前事务创建或修改的行 行的删除操作的版本一定是未定义的或者大于当前事务的版本号，确定了当前事务开始之前，行没有被删除 符合了以上两点则返回查询结果。 INSERT InnoDB为每个新增行记录当前系统版本号作为创建ID。 DELETE InnoDB为每个删除行的记录当前系统版本号作为行的删除ID。 UPDATE InnoDB复制了一行。这个新行的版本号使用了系统版本号。它也把系统版本号作为了删除行的版本。 说明 insert 操作时 “创建时间”=DB_ROW_ID，这时，“删除时间 ”是未定义的； update 时，复制新增行的“创建时间”=DB_ROW_ID，删除时间未定义，旧数据行“创建时间”不变，删除时间=该事务的DB_ROW_ID； delete 操作，相应数据行的“创建时间”不变，删除时间=该事务的DB_ROW_ID； select 操作对两者都不修改，只读相应的数据 三、对于MVCC的总结上述更新前建立undo log，根据各种策略读取时非阻塞就是MVCC，undo log中的行就是MVCC中的多版本，这个可能与我们所理解的MVCC有较大的出入，一般我们认为MVCC有下面几个特点： 每行数据都存在一个版本，每次数据更新时都更新该版本 修改时Copy出当前版本随意修改，各个事务之间无干扰 保存时比较版本号，如果成功（commit），则覆盖原记录；失败则放弃copy（rollback） 就是每行都有版本号，保存时根据版本号决定是否成功，听起来含有乐观锁的味道，而Innodb的实现方式是： 事务以排他锁的形式修改原始数据 把修改前的数据存放于undo log，通过回滚指针与主数据关联 修改成功（commit）啥都不做，失败则恢复undo log中的数据（rollback） 二者最本质的区别是，当修改数据时是否要排他锁定，如果锁定了还算不算是MVCC？ Innodb的实现真算不上MVCC，因为并没有实现核心的多版本共存，undo log中的内容只是串行化的结果，记录了多个事务的过程，不属于多版本共存。但理想的MVCC是难以实现的，当事务仅修改一行记录使用理想的MVCC模式是没有问题的，可以通过比较版本号进行回滚；但当事务影响到多行数据时，理想的MVCC据无能为力了。 比如，如果Transaciton1执行理想的MVCC，修改Row1成功，而修改Row2失败，此时需要回滚Row1，但因为Row1没有被锁定，其数据可能又被Transaction2所修改，如果此时回滚Row1的内容，则会破坏Transaction2的修改结果，导致Transaction2违反ACID。 理想MVCC难以实现的根本原因在于企图通过乐观锁代替二段提交。修改两行数据，但为了保证其一致性，与修改两个分布式系统中的数据并无区别，而二提交是目前这种场景保证一致性的唯一手段。二段提交的本质是锁定，乐观锁的本质是消除锁定，二者矛盾，故理想的MVCC难以真正在实际中被应用，Innodb只是借了MVCC这个名字，提供了读的非阻塞而已。 参考文章 https://www.percona.com/blog/2014/12/17/innodbs-multi-versioning-handling-can-be-achilles-heel/http://www.xdata.me/?p=289http://blogread.cn/it/article/5969http://blog.csdn.net/chen77716/article/details/6742128http://blog.chinaunix.net/link.php?url=http://forge.mysql.com%2Fwiki%2FMySQL_Internals 作者：踏雪无痕 出处：http://www.cnblogs.com/chenpingzhao/ 本文版权归作者和博客园共有，如需转载，请联系 pingzhao1990#163.com]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[垃圾回收算法]]></title>
    <url>%2F2018%2F03%2F11%2Fgarbage-collection%2F</url>
    <content type="text"><![CDATA[前人的肩膀 ref 常用垃圾回收算法 ref 《垃圾回收的算法与实现》 by 中村成洋 ref JVM中CMS收集器（示例图片靠谱） key word对象、指针、mutator、堆、活动对象/非活动对象、分配、分块、根（GC root） mutator from： 《垃圾回收的算法与实现》1.3 mutator mutator 是 Edsger Dijkstra琢磨出来的词，有“改变某物”的意思。mutator 的实际操作有一下两种： 生成对象 更新指针 mutator 在进行这些操作时，会同时为应用程序的用户进行一些处理（数值计算、浏览网页、编辑文章等）。对着这些处理的逐步推进，对象间的引用关系也会“改变”，而负责回收这些垃圾的机制就是GC。 评价标准 吞吐量（throughput） 最大暂停时间 堆使用效率 访问的局部性 垃圾回收算法Reference Counting 引用计数法这个方法是最经典点的一种方法。具体是对于对象设置一个引用计数器，每增加一个变量对它的引用，引用计数器就会加1，每减少一个变量的引用，引用计数器就会减1，只有当对象的引用计数器变成0时，该对象才会被回收。 RC仅可远观，因为，坑很多： 采用这种方法后，每次在增加变量引用和减少引用时都要进行加法或减法操作，如果频繁操作对象的话，在一定程度上增加的系统的消耗。 这种方法无法处理循环引用的情况（假设有两个对象 A和B，A中引用了B对象，并且B中也引用了A对象，那么这时两个对象的引用计数器都不为0，但是由于存在相互引用导致无法垃圾回收A和 B，导致内存泄漏） RC 优点 可立刻回收垃圾：直接可以通过计数判断 最大暂停时间短 没有必要沿指针查找 RC 缺点 计数器值的增减处理繁重 计数器需要占用额外的位用于已用计数的计数器最大必须能数完堆中的所有对象的引用数。比如用32位机器，就有可能要让2的32次方个对象同时引用一个对象。考虑到这种情况，就有必要确保各对象的计数器有32位大小。也就是说，对于所有对象，必须留有32位的空间。会使空间利用率大大降低 实现繁琐复杂 循环引用无法回收 Mark Sweep 标记清除法这个方法是将垃圾回收分成了两个阶段：标记阶段和清除阶段。 标记阶段：通过跟对象，标记所有从根节点开始可达的对象，那么未标记的对象就是未被引用的垃圾对象。 清除阶段：清除掉所以的未被标记的对象。 MS 优点 算法简单，实现容易； vs 引用计数中切实管理计数器的增减复杂，实现也很困难 由于标记清除实现简单，所以更容易与其他算法结合使用，比如JVM中与Mark Compact混合使用的CMS 不移动对象（因此也可以与保守式GC兼容） MS 缺点 碎片化（fragmentation） 垃圾回收后可能存在大量的磁盘碎片，准确的说是内存碎片。因为对象所占用的地址空间是固定的。 Mark Compact 标记压缩清除法（Java中老年代采用）在 Mark Sweep 的基础上做了一个改进，可以说这个算法分为三个阶段： 标记阶段（不变） 压缩阶段（新增） 清除阶段（不变） 将这些标记过的对象集中放到一起，确定开始和结束地址，比如全部放到开始处，这样再去清除，将不会产生磁盘碎片。但是我们也要注意到几个问题，压缩阶段占用了系统的消耗，并且如果标记对象过多的话，损耗可能会很大，在标记对象相对较少的时候，效率较高。 MC优点 可有效利用堆 MC缺点 压缩话费计算成本 Copying GC复制算法（Java中新生代采用）。 分块，将存活对象复制到另一个块中 核心思想是将内存空间分成两块，同一时刻只使用其中的一块，在垃圾回收时将正在使用的内存中的存活的对象复制到未使用的内存中，然后清除正在使用的内存块中所有的对象，然后把未使用的内存块变成正在使用的内存块，把原来使用的内存块变成未使用的内存块。很明显如果存活对象较多的话，算法效率会比较差，并且这样会使内存的空间折半，但是这种方法也不会产生内存碎片。 copy优点 优秀的吞吐量：仅需搜索并复制活动对象； 可实现高速分配：分块是连续的内存空间（不使用空闲链表），因此仅需调查分块的大小，只要分块大小不小于所申请的大小，仅需要移动$free指针可以进行分配； 不会发生碎片化：复制后的存活对象是内存连续的； 与缓存兼容：在GC复制算法中有引用关系的对象会被安排在堆里离彼此较近的位置。这种情况有一个优点，就是mutator执行速度极快 copy缺点 堆使用效率低下：堆二分，一次只能利用一半 不兼容保守式GC算法：保守式GC不移动对象 递归调用函数：在复制某个对象时，需要递归复制它的子对象，在每次复制的时候都要调用函数，会带来不容忽视的额外负担 分代法（Java堆采用）。主要思想是根据对象的生命周期长短特点将其进行分块，根据每块内存区间的特点，使用不同的回收算法，从而提高垃圾回收的效率。比如Java虚拟机中的堆就采用了这种方法分成了新生代和老年代。然后对于不同的代采用不同的垃圾回收算法。新生代使用了复制算法，老年代使用了标记压缩清除算法。 老年代：old 或称 tenuringminGC、majorGC 分区算法。这种方法将整个空间划分成连续的不同的小区间，每个区间都独立使用，独立回收，好处是可以控制一次回收多少个小区间。 VM分代式GC里，年老代常用mark-sweep；或者是mark-sweep/mark-compact的混合方式，一般情况下用mark-sweep，统计估算碎片量达到一定程度时用mark-compact。这是因为传统上大家认为年老代的对象可能会长时间存活且存活率高，或者是比较大，这样拷贝起来不划算，还不如采用就地收集的方式。Mark-sweep、mark-compact、copying这三种基本算法里，只有mark-sweep是不移动对象（也就是不用拷贝）的，所以选用mark-sweep。 简要对比三种基本算法： mark-sweep mark-compact copying 速度 中等 最慢 最快 空间开销 少（但会堆积碎片） 少（不堆积碎片） 通常需要活对象的2倍大小（不堆积碎片） 移动对象？ 否 是 是 关于时间开销： mark-sweep：mark阶段与活对象的数量成正比，sweep阶段与整堆大小成正比 mark-compact：mark阶段与活对象的数量成正比，compact阶段与活对象的大小成正比 copying：与活对象大小成正比 如果把mark、sweep、compact、copying这几种动作的耗时放在一起看，大致有这样的关系： compaction &gt;= copying &gt; marking &gt; sweeping 还有 marking + sweeping &gt; copying （虽然compactiont与copying都涉及移动对象，但取决于具体算法，compact可能要先计算一次对象的目标地址，然后修正指针，然后再移动对象；copying则可以把这几件事情合为一体来做，所以可以快一些。 另外还需要留意GC带来的开销不能只看collector的耗时，还得看allocator一侧的。如果能保证内存没碎片，分配就可以用pointer bumping方式，只有挪一个指针就完成了分配，非常快；而如果内存有碎片就得用freelist之类的方式管理，分配速度通常会慢一些。） 在分代式假设中，年轻代中的对象在minor GC时的存活率应该很低，这样用copying算法就是最合算的，因为其时间开销与活对象的大小成正比，如果没多少活对象，它就非常快；而且young gen本身应该比较小，就算需要2倍空间也只会浪费不太多的空间。 而年老代被GC时对象存活率可能会很高，而且假定可用剩余空间不太多，这样copying算法就不太合适，于是更可能选用另两种算法，特别是不用移动对象的mark-sweep算法。 不过HotSpot VM中除了CMS之外的其它收集器都是会移动对象的，也就是要么是copying、要么是mark-compact的变种。 Hotspot 参考 JVM cms HotSpot VM的serial GC（UseSerialGC）、parallel GC（UseParallelGC）中，只有full GC会收集年老代（实际上收集整个GC堆，包括年老代在内）。它用的算法是mark-compact（”Mark-Compact Old Object Collector”那一节），具体来说是典型的单线程（串行）的LISP 2算法。虽然在HotSpot VM的源码里，这个full GC的实现类叫做MarkSweep，而许多资料上都把它称为mark-sweep-compact，但实际上它是典型的mark-compact而不是mark-sweep，请留意不要弄混了。出现这种情况是历史原因，十几二十年前GC的术语还没固定到几个公认的用法时mark-sweep-compact和mark-compact说的是一回事。 我不太清楚当初HotSpot VM为何选择先以mark-compact算法来实现full GC，而不像后来微软的CLR那样先选择使用mark-sweep为基本算法来实现Gen 2 GC。但其背后的真相未必很复杂： HotSpot VM的前身是Strongtalk VM，它的full GC也是mark-compact算法的，虽说具体算法跟HotSpot VM的不同，是一种threaded compaction算法。这种算法比较省空间，但限制也挺多，实现起来比较绕弯，所以后来出现的HotSpot才改用了更简单直观的LISP 2算法吧，而这个决定又进一步在V8上得到体现。 而Strongtalk VM的前身是Self VM，同样使用mark-compact算法来实现full GC。可以看到mark-compact是这一系列VM一脉相承的，一直延续到更加新的Google V8也是如此。或许当初规划HotSpot VM时也没想那么多就先继承下了其前身的特点。 如果硬要猜为什么，那一个合理的推断是：如果不能整理碎片，长时间运行的程序终究会遭遇内存碎片化，导致内存空间的浪费和内存分配速度下降的问题；要解决这个问题就得要能整理内存。如果决定要根治碎片化问题，那么可以直接选用mark-compact，或者是主要用mark-sweep外加用mark-compact来备份。显然直接选用mark-compact实现起来更简单些。所以就选它了。 （而CLR就选择了不根治碎片化问题。所有可能出问题的地方都最终会出问题，于是现在就有很多.NET程序受碎片化的困扰） 后来HotSpot VM有了parallel old GC（UseParallelOldGC），这个用的是多线程并行版的mark-compact算法。这个算法具体应该叫什么名字我说不上来，因为并没有专门的论文去描述它，而大家有许多不同的办法去并行化LISP 2之类的经典mark-compact算法，各自取舍的细节都不同。无论如何，这里要关注的只是它用的也是mark-compact而不是mark-sweep算法。 ================================================================ 那CMS为啥选用mark-sweep为基本算法将其并发化，而不跟HotSpot VM的其它GC一样用会移动对象的算法呢？ 一个不算原因的原因是：当时设计和实现CMS是在Sun的另外一款JVM，Exact VM（EVM）上做的。后来EVM项目跟HotSpot VM竞争落败，CMS才从EVM移植到HotSpot VM来。因此它没有HotSpot VM的初始血缘。 &lt;- 真的算不上原因（逃 真正的原因请参考CMS的原始论文：A Generational Mostly-concurrent Garbage Collector（可恶，Oracle Labs的链接挂了。用CiteSeerX的链接吧） 把GC之外的代码（主要是应用程序的逻辑）叫做mutator，把GC的代码叫做collector。两者之间需要保持同步，这样才可以保证两者所观察到的对象图是一致的。 如果有一个串行、不并发、不分代、不增量式的collector，那么它在工作的时候总是能观察到整个对象图。因而它跟mutator之间的同步方式非常简单：mutator一侧不用做任何特殊的事情，只要在需要GC时同步调用collector即可，就跟普通函数调用一样。 如果有一个分代式的，或者增量式的collector，那它在工作的时候就只会观察到整个对象图的一部分；它观察不到的部分就有可能与mutator产生不一致，于是需要mutator配合：它与mutator之间需要额外的同步。Mutator在改变对象图中的引用关系时必须执行一些额外代码，让collector记录下这些变化。有两种做法，一种是write barrier，一种是read barrier。 Write barrier就是当改写一个引用时： Java代码 “收藏这段代码”) a.x = b a.x = b 插入一块额外的代码，变成： C代码 [![收藏代码](http://hllvm.group.iteye.com/images/icon_star.png)![](http://hllvm.group.iteye.com/images/spinner.gif)](javascript:void() "收藏这段代码") 1. write_barrier(a, &(a->x), b); 2. a->x = b; write_barrier(a, &(a->x), b); a->x = b; Read barrier就是当读取一个引用时： Java代码 [![收藏代码](http://hllvm.group.iteye.com/images/icon_star.png)![](http://hllvm.group.iteye.com/images/spinner.gif)](javascript:void() "收藏这段代码") 1. b = a.x b = a.x 插入一块额外的代码，变成： C代码 [![收藏代码](http://hllvm.group.iteye.com/images/icon_star.png)![](http://hllvm.group.iteye.com/images/spinner.gif)](javascript:void() "收藏这段代码") 1. read_barrier(&(a->x)); 2. b = a->x; read_barrier(&(a->x)); b = a->x; 通常一个程序里对引用的读远比对引用的写要更频繁，所以通常认为read barrier的开销远大于write barrier，所以很少有GC使用read barrier。 如果只用write barrier，那么“移动对象”这个动作就必须要完全暂停mutator，让collector把对象都移动好，然后把指针都修正好，接下来才可以恢复mutator的执行。也就是说collector“移动对象”这个动作无法与mutator并发进行。 如果用到了read barrier（虽少见但不是不存在，例如Azul C4 Collector），那移动对象就可以单个单个的进行，而且不需要立即修正所有的指针，所以可以看作整个过程collector都与mutator是并发的。 CMS没有使用read barrier，只用了write barrier。这样，如果它要选用mark-compact为基本算法的话，就只有mark阶段可以并发执行（其中root scanning阶段仍然需要暂停mutator，这是initial marking；后面的concurrent marking才可以跟mutator并发执行），然后整个compact阶段都要暂停mutator。回想最初提到的：compact阶段的时间开销与活对象的大小成正比，这对年老代来说就不划算了。 于是选用mark-sweep为基本算法就是很合理的选择：mark与sweep阶段都可以与mutator并发执行。Sweep阶段由于不移动对象所以不用修正指针，所以不用暂停mutator。 （题外话：但现实中我们仍然可以看到以mark-compact为基础算法的增量式/并发式年老代GC。例如Google V8里的年老代GC就可以把marking阶段拆分为非并发的initial marking和增量式的incremental marking；但真正比较耗时的compact阶段仍然需要完全暂停mutator。它要降低暂停时间就只能想办法在年老代内进一步选择其中一部分来做compaction，而不是整个年老代一口气做compaction。这在V8里也已经有实现，叫做incremental compaction。再继续朝这方向发展的话最终会变成region-based collector，那就跟G1类似了。） 那碎片堆积起来了怎么办呢？HotSpot VM里CMS只负责并发收集年老代（而不是整个GC堆）。如果并发收集所回收到的空间赶不上分配的需求，就会回退到使用serial GC的mark-compact算法做full GC。也就是mark-sweep为主，mark-compact为备份的经典配置。但这种配置方式也埋下了隐患：使用CMS时必须非常小心的调优，尽量推迟由碎片化引致的full GC的发生。一旦发生full GC，暂停时间可能又会很长，这样原本为低延迟而选择CMS的优势就没了。 所以新的Garbage-First（G1）GC就回到了以copying为基础的算法上，把整个GC堆划分为许多小区域（region），通过每次GC只选择收集很少量region来控制移动对象带来的暂停时间。这样既能实现低延迟也不会受碎片化的影响。 （注意：G1虽然有concurrent global marking，但那是可选的，真正带来暂停时间的工作仍然是基于copying算法而不是mark-compact的）]]></content>
      <tags>
        <tag>gc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring interceptor vs filter]]></title>
    <url>%2F2018%2F03%2F10%2Fspring-interceptor-vs-filter%2F</url>
    <content type="text"><![CDATA[Spring的Interceptor(拦截器)与Servlet的Filter有相似之处，都能实现权限检查、日志记录等。不同的是： Filter Interceptor Summary Filter 接口定义在 javax.servlet 包中 接口 HandlerInterceptor 定义在org.springframework.web.servlet 包中 Filter 定义在 web.xml 中 Filter在只在 Servlet 前后起作用。Filters 通常将 请求和响应（request/response） 当做黑盒子，Filter 通常不考虑servlet 的实现。 拦截器能够深入到方法前后、异常抛出前后等，因此拦截器的使用具有更大的弹性。允许用户介入（hook into）请求的生命周期，在请求过程中获取信息，Interceptor 通常和请求更加耦合。 在Spring构架的程序中，要优先使用拦截器。几乎所有 Filter 能够做的事情， interceptor 都能够轻松的实现^top Filter 是 Servlet 规范规定的。 而拦截器既可以用于Web程序，也可以用于Application、Swing程序中。 使用范围不同 Filter 是在 Servlet 规范中定义的，是 Servlet 容器支持的。 而拦截器是在 Spring容器内的，是Spring框架支持的。 规范不同 Filter 不能够使用 Spring 容器资源 拦截器是一个Spring的组件，归Spring管理，配置在Spring文件中，因此能使用Spring里的任何资源、对象，例如 Service对象、数据源、事务管理等，通过IoC注入到拦截器即可 Spring 中使用 interceptor 更容易 Filter 是被 Server(like Tomcat) 调用 Interceptor 是被 Spring 调用 因此 Filter 总是优先于 Interceptor 执行 interceptor 使用interceptor 的执行顺序大致为： 请求到达 DispatcherServlet DispatcherServlet 发送至 Interceptor ，执行 preHandle 请求达到 Controller 请求结束后，postHandle 执行 Spring 中主要通过 HandlerInterceptor 接口来实现请求的拦截，实现 HandlerInterceptor 接口需要实现下面三个方法： preHandle() – 在handler执行之前，返回 boolean 值，true 表示继续执行，false 为停止执行并返回。 postHandle() – 在handler执行之后, 可以在返回之前对返回的结果进行修改 afterCompletion() – 在请求完全结束后调用，可以用来统计请求耗时等等 统计请求耗时 12345678910111213141516171819202122232425262728293031323334353637383940414243import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.apache.log4j.Logger;import org.springframework.web.servlet.ModelAndView;import org.springframework.web.servlet.handler.HandlerInterceptorAdapter;public class ExecuteTimeInterceptor extends HandlerInterceptorAdapter&#123; private static final Logger logger = Logger.getLogger(ExecuteTimeInterceptor.class); //before the actual handler will be executed public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; long startTime = System.currentTimeMillis(); request.setAttribute(&quot;startTime&quot;, startTime); return true; &#125; //after the handler is executed public void postHandle( HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; long startTime = (Long)request.getAttribute(&quot;startTime&quot;); long endTime = System.currentTimeMillis(); long executeTime = endTime - startTime; //modified the exisitng modelAndView modelAndView.addObject(&quot;executeTime&quot;,executeTime); //log it if(logger.isDebugEnabled())&#123; logger.debug(&quot;[&quot; + handler + &quot;] executeTime : &quot; + executeTime + &quot;ms&quot;); &#125; &#125;&#125; 例子来源 mkyong 使用mvc:interceptors标签来声明需要加入到SpringMVC拦截器链中的拦截器 12345678910111213&lt;mvc:interceptors&gt; &lt;!-- 使用bean定义一个Interceptor，直接定义在mvc:interceptors根下面的Interceptor将拦截所有的请求 --&gt; &lt;bean class=&quot;com.company.app.web.interceptor.AllInterceptor&quot;/&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=&quot;/**&quot;/&gt; &lt;mvc:exclude-mapping path=&quot;/parent/**&quot;/&gt; &lt;bean class=&quot;com.company.authorization.interceptor.SecurityInterceptor&quot; /&gt; &lt;/mvc:interceptor&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=&quot;/parent/**&quot;/&gt; &lt;bean class=&quot;com.company.authorization.interceptor.SecuritySystemInterceptor&quot; /&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; 可以利用mvc:interceptors标签声明一系列的拦截器，然后它们就可以形成一个拦截器链，拦截器的执行顺序是按声明的先后顺序执行的，先声明的拦截器中的preHandle方法会先执行，然而它的postHandle方法和afterCompletion方法却会后执行。 在mvc:interceptors标签下声明interceptor主要有两种方式： 直接定义一个Interceptor实现类的bean对象。使用这种方式声明的Interceptor拦截器将会对所有的请求进行拦截。 使用mvc:interceptor标签进行声明。使用这种方式进行声明的Interceptor可以通过mvc:mapping子标签来定义需要进行拦截的请求路径。 经过上述两步之后，定义的拦截器就会发生作用对特定的请求进行拦截了。 Filter 使用Servlet 的 Filter 接口需要实现如下方法： void init(FilterConfig paramFilterConfig) – 当容器初始化 Filter 时调用，该方法在 Filter 的生命周期只会被调用一次，一般在该方法中初始化一些资源，FilterConfig 是容器提供给 Filter 的初始化参数，在该方法中可以抛出 ServletException 。init 方法必须执行成功，否则 Filter 可能不起作用，出现以下两种情况时，web 容器中 Filter 可能无效： 1）抛出 ServletException 2）超过 web 容器定义的执行时间。 doFilter(ServletRequest paramServletRequest, ServletResponse paramServletResponse, FilterChain paramFilterChain) – Web 容器每一次请求都会调用该方法。该方法将容器的请求和响应作为参数传递进来， FilterChain 用来调用下一个 Filter。 void destroy() – 当容器销毁 Filter 实例时调用该方法，可以在方法中销毁资源，该方法在 Filter 的生命周期只会被调用一次。 123456789&lt;filter&gt; &lt;filter-name&gt;FrequencyLimitFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.company.filter.FrequencyLimitFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;FrequencyLimitFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/login/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; Filter 和 Interceptor 的一些用途 Authentication Filters Logging and Auditing Filters Image conversion Filters Data compression Filters Encryption Filters Tokenizing Filters Filters that trigger resource access events XSL/T filters Mime-type chain Filter Request Filters 可以: 执行安全检查 perform security checks 格式化请求头和主体 reformat request headers or bodies 审查或者记录日志 audit or log requests 根据请求内容授权或者限制用户访问 Authentication-Blocking requests based on user identity. 根据请求频率限制用户访问 Response Filters 可以: 压缩响应内容,比如让下载的内容更小 Compress the response stream 追加或者修改响应 append or alter the response stream 创建或者整体修改响应 create a different response altogether 根据地方不同修改响应内容 Localization-Targeting the request and response to a particular locale. reference https://gopalakrishnadurga.wordpress.com/2012/06/08/filter-vs-interceptor/]]></content>
      <tags>
        <tag>spring</tag>
        <tag>spring interceptor</tag>
        <tag>java filter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 死锁的那些事儿]]></title>
    <url>%2F2018%2F03%2F10%2Fmysql-deadlock%2F</url>
    <content type="text"><![CDATA[快捷入口 在 show engine innodb status\G 中查询 LATEST DETECTED DEADLOCK; 通过 SELECT * FROM information_schema.INNODB_LOCKS; 查询锁信息； begin, commit 的方式手动触发，复现问题 查看当前事务隔离级别1234567mysql&gt; SELECT @@global.tx_isolation, @@session.tx_isolation, @@tx_isolation;+-----------------------+------------------------+----------------+| @@global.tx_isolation | @@session.tx_isolation | @@tx_isolation |+-----------------------+------------------------+----------------+| READ-COMMITTED | READ-COMMITTED | READ-COMMITTED |+-----------------------+------------------------+----------------+1 row in set (0.00 sec) 查看当前数据库锁通过进程信息查询1show full processlist 主要观察state和info 查询 innodb status1show engine innodb status\G 重点关注 TRANSACTIONS 部分和 LATEST DETECTED DEADLOCK 两个部分； 通过 information_shcema 数据表查询 innodb_trx ：innodb内核中的当前活跃（ACTIVE）事务 innodb_locks ：当前状态产生的innodb锁 仅在有锁等待时 innodb_lock_waits ：当前状态产生的innodb锁等待 仅在有锁等待时 innodb_trx 表结构 字段名 说明 trx_id innodb存储引擎内部唯一的事物ID trx_state 当前事物状态（running和lock wait两种状态） trx_started 事物的开始时间 trx_requested_lock_id 等待事物的锁ID，如trx_state的状态为Lock wait，那么该值带表当前事物等待之前事物占用资源的ID，若trx_state不是Lock wait 则该值为NULL trx_wait_started 事物等待的开始时间 trx_weight 事物的权重，在innodb存储引擎中，当发生死锁需要回滚的时，innodb存储引擎会选择该值最小的进行回滚 trx_mysql_thread_id mysql中的线程id, 即show processlist显示的结果 trx_query 事物运行的SQL语句 innodb_locks 表结构 字段名 说明 lock_id 锁的ID lock_trx_id 事物的ID lock_mode 锁的模式（S锁与X锁两种模式） lock_type 锁的类型 表锁还是行锁（RECORD） lock_table 要加锁的表 lock_index 锁住的索引 lock_space 锁住对象的space id lock_page 事物锁定页的数量，若是表锁则该值为NULL lock_rec 事物锁定行的数量，若是表锁则该值为NULL lock_data 事物锁定记录主键值，若是表锁则该值为NULL（此选项不可信） innodb_lock_waits 表结构 字段名 说明 requesting_trx_id 申请锁资源的事物ID requested_lock_id 申请的锁的ID blocking_trx_id 阻塞其他事物的事物ID blocking_lock_id 阻塞其他锁的锁ID 如何读 LATEST DETECTED DEADLOCKLATEST DETECTED DEADLOCK 中会记录最近一次死锁的信息，包含以下信息 包含两个事务：TRANSACTION 119992026，TRANSACTION 119991521 事务2026 等待 一个行级的 X锁 （WAITING FOR ···· RECORD LOCKS ··· lock_mode X locks rec but not gap） 事务1521 持有 一个行级的 X锁 （HOLDS ··· RECORD LOCKS ··· lock_mode X locks rec but not gap） 等待 一个行级的 S锁 （WAITING FOR THIS LOCK TO BE GRANTED ··· RECORD LOCKS ··· lock mode S waiting） 1234567891011121314151617181920212223------------------------LATEST DETECTED DEADLOCK------------------------2018-03-10 16:21:02 0x7f8ac30e1700*** (1) TRANSACTION:TRANSACTION 119992026, ACTIVE 87 sec starting index readmysql tables in use 1, locked 1LOCK WAIT 2 lock struct(s), heap size 1136, 1 row lock(s)MySQL thread id 1462608, OS thread handle 140233934087936, query id 4903877046 172.26.182.190 root updatingdelete from ac_role_function WHERE ( role_id = 12287 and business_sys_id = 353 and tenant_code = &apos;1&apos; )*** (1) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 9190 page no 35 n bits 448 index unique_busi_tenant_role_fun of table `uac_test`.`ac_role_function` trx id 119992026 lock_mode X locks rec but not gap waiting*** (2) TRANSACTION:TRANSACTION 119991521, ACTIVE 149 sec insertingmysql tables in use 1, locked 14 lock struct(s), heap size 1136, 3 row lock(s), undo log entries 2MySQL thread id 1462607, OS thread handle 140233954694912, query id 4903902025 172.26.182.190 root updateinsert into ac_role_function ( tenant_code, business_sys_id, role_id, function_id ) values ( &apos;1&apos;, 353, 12287, 2869 )*** (2) HOLDS THE LOCK(S):RECORD LOCKS space id 9190 page no 35 n bits 448 index unique_busi_tenant_role_fun of table `uac_test`.`ac_role_function` trx id 119991521 lock_mode X locks rec but not gap*** (2) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 9190 page no 35 n bits 448 index unique_busi_tenant_role_fun of table `uac_test`.`ac_role_function` trx id 119991521 lock mode S waiting*** WE ROLL BACK TRANSACTION (1) 🌰案发现场innodb status 中 deadlock 信息事务2026占用X锁失败，1234567891011121314151617181920212223------------------------LATEST DETECTED DEADLOCK------------------------2018-03-10 16:21:02 0x7f8ac30e1700*** (1) TRANSACTION:TRANSACTION 119992026, ACTIVE 87 sec starting index readmysql tables in use 1, locked 1LOCK WAIT 2 lock struct(s), heap size 1136, 1 row lock(s)MySQL thread id 1462608, OS thread handle 140233934087936, query id 4903877046 172.26.182.190 root updatingdelete from ac_role_function WHERE ( role_id = 12287 and business_sys_id = 353 and tenant_code = &apos;1&apos; )*** (1) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 9190 page no 35 n bits 448 index unique_busi_tenant_role_fun of table `uac_test`.`ac_role_function` trx id 119992026 lock_mode X locks rec but not gap waiting*** (2) TRANSACTION:TRANSACTION 119991521, ACTIVE 149 sec insertingmysql tables in use 1, locked 14 lock struct(s), heap size 1136, 3 row lock(s), undo log entries 2MySQL thread id 1462607, OS thread handle 140233954694912, query id 4903902025 172.26.182.190 root updateinsert into ac_role_function ( tenant_code, business_sys_id, role_id, function_id ) values ( &apos;1&apos;, 353, 12287, 2869 )*** (2) HOLDS THE LOCK(S):RECORD LOCKS space id 9190 page no 35 n bits 448 index unique_busi_tenant_role_fun of table `uac_test`.`ac_role_function` trx id 119991521 lock_mode X locks rec but not gap*** (2) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 9190 page no 35 n bits 448 index unique_busi_tenant_role_fun of table `uac_test`.`ac_role_function` trx id 119991521 lock mode S waiting*** WE ROLL BACK TRANSACTION (1) 业务系统记下了这个bug Deadlock found when trying to get lock; try restarting transaction 证据确凿，一个deadlock 12345678### SQL: delete from ac_role_function WHERE ( role_id = ? and business_sys_id = ? and tenant_code = ? )### Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction; SQL []; Deadlock found when trying to get lock; try restarting transaction; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:263) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:73) at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:74) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:421) at com.sun.proxy.$Proxy52.delete(Unknown Source) 到底发生了什么这段业务代码中在进行一个关联信息的保存操作 按照上级先删除所有的关联信息； 按照用户当前的配置，插入新的关联信息； 关联信息建有唯一索引 然后，坑出现了！！！ 删除操作需要占用资源的X锁 执行插入操作前，需要占用资源的S锁； 当请求并发执行时 事务1：占用资源的X锁，删除资源； 事务2：占用资源的X锁，删除资源（此时删除操作被挂起，等待X锁） 事务1：执行插入操作，请求资源的S锁； 事务1执行完成，事务2直接抛出deadlock sql命令行验证下假想 时序 事务1（1521） 事务2（2026） 锁状态 1 begin begin 2 delete from ac_role_function WHERE role_id = 12287 and business_sys_id = 353 and tenant_code = &#39;1&#39; ; 3 delete from ac_role_function WHERE role_id = 12287 and business_sys_id = 353 and tenant_code = &#39;1&#39; ; 事务1、事务2分别持有X锁，锁定索引相同 4 insert into ac_role_function ( tenant_code, business_sys_id, role_id, function_id ) values ( &#39;1&#39;, 353, 12287, 2869 ); 事务2抛出deadlock，事务回滚 然后呢在这个案例中 数据是用户自身的，请求并不需要并行执行 –》 前端串行化 X锁和S锁的矛盾源头是保存操作中，不管三七二十一的删了重新插入，导致每个请求都需要针对这些资源同时申请X锁和S锁 –》 拆分保存操作，只保存实际新增的，只删除实际需要移除的，不修改未发生变更的数据（基于log的数据同步也能降低些压力）； 再来个🌰，多线程插入数据引起的死锁回滚（唯一索引场景）引自：mysql deadlock when concurrent insert 案发现场应用程序集群有3台机器，由于并发的问题，3台机器同时往数据里插入记录，并且在插入数据过程有其他的数据校验，因为数据校验失败，事务需要回滚，而导致死锁产生。 案件重演三个事务并发执行插入请求，分别请求X锁；事务T1发生回滚后 事务T3抢到X锁，执行成功； 事务T2没有抢到X锁，发生死锁，事务回滚 T1(140104) T2(140105) T3(140106) BEGIN; BEGIN; BEGIN; INSERT INTO deadlock(a,b,c) VALUES(1,2,4); INSERT INTO deadlock(a,b,c) VALUES(1,2,4); INSERT INTO deadlock(a,b,c) VALUES(1,2,4); ROLLBACK; Query OK, 1 row affected (13.10 sec) ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction 如果T1没有发生回滚，T2、T3会报唯一主键冲突； 看看他们是怎么处理的 避免此DEADLOCK我们都知道死锁的问题通常都是业务处理的逻辑造成的，既然是uniq key，同时多台不同服务器上的相同程序对其 INSERT 一模一样的value，这本身逻辑就不太完美。 故解决此问题： 保证业务程序别再同一时间点并发的插入相同的值到相同的uniq key的表中 上述实验可知，是由于第一个事务ROLLBACK了才产生的DEADLOCK，查明ROLLBACK的原因 尽量减少完成事务的时间]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>deadlock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的那些事儿（锁、事务）]]></title>
    <url>%2F2018%2F03%2F10%2Fmysql-lock-and-transaction%2F</url>
    <content type="text"><![CDATA[官方文档章节：InnoDB Locking and Transaction Model (Locking, Transaction Model, Locks Set by Different SQL Statements in InnoDB, Phantom Rows, Deadlocks in InnoDB) 锁类型(lock type) 事务隔离级别（Transaction isolation）和锁策略（locking strategis）；以及自动提交（autocommit），一致性非锁定读（consistent non-blocking），锁定读（locking read） “Locks Set by Different SQL Statements in InnoDB” discusses specific types of locks set in InnoDB for various statements. Phantom rows（how InnoDB uses next-key locking to avoid phantom rows.） 死锁（deadlock） key word共享锁（S）、排他锁（X）、意向共享（IS）、意向排他（IX） Record Lock：单个行记录上的锁。 Gap Lock：间隙锁，锁定一个范围，但不包括记录本身。GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。 Next-Key Lock：1 + 2，锁定一个范围，并且锁定记录本身。对于行的查询，都是采用该方法，主要目的是解决幻读的问题。 Multi-VersioningIn the InnoDB transaction model, the goal is to combine the best properties of a multi-versioning database with traditional two-phase locking. InnoDB的锁（locking）共享锁(Shard Locks)与排它锁(_E_xclusive Locks)S锁(shared locks, S locks) 和 X锁(exclusive locks, X locks) 同为 行级锁（row-level locking） A shared (S) lock permits the transaction that holds the lock to read a row. An exclusive(X) lock permits the transaction that holds the lock to update or delete a row. 多个线程可以同时持有S锁，X锁仅能被唯一线程持有（其他线程请求X锁，将会等待 wait to be granted）； Intention Locks Gap Locks中存在一种插入意向锁(Insert Intention Lock)，在INSERT操作时产生。 refInnoDB supports multiple granularity locking which permits coexistence of row locks and table locks. For example, a statement such as LOCK TABLES ... WRITE takes an exclusive lock (an Xlock) on the specified table. To make locking at multiple granularity levels practical, InnoDB usesintention locks.Intention locks are table-level locks that indicate which type of lock (shared or exclusive) a transaction requires later for a row in a table. There are two types of intention locks: An intention shared lock (IS) indicates that a transaction intends to set a shared lock on individual rows in a table. An intention exclusive lock (IX) indicates that that a transaction intends to set an exclusive lock on individual rows in a table. For example, SELECT ... LOCK IN SHARE MODE sets an IS lock, and SELECT ... FOR UPDATE sets an IX lock. The intention locking protocol is as follows: Before a transaction can acquire a shared lock on a row in a table, it must first acquire an IS lock or stronger on the table. Before a transaction can acquire an exclusive lock on a row in a table, it must first acquire an IX lock on the table. Table-level lock type compatibility is summarized in the following matrix. X IX S IS X Conflict Conflict Conflict Conflict IX Conflict Compatible Conflict Compatible S Conflict Conflict Compatible Compatible IS Conflict Compatible Compatible Compatible A lock is granted to a requesting transaction if it is compatible with existing locks, but not if it conflicts with existing locks. A transaction waits until the conflicting existing lock is released. If a lock request conflicts with an existing lock and cannot be granted because it would cause deadlock, an error occurs. Intention locks do not block anything except full table requests (for example, LOCK TABLES ... WRITE). The main purpose of intention locks is to show that someone is locking a row, or going to lock a row in the table. Transaction data for an intention lock appears similar to the following in SHOW ENGINE INNODB STATUS and InnoDB monitoroutput: 1TABLE LOCK table `test`.`t` trx id 10080 lock mode IX Record Locks 通过 for update 占用 record locks，防止其他线程 CUD； Record Locks 创建在索引上，如果没有索引，会创建 hidden clusterd index 日志样式：lock_mode X locks rec but not gap refA record lock is a lock on an index record. For example, SELECT c1 FROM t WHERE c1 = 10 FOR UPDATE; prevents any other transaction from inserting, updating, or deleting rows where the value of t.c1 is 10. Record locks always lock index records, even if a table is defined with no indexes. For such cases, InnoDB creates a hidden clustered index and uses this index for record locking. See Section 14.8.2.1, “Clustered and Secondary Indexes”. Transaction data for a record lock appears similar to the following in SHOW ENGINE INNODB STATUS and InnoDB monitoroutput: 123456RECORD LOCKS space id 58 page no 3 n bits 72 index `PRIMARY` of table `test`.`t` trx id 10078 lock_mode X locks rec but not gapRecord lock, heap no 2 PHYSICAL RECORD: n_fields 3; compact format; info bits 0 0: len 4; hex 8000000a; asc ;; 1: len 6; hex 00000000274f; asc &apos;O;; 2: len 7; hex b60000019d0110; asc ;; Gap Locks?? Gap Locks中存在一种插入意向锁(Insert Intention Lock)，在INSERT操作时产生。?? 通过BETWEEN 10 and 20 FOR UPDATE 锁定一个取件，防止其他线程在期间insert数据 gap lock 针对 记录上没有索引 记录上有非唯一索引 如果记录上有唯一索引（unique index），会使用 index-record lock，而非 gap lock；（查询条件没有覆盖唯一索引所有字段除外） 如何禁用gap lock 设置事务隔离级别为RC，transaction isolation level to READ COMMITTED 设置innodb_locks_unsafe_for_binlog参数为生效；enable the innodb_locks_unsafe_for_binlog system variable (which is now deprecated) refA gap lock is a lock on a gap between index records, or a lock on the gap before the first or after the last index record. For example, SELECT c1 FROM t WHERE c1 BETWEEN 10 and 20 FOR UPDATE; prevents other transactions from inserting a value of 15 into column t.c1, whether or not there was already any such value in the column, because the gaps between all existing values in the range are locked. A gap might span a single index value, multiple index values, or even be empty. Gap locks are part of the tradeoff between performance and concurrency, and are used in some transaction isolation levels and not others. Gap locking is not needed for statements that lock rows using a unique index to search for a unique row. (This does not include the case that the search condition includes only some columns of a multiple-column unique index; in that case, gap locking does occur.) For example, if the id column has a unique index, the following statement uses only an index-record lock for the row having id value 100 and it does not matter whether other sessions insert rows in the preceding gap: 1SELECT * FROM child WHERE id = 100; If id is not indexed or has a nonunique index, the statement does lock the preceding gap. It is also worth noting here that conflicting locks can be held on a gap by different transactions. For example, transaction A can hold a shared gap lock (gap S-lock) on a gap while transaction B holds an exclusive gap lock (gap X-lock) on the same gap. The reason conflicting gap locks are allowed is that if a record is purged from an index, the gap locks held on the record by different transactions must be merged. Gap locks in InnoDB are “purely inhibitive”, which means they only stop other transactions from inserting to the gap. They do not prevent different transactions from taking gap locks on the same gap. Thus, a gap X-lock has the same effect as a gap S-lock. Gap locking can be disabled explicitly. This occurs if you change the transaction isolation level to READ COMMITTED or enable the innodb_locks_unsafe_for_binlog system variable (which is now deprecated). Under these circumstances, gap locking is disabled for searches and index scans and is used only for foreign-key constraint checking and duplicate-key checking. There are also other effects of using the READ COMMITTED isolation level or enabling innodb_locks_unsafe_for_binlog.Record locks for nonmatching rows are released after MySQL has evaluated the WHERE condition. ForUPDATE statements, InnoDB does a “semi-consistent” read, such that it returns the latest committed version to MySQL so that MySQL can determine whether the row matches the WHERE condition of the UPDATE. Next-Key Locks Next-Key Lock = Record Lock + Gap Lock refA next-key lock is a combination of a record lock on the index record and a gap lock on the gap before the index record. InnoDB performs row-level locking in such a way that when it searches or scans a table index, it sets shared or exclusive locks on the index records it encounters. Thus, the row-level locks are actually index-record locks. A next-key lock on an index record also affects the “gap” before that index record. That is, a next-key lock is an index-record lock plus a gap lock on the gap preceding the index record. If one session has a shared or exclusive lock on record R in an index, another session cannot insert a new index record in the gap immediately before R in the index order. Suppose that an index contains the values 10, 11, 13, and 20. The possible next-key locks for this index cover the following intervals, where a round bracket denotes exclusion of the interval endpoint and a square bracket denotes inclusion of the endpoint: 12345(negative infinity, 10](10, 11](11, 13](13, 20](20, positive infinity) For the last interval, the next-key lock locks the gap above the largest value in the index and the “supremum” pseudo-record having a value higher than any value actually in the index. The supremum is not a real index record, so, in effect, this next-key lock locks only the gap following the largest index value. By default, InnoDB operates in REPEATABLE READ transaction isolation level. In this case, InnoDB uses next-key locks for searches and index scans, which prevents phantom rows (see Section 14.5.4, “Phantom Rows”). Transaction data for a next-key lock appears similar to the following in SHOW ENGINE INNODB STATUS and InnoDB monitoroutput: 123456789RECORD LOCKS space id 58 page no 3 n bits 72 index `PRIMARY` of table `test`.`t` trx id 10080 lock_mode XRecord lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;;Record lock, heap no 2 PHYSICAL RECORD: n_fields 3; compact format; info bits 0 0: len 4; hex 8000000a; asc ;; 1: len 6; hex 00000000274f; asc &apos;O;; 2: len 7; hex b60000019d0110; asc ;; Insert Intetion Locks··· TODO AUTO-INC Locks table-level lock refAn AUTO-INC lock is a special table-level lock taken by transactions inserting into tables withAUTO_INCREMENT columns. In the simplest case, if one transaction is inserting values into the table, any other transactions must wait to do their own inserts into that table, so that rows inserted by the first transaction receive consecutive primary key values. The innodb_autoinc_lock_mode configuration option controls the algorithm used for auto-increment locking. It allows you to choose how to trade off between predictable sequences of auto-increment values and maximum concurrency for insert operations. For more information, see Section 14.8.1.5, “AUTO_INCREMENT Handling in InnoDB”. Predicate Locks for Spatial Indexes··· TODO InnoDB事务模型（Transaction Model）事务的基本要素（ACID）原子性（Atomicity）事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。 一致性（Consistency）事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到。 隔离性（Isolation）同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。 持久性（Durability）事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。 事务的并发问题脏读事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据 不可重复读 MTDB默认使用RC，而非RR 事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果 不一致。 幻读系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。 不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表 事务隔离级别（Transaction Isolation） 事务隔离级别 简写 脏读 不可重复读 幻读 读未提交（read-uncommitted） 是 是 是 不可重复读（read-committed）MT default RC 否 是 是 可重复读（repeatable-read） 默认实现 RR 否 否 是 串行化（serializable） 否 否 否 Locking Read select with for update update delete 事务隔离级别 - 不可重复读（read-committed） InnoDB locks only index records, not the gaps before them, and thus permits the free insertion of new records next to locked records. Gap locking is only used for foreign-key constraint checking and duplicate-key checking. must use row-based binary logging. 可重复读（repeatable-read）]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>ACID</tag>
        <tag>事务隔离级别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UDT 那些事儿]]></title>
    <url>%2F2018%2F03%2F04%2Fnarration-of-udt%2F</url>
    <content type="text"></content>
      <tags>
        <tag>udp</tag>
        <tag>udt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP 那些事儿]]></title>
    <url>%2F2018%2F03%2F04%2Fnarration-of-tcp%2F</url>
    <content type="text"><![CDATA[引自： TCP 的那些事儿（上）- 左耳朵耗子 TCP 的那些事儿（下）- 左耳朵耗子 概要 TCP协议的定义和丢包时的重传机制。 TCP的流迭、拥塞处理。 摘要OSI模型 层数 名称 数据名称 协议 4 Transport Segment 3 Network Packet IP 2 Data Link Frame ARP 开个头儿TCP是一个巨复杂的协议，因为他要解决很多问题，而这些问题又带出了很多子问题和阴暗面。所以学习TCP本身是个比较痛苦的过程，但对于学习的过程却能让人有很多收获。关于TCP这个协议的细节，推荐去看 W.Richard Stevens 的 《TCP/IP 详解 卷1：协议》（当然，你也可以去读一下 RFC793 以及后面N多的RFC）。另外，本文会使用英文术语，这样方便你通过这些英文关键词来查找相关的技术文档。 首先，我们需要知道TCP在网络OSI的七层模型中的第四层——Transport层，IP在第三层——Network层，ARP在第二层——Data Link层，在第二层上的数据，我们叫Frame，在第三层上的数据叫Packet，第四层的数据叫Segment。 首先，我们需要知道，我们程序的数据首先会打到TCP的Segment中，然后TCP的Segment会打到IP的Packet中，然后再打到以太网Ethernet的Frame中，传到对端后，各个层解析自己的协议，然后把数据交给更高层的协议处理。 TCP头格式我们来看一下TCP头的格式 你需要注意这么几点： TCP的包是没有IP地址的，那是IP层上的事。但是有源端口和目标端口。 一个TCP连接需要四个元组来表示是同一个连接（src_ip, src_port, dst_ip, dst_port）准确说是五元组，还有一个是协议。但因为这里只是说TCP协议，所以，这里我只说四元组。 注意上图中的四个非常重要的东西： Sequence Number是包的序号，用来解决网络包乱序（reordering）问题。 Acknowledgement Number就是ACK——用于确认收到，用来解决不丢包的问题。 Window又叫Advertised-Window，也就是著名的滑动窗口（Sliding Window），用于解决流控的。 TCP Flag ，也就是包的类型，主要是用于操控TCP的状态机的。 关于其它的东西，可以参看下面的图示 （图片来源） TCP的状态机其实，网络上的传输是没有连接的，包括TCP也是一样的。而TCP所谓的“连接”，其实只不过是在通讯的双方维护一个“连接状态”，让它看上去好像有连接一样。所以，TCP的状态变换是非常重要的。 下面是：“TCP协议的状态机”（图片来源） 和 “TCP建链接”、“TCP断链接”、“传数据” 的对照图，我把两个图并排放在一起，这样方便在你对照着看。另外，下面这两个图非常非常的重要，你一定要记牢。（吐个槽：看到这样复杂的状态机，就知道这个协议有多复杂，复杂的东西总是有很多坑爹的事情，所以TCP协议其实也挺坑爹的） 建立链接三次握手，断开链接四次握手很多人会问，为什么建链接要3次握手，断链接需要4次挥手？ 对于建链接的3次握手，主要是要初始化Sequence Number 的初始值。通信的双方要互相通知对方自己的初始化的Sequence Number（缩写为ISN：Inital Sequence Number）——所以叫SYN，全称Synchronize Sequence Numbers。也就上图中的 x 和 y。这个号要作为以后的数据通信的序号，以保证应用层接收到的数据不会因为网络上的传输的问题而乱序（TCP会用这个序号来拼接数据）。 对于4次挥手，其实你仔细看是2次，因为TCP是全双工的，所以，发送方和接收方都需要Fin和Ack。只不过，有一方是被动的，所以看上去就成了所谓的4次挥手。如果两边同时断连接，那就会就进入到CLOSING状态，然后到达TIME_WAIT状态。下图是双方同时断连接的示意图（你同样可以对照着TCP状态机看）： 两端同时断连接（图片来源） 注意几个事儿另外，有几个事情需要注意一下： 关于建连接时SYN超时试想一下，如果server端接到了clien发的SYN后回了SYN-ACK后client掉线了，server端没有收到client回来的ACK，那么，这个连接处于一个中间状态，即没成功，也没失败。于是，server端如果在一定时间内没有收到的TCP会重发SYN-ACK。在Linux下，默认重试次数为5次，重试的间隔时间从1s开始每次都翻售，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s都知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 2^6 -1 = 63s，TCP才会把断开这个连接。 关于SYN Flood攻击一些恶意的人就为此制造了SYN Flood攻击——给服务器发了一个SYN后，就下线了，于是服务器需要默认等63s才会断开连接，这样，攻击者就可以把服务器的syn连接的队列耗尽，让正常的连接请求不能处理。于是，Linux下给了一个叫tcp_syncookies的参数来应对这个事——当SYN队列满了后，TCP会通过源地址端口、目标地址端口和时间戳打造出一个特别的Sequence Number发回去（又叫cookie），如果是攻击者则不会有响应，如果是正常连接，则会把这个 SYN Cookie发回来，然后服务端可以通过cookie建连接（即使你不在SYN队列中）。请注意，请先千万别用tcp_syncookies来处理正常的大负载的连接的情况。因为，synccookies是妥协版的TCP协议，并不严谨。对于正常的请求，你应该调整三个TCP参数可供你选择，第一个是：tcp_synack_retries 可以用他来减少重试次数；第二个是：tcp_max_syn_backlog，可以增大SYN连接数；第三个是：tcp_abort_on_overflow 处理不过来干脆就直接拒绝连接了。 关于ISN的初始化ISN是不能hard code的，不然会出问题的——比如：如果连接建好后始终用1来做ISN，如果client发了30个segment过去，但是网络断了，于是 client重连，又用了1做ISN，但是之前连接的那些包到了，于是就被当成了新连接的包，此时，client的Sequence Number 可能是3，而Server端认为client端的这个号是30了。全乱了。RFC793中说，ISN会和一个假的时钟绑在一起，这个时钟会在每4微秒对ISN做加一操作，直到超过2^32，又从0开始。这样，一个ISN的周期大约是4.55个小时。因为，我们假设我们的TCP Segment在网络上的存活时间不会超过Maximum Segment Lifetime（缩写为MSL – Wikipedia语条），所以，只要MSL的值小于4.55小时，那么，我们就不会重用到ISN。 关于 MSL 和 TIME_WAIT通过上面的ISN的描述，相信你也知道MSL是怎么来的了。我们注意到，在TCP的状态图中，从TIME_WAIT状态到CLOSED状态，有一个超时设置，这个超时设置是 2 * MSL（RFC793定义了MSL为2分钟，Linux设置成了30s）为什么要这有TIME_WAIT？为什么不直接给转成CLOSED状态呢？主要有两个原因：1）TIME_WAIT确保有足够的时间让对端收到了ACK，如果被动关闭的那方没有收到Ack，就会触发被动端重发Fin，一来一去正好2个MSL，2）有足够的时间让这个连接不会跟后面的连接混在一起（你要知道，有些自做主张的路由器会缓存IP数据包，如果连接被重用了，那么这些延迟收到的包就有可能会跟新连接混在一起）。你可以看看这篇文章《TIME_WAIT and its design implications for protocols and scalable client server systems》 关于TIME_WAIT数量太多从上面的描述我们可以知道，TIME_WAIT是个很重要的状态，但是如果在大并发的短链接下，TIME_WAIT 就会太多，这也会消耗很多系统资源。只要搜一下，你就会发现，十有八九的处理方式都是教你设置两个参数，一个叫tcp_tw_reuse，另一个叫tcp_tw_recycle的参数，这两个参数默认值都是被关闭的，后者recyle比前者resue更为激进，resue要温柔一些。另外，如果使用tcp_tw_reuse，必需设置tcp_timestamps=1，否则无效。这里，你一定要注意，打开这两个参数会有比较大的坑——可能会让TCP连接出一些诡异的问题（因为如上述一样，如果不等待超时重用连接的话，新的连接可能会建不上。正如官方文档上说的一样“It should not be changed without advice/request of technical experts”）。 关于tcp_tw_reuse官方文档上说tcp_tw_reuse 加上tcp_timestamps（又叫PAWS, for Protection Against Wrapped Sequence Numbers）可以保证协议的角度上的安全，但是你需要tcp_timestamps在两边都被打开（你可以读一下tcp_twsk_unique的源码 ）。我个人估计还是有一些场景会有问题。 关于tcp_tw_recycle如果是tcp_tw_recycle被打开了话，会假设对端开启了tcp_timestamps，然后会去比较时间戳，如果时间戳变大了，就可以重用。但是，如果对端是一个NAT网络的话（如：一个公司只用一个IP出公网）或是对端的IP被另一台重用了，这个事就复杂了。建链接的SYN可能就被直接丢掉了（你可能会看到connection time out的错误）（如果你想观摩一下Linux的内核代码，请参看源码 tcp_timewait_state_process）。 关于tcp_max_tw_buckets这个是控制并发的TIME_WAIT的数量，默认值是180000，如果超限，那么，系统会把多的给destory掉，然后在日志里打一个警告（如：time wait bucket table overflow），官网文档说这个参数是用来对抗DDoS攻击的。也说的默认值180000并不小。这个还是需要根据实际情况考虑。 Again，使用tcp_tw_reuse和tcp_tw_recycle来解决TIME_WAIT的问题是非常非常危险的，因为这两个参数违反了TCP协议（RFC 1122） 其实，TIME_WAIT表示的是你主动断连接，所以，这就是所谓的“不作死不会死”。试想，如果让对端断连接，那么这个破问题就是对方的了，呵呵。另外，如果你的服务器是于HTTP服务器，那么设置一个HTTP的KeepAlive有多重要（浏览器会重用一个TCP连接来处理多个HTTP请求），然后让客户端去断链接（你要小心，浏览器可能会非常贪婪，他们不到万不得已不会主动断连接）。 数据传输中的Sequence Number下图是我从Wireshark中截了个我在访问coolshell.cn时的有数据传输的图给你看一下，SeqNum是怎么变的。（使用Wireshark菜单中的Statistics -&gt;Flow Graph… ） 你可以看到，SeqNum的增加是和传输的字节数相关的。上图中，三次握手后，来了两个Len:1440的包，而第二个包的SeqNum就成了1441。然后第一个ACK回的是1441，表示第一个1440收到了。 注意如果你用Wireshark抓包程序看3次握手，你会发现SeqNum总是为0，不是这样的，Wireshark为了显示更友好，使用了Relative SeqNum——相对序号，你只要在右键菜单中的protocol preference 中取消掉就可以看到“Absolute SeqNum”了 TCP重传机制TCP要保证所有的数据包都可以到达，所以，必需要有重传机制。 注意，接收端给发送端的Ack确认只会确认最后一个连续的包，比如，发送端发了1,2,3,4,5一共五份数据，接收端收到了1，2，于是回ack 3，然后收到了4（注意此时3没收到），此时的TCP会怎么办？我们要知道，因为正如前面所说的，SeqNum和Ack是以字节数为单位，所以ack的时候，不能跳着确认，只能确认最大的连续收到的包，不然，发送端就以为之前的都收到了。 超时重传机制一种是不回ack，死等3，当发送方发现收不到3的ack超时后，会重传3。一旦接收方收到3后，会ack 回 4——意味着3和4都收到了。 但是，这种方式会有比较严重的问题，那就是因为要死等3，所以会导致4和5即便已经收到了，而发送方也完全不知道发生了什么事，因为没有收到Ack，所以，发送方可能会悲观地认为也丢了，所以有可能也会导致4和5的重传。 对此有两种选择： 一种是仅重传timeout的包。也就是第3份数据。 另一种是重传timeout后所有的数据，也就是第3，4，5这三份数据。 这两种方式有好也有不好。第一种会节省带宽，但是慢，第二种会快一点，但是会浪费带宽，也可能会有无用功。但总体来说都不好。因为都在等timeout，timeout可能会很长（在下篇会说TCP是怎么动态地计算出timeout的） 快速重传机制于是，TCP引入了一种叫Fast Retransmit 的算法，不以时间驱动，而以数据驱动重传。也就是说，如果，包没有连续到达，就ack最后那个可能被丢了的包，如果发送方连续收到3次相同的ack，就重传。Fast Retransmit的好处是不用等timeout了再重传。 比如：如果发送方发出了1，2，3，4，5份数据，第一份先到送了，于是就ack回2，结果2因为某些原因没收到，3到达了，于是还是ack回2，后面的4和5都到了，但是还是ack回2，因为2还是没有收到，于是发送端收到了三个ack=2的确认，知道了2还没有到，于是就马上重转2。然后，接收端收到了2，此时因为3，4，5都收到了，于是ack回6。示意图如下： Fast Retransmit只解决了一个问题，就是timeout的问题，它依然面临一个艰难的选择，就是，是重传之前的一个还是重传所有的问题。对于上面的示例来说，是重传#2呢还是重传#2，#3，#4，#5呢？因为发送端并不清楚这连续的3个ack(2)是谁传回来的？也许发送端发了20份数据，是#6，#10，#20传来的呢。这样，发送端很有可能要重传从2到20的这堆数据（这就是某些TCP的实际的实现）。可见，这是一把双刃剑。 SACK 方法另外一种更好的方式叫：Selective Acknowledgment (SACK)（参看RFC 2018），这种方式需要在TCP头里加一个SACK的东西，ACK还是Fast Retransmit的ACK，SACK则是汇报收到的数据碎版。参看下图： 这样，在发送端就可以根据回传的SACK来知道哪些数据到了，哪些没有到。于是就优化了Fast Retransmit的算法。当然，这个协议需要两边都支持。在 Linux下，可以通过tcp_sack参数打开这个功能（Linux 2.4后默认打开）。 这里还需要注意一个问题——接收方Reneging，所谓Reneging的意思就是接收方有权把已经报给发送端SACK里的数据给丢了。这样干是不被鼓励的，因为这个事会把问题复杂化了，但是，接收方这么做可能会有些极端情况，比如要把内存给别的更重要的东西。所以，发送方也不能完全依赖SACK，还是要依赖ACK，并维护Time-Out，如果后续的ACK没有增长，那么还是要把SACK的东西重传，另外，接收端这边永远不能把SACK的包标记为Ack。 注意：SACK会消费发送方的资源，试想，如果一个攻击者给数据发送方发一堆SACK的选项，这会导致发送方开始要重传甚至遍历已经发出的数据，这会消耗很多发送端的资源。详细的东西请参看《TCP SACK的性能权衡》 Duplicate SACK – 重复收到数据的问题Duplicate SACK又称D-SACK，其主要使用了SACK来告诉发送方有哪些数据被重复接收了。RFC-2883 里有详细描述和示例。下面举几个例子（来源于RFC-2883） D-SACK使用了SACK的第一个段来做标志， 如果SACK的第一个段的范围被ACK所覆盖，那么就是D-SACK 如果SACK的第一个段的范围被SACK的第二个段覆盖，那么就是D-SACK 示例一：ACK丢包下面的示例中，丢了两个ACK，所以，发送端重传了第一个数据包（3000-3499），于是接收端发现重复收到，于是回了一个SACK=3000-3500，因为ACK都到了4000意味着收到了4000之前的所有数据，所以这个SACK就是D-SACK——旨在告诉发送端我收到了重复的数据，而且我们的发送端还知道，数据包没有丢，丢的是ACK包。 Transmitted Segment Received Segment ACK Sent (Including SACK Blocks) 3000-3499 3000-3499 3500 (ACK dropped) 3500-3999 3500-3999 4000 (ACK dropped) 3000-3499 3000-3499 4000, SACK=3000-3500 示例二，网络延误下面的示例中，网络包（1000-1499）被网络给延误了，导致发送方没有收到ACK，而后面到达的三个包触发了“Fast Retransmit算法”，所以重传，但重传时，被延误的包又到了，所以，回了一个SACK=1000-1500，因为ACK已到了3000，所以，这个SACK是D-SACK——标识收到了重复的包。 这个案例下，发送端知道之前因为“Fast Retransmit算法”触发的重传不是因为发出去的包丢了，也不是因为回应的ACK包丢了，而是因为网络延时了。 Transmitted Segment Received Segment ACK Sent (Including SACK Blocks) 500-999 500-999 1000 1000-1499 (delayed) 1500-1999 1500-1999 1000, SACK=1500-2000 2000-2499 2000-2499 1000, SACK=1500-2500 2500-2999 2500-2999 1000, SACK=1500-3000 1000-1499 1000-1499 3000 1000-1499 3000, SACK=1000-1500 可见，引入了D-SACK，有这么几个好处： 可以让发送方知道，是发出去的包丢了，还是回来的ACK包丢了。 是不是自己的timeout太小了，导致重传。 网络上出现了先发的包后到的情况（又称reordering） 网络上是不是把我的数据包给复制了。 知道这些东西可以很好得帮助TCP了解网络情况，从而可以更好的做网络上的流控。 Linux下的tcp_dsack参数用于开启这个功能（Linux 2.4后默认打开） ref：TCP 的那些事儿（下） TCP的RTT算法从前面的TCP重传机制我们知道Timeout的设置对于重传非常重要。 设长了，重发就慢，丢了老半天才重发，没有效率，性能差； 设短了，会导致可能并没有丢就重发。于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。 而且，这个超时时间在不同的网络的情况下，根本没有办法设置一个死的值。只能动态地设置。 为了动态地设置，TCP引入了RTT——Round Trip Time，也就是一个数据包从发出去到回来的时间。这样发送端就大约知道需要多少的时间，从而可以方便地设置Timeout——RTO（Retransmission TimeOut），以让我们的重传机制更高效。 听起来似乎很简单，好像就是在发送端发包时记下t0，然后接收端再把这个ack回来时再记一个t1，于是RTT = t1 – t0。没那么简单，这只是一个采样，不能代表普遍情况。 经典算法RFC793 中定义的经典算法是这样的： 首先，先采样RTT，记下最近好几次的RTT值。 然后做平滑计算SRTT（ Smoothed RTT）。公式为：（其中的 α 取值在0.8 到 0.9之间，这个算法英文叫Exponential weighted moving average，中文叫：加权移动平均） SRTT = ( α SRTT ) + ((1- α) RTT) 开始计算RTO。公式如下： RTO = min [ UBOUND, max [ LBOUND, (β * SRTT) ] ] 其中： UBOUND是最大的timeout时间，上限值 LBOUND是最小的timeout时间，下限值 β 值一般在1.3到2.0之间。 Karn / Partridge 算法但是上面的这个算法在重传的时候会出有一个终极问题——你是用第一次发数据的时间和ack回来的时间做RTT样本值，还是用重传的时间和ACK回来的时间做RTT样本值？ 这个问题无论你选那头都是按下葫芦起了瓢。 如下图所示： 情况（a）是ack没回来，所以重传。如果你计算第一次发送和ACK的时间，那么，明显算大了。 情况（b）是ack回来慢了，但是导致了重传，但刚重传不一会儿，之前ACK就回来了。如果你是算重传的时间和ACK回来的时间的差，就会算短了。 所以1987年的时候，搞了一个叫Karn / Partridge Algorithm，这个算法的最大特点是——忽略重传，不把重传的RTT做采样（你看，你不需要去解决不存在的问题）。 但是，这样一来，又会引发一个大BUG——如果在某一时间，网络闪动，突然变慢了，产生了比较大的延时，这个延时导致要重转所有的包（因为之前的RTO很小），于是，因为重转的不算，所以，RTO就不会被更新，这是一个灾难。 于是Karn算法用了一个取巧的方式——只要一发生重传，就对现有的RTO值翻倍（这就是所谓的 Exponential backoff），很明显，这种死规矩对于一个需要估计比较准确的RTT也不靠谱。 Jacobson / Karels 算法前面两种算法用的都是“加权移动平均”，这种方法最大的毛病就是如果RTT有一个大的波动的话，很难被发现，因为被平滑掉了。所以，1988年，又有人推出来了一个新的算法，这个算法叫Jacobson / Karels Algorithm（参看RFC6289）。这个算法引入了最新的RTT的采样和平滑过的SRTT的差距做因子来计算。 公式如下：（其中的DevRTT是Deviation RTT的意思） 计算平滑RTT：SRTT= SRTT + α (RTT – SRTT)计算平滑RTT和真实的差距（加权移动平均）：DevRTT= (1 - β) * DevRTT + β * (| RTT - SRTT | )神一样的公式：RTO= µ * SRTT + ∂ * DevRTT 其中：在Linux下，α = 0.125，β = 0.25， μ = 1，∂ = 4 ——这就是算法中的“调得一手好参数”，nobody knows why, it just works…） 最后的这个算法在被用在今天的TCP协议中（Linux的源代码在：tcp_rtt_estimator。 TCP滑动窗口需要说明一下，如果你不了解TCP的滑动窗口这个事，你等于不了解TCP协议。我们都知道，TCP必需要解决的可靠传输以及包乱序（reordering）的问题，所以，TCP必需要知道网络实际的数据处理带宽或是数据处理速度，这样才不会引起网络拥塞，导致丢包。 所以，TCP引入了一些技术和设计来做网络流控，Sliding Window是其中一个技术。 前面我们说过，TCP头里有一个字段叫Window，又叫Advertised-Window，这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。 为了说明滑动窗口，我们需要先看一下TCP缓冲区的一些数据结构： 上图中，我们可以看到： 接收端LastByteRead指向了TCP缓冲区中读到的位置，NextByteExpected指向的地方是收到的连续包的最后一个位置，LastByteRcved指向的是收到的包的最后一个位置，我们可以看到中间有些数据还没有到达，所以有数据空白区。 发送端的LastByteAcked指向了被接收端Ack过的位置（表示成功发送确认），LastByteSent表示发出去了，但还没有收到成功确认的Ack，LastByteWritten指向的是上层应用正在写的地方。 于是： 接收端在给发送端回ACK中会汇报自己的AdvertisedWindow = MaxRcvBuffer – LastByteRcvd – 1; 而发送方会根据这个窗口来控制发送数据的大小，以保证接收方可以处理。 下面我们来看一下发送方的滑动窗口示意图： （图片来源） 上图中分成了四个部分，分别是：（其中那个黑模型就是滑动窗口） #1已收到ack确认的数据。 #2发还没收到ack的。 #3在窗口中还没有发出的（接收方还有空间）。 #4窗口以外的数据（接收方没空间） 下面是个滑动后的示意图（收到36的ack，并发出了46-51的字节）： 下面我们来看一个接受端控制发送端的图示： （图片来源） Zero Window上图，我们可以看到一个处理缓慢的Server（接收端）是怎么把Client（发送端）的TCP Sliding Window给降成0的。此时，你一定会问，如果Window变成0了，TCP会怎么样？是不是发送端就不发数据了？是的，发送端就不发数据了，你可以想像成“Window Closed”，那你一定还会问，如果发送端不发数据了，接收方一会儿Window size 可用了，怎么通知发送端呢？ 解决这个问题，TCP使用了Zero Window Probe技术，缩写为ZWP，也就是说，发送端在窗口变成0后，会发ZWP的包给接收方，让接收方来ack他的Window尺寸，一般这个值会设置成3次，第次大约30-60秒（不同的实现可能会不一样）。如果3次过后还是0的话，有的TCP实现就会发RST把链接断了。 注意：只要有等待的地方都可能出现DDoS攻击，Zero Window也不例外，一些攻击者会在和HTTP建好链发完GET请求后，就把Window设置为0，然后服务端就只能等待进行ZWP，于是攻击者会并发大量的这样的请求，把服务器端的资源耗尽。（关于这方面的攻击，大家可以移步看一下Wikipedia的SockStress词条） 另外，Wireshark中，你可以使用tcp.analysis.zero_window来过滤包，然后使用右键菜单里的follow TCP stream，你可以看到ZeroWindowProbe及ZeroWindowProbeAck的包。 Silly Window SyndromeSilly Window Syndrome翻译成中文就是“糊涂窗口综合症”。正如你上面看到的一样，如果我们的接收方太忙了，来不及取走Receive Windows里的数据，那么，就会导致发送方越来越小。到最后，如果接收方腾出几个字节并告诉发送方现在有几个字节的window，而我们的发送方会义无反顾地发送这几个字节。 要知道，我们的TCP+IP头有40个字节，为了几个字节，要达上这么大的开销，这太不经济了。 另外，你需要知道网络上有个MTU，对于以太网来说，MTU是1500字节，除去TCP+IP头的40个字节，真正的数据传输可以有1460，这就是所谓的MSS（Max Segment Size）注意，TCP的RFC定义这个MSS的默认值是536，这是因为 RFC 791里说了任何一个IP设备都得最少接收576尺寸的大小（实际上来说576是拨号的网络的MTU，而576减去IP头的20个字节就是536）。 如果你的网络包可以塞满MTU，那么你可以用满整个带宽，如果不能，那么你就会浪费带宽。（大于MTU的包有两种结局，一种是直接被丢了，另一种是会被重新分块打包发送） 你可以想像成一个MTU就相当于一个飞机的最多可以装的人，如果这飞机里满载的话，带宽最高，如果一个飞机只运一个人的话，无疑成本增加了，也而相当二。 所以，Silly Windows Syndrome这个现像就像是你本来可以坐200人的飞机里只做了一两个人。 要解决这个问题也不难，就是避免对小的window size做出响应，直到有足够大的window size再响应，这个思路可以同时实现在sender和receiver两端。 如果这个问题是由Receiver端引起的，那么就会使用 David D Clark’s 方案。在receiver端，如果收到的数据导致window size小于某个值，可以直接ack(0)回sender，这样就把window给关闭了，也阻止了sender再发数据过来，等到receiver端处理了一些数据后windows size 大于等于了MSS，或者，receiver buffer有一半为空，就可以把window打开让send 发送数据过来。 如果这个问题是由Sender端引起的，那么就会使用著名的 Nagle’s algorithm。这个算法的思路也是延时处理，他有两个主要的条件：1）要等到 Window Size&gt;=MSS 或是 Data Size &gt;=MSS，2）收到之前发送数据的ack回包，他才会发数据，否则就是在攒数据。 另外，Nagle算法默认是打开的，所以，对于一些需要小包场景的程序——比如像telnet或ssh这样的交互性比较强的程序，你需要关闭这个算法。你可以在Socket设置TCP_NODELAY选项来关闭这个算法（关闭Nagle算法没有全局参数，需要根据每个应用自己的特点来关闭） setsockopt(sock_fd, IPPROTO_TCP, TCP_NODELAY, (char *) &amp; value, sizeof(int)); 另外，网上有些文章说TCP_CORK的socket option是也关闭Nagle算法，这不对。TCP_CORK其实是更新激进的Nagle算汉，完全禁止小包发送，而Nagle算法没有禁止小包发送，只是禁止了大量的小包发送。最好不要两个选项都设置。 TCP的拥塞处理 – Congestion Handling上面我们知道了，TCP通过Sliding Window来做流控（Flow Control），但是TCP觉得这还不够，因为Sliding Window需要依赖于连接的发送端和接收端，其并不知道网络中间发生了什么。TCP的设计者觉得，一个伟大而牛逼的协议仅仅做到流控并不够，因为流控只是网络模型4层以上的事，TCP的还应该更聪明地知道整个网络上的事。 具体一点，我们知道TCP通过一个timer采样了RTT并计算RTO，但是，如果网络上的延时突然增加，那么，TCP对这个事做出的应对只有重传数据，但是，重传会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，于是，这个情况就会进入恶性循环被不断地放大。试想一下，如果一个网络内有成千上万的TCP连接都这么行事，那么马上就会形成“网络风暴”，TCP这个协议就会拖垮整个网络。这是一个灾难。 所以，TCP不能忽略网络上发生的事情，而无脑地一个劲地重发数据，对网络造成更大的伤害。对此TCP的设计理念是：TCP不是一个自私的协议，当拥塞发生的时候，要做自我牺牲。就像交通阻塞一样，每个车都应该把路让出来，而不要再去抢路了。 关于拥塞控制的论文请参看《Congestion Avoidance and Control》(PDF) 拥塞控制主要是四个算法：1）慢启动，2）拥塞避免，3）拥塞发生，4）快速恢复。这四个算法不是一天都搞出来的，这个四算法的发展经历了很多时间，到今天都还在优化中。 备注: 1988年，TCP-Tahoe 提出了1）慢启动，2）拥塞避免，3）拥塞发生时的快速重传 1990年，TCP Reno 在Tahoe的基础上增加了4）快速恢复 慢热启动算法 – Slow Start首先，我们来看一下TCP的慢热启动。慢启动的意思是，刚刚加入网络的连接，一点一点地提速，不要一上来就像那些特权车一样霸道地把路占满。新同学上高速还是要慢一点，不要把已经在高速上的秩序给搞乱了。 慢启动的算法如下(cwnd全称Congestion Window)： 连接建好的开始先初始化cwnd = 1，表明可以传一个MSS大小的数据。 每当收到一个ACK，cwnd++; 呈线性上升 每当过了一个RTT，cwnd = cwnd * 2; 呈指数让升 还有一个ssthresh（slow start threshold），是一个上限，当cwnd &gt;= ssthresh时，就会进入“拥塞避免算法”（后面会说这个算法） 所以，我们可以看到，如果网速很快的话，ACK也会返回得快，RTT也会短，那么，这个慢启动就一点也不慢。下图说明了这个过程。 这里，我需要提一下的是一篇Google的论文《An Argument for Increasing TCP’s Initial Congestion Window》Linux 3.0后采用了这篇论文的建议——把cwnd 初始化成了 10个MSS。 而Linux 3.0以前，比如2.6，Linux采用了RFC3390，cwnd是跟MSS的值来变的，如果MSS&lt; 1095，则cwnd = 4；如果MSS&gt;2190，则cwnd=2；其它情况下，则是3。 拥塞避免算法 – Congestion Avoidance前面说过，还有一个ssthresh（slow start threshold），是一个上限，当cwnd &gt;= ssthresh时，就会进入“拥塞避免算法”。一般来说ssthresh的值是65535，单位是字节，当cwnd达到这个值时后，算法如下： 收到一个ACK时，cwnd = cwnd + 1 / cwnd 当每过一个RTT时，cwnd = cwnd + 1 这样就可以避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值。很明显，是一个线性上升的算法。 拥塞状态时的算法前面我们说过，当丢包的时候，会有两种情况： 等到RTO超时，重传数据包。TCP认为这种情况太糟糕，反应也很强烈。 sshthresh = cwnd / 2 cwnd 重置为 1 进入慢启动过程 Fast Retransmit算法，也就是在收到3个duplicate ACK时就开启重传，而不用等到RTO超时。 TCP Tahoe的实现和RTO超时一样。 TCP Reno的实现是： cwnd = cwnd /2 sshthresh = cwnd 进入快速恢复算法——Fast Recovery 上面我们可以看到RTO超时后，sshthresh会变成cwnd的一半，这意味着，如果cwnd&lt;=sshthresh时出现的丢包，那么TCP的sshthresh就会减了一半，然后等cwnd又很快地以指数级增涨爬到这个地方时，就会成慢慢的线性增涨。我们可以看到，TCP是怎么通过这种强烈地震荡快速而小心得找到网站流量的平衡点的。 快速恢复算法 – Fast RecoveryTCP Reno 这个算法定义在RFC5681。快速重传和快速恢复算法一般同时使用。快速恢复算法是认为，你还有3个Duplicated Acks说明网络也不那么糟糕，所以没有必要像RTO超时那么强烈。 注意，正如前面所说，进入Fast Recovery之前，cwnd 和 sshthresh已被更新： cwnd = cwnd /2 sshthresh = cwnd 然后，真正的Fast Recovery算法如下： cwnd = sshthresh + 3 * MSS （3的意思是确认有3个数据包被收到了） 重传Duplicated ACKs指定的数据包 如果再收到 duplicated Acks，那么cwnd = cwnd +1 如果收到了新的Ack，那么，cwnd = sshthresh ，然后就进入了拥塞避免的算法了。 如果你仔细思考一下上面的这个算法，你就会知道，上面这个算法也有问题，那就是——它依赖于3个重复的Acks。注意，3个重复的Acks并不代表只丢了一个数据包，很有可能是丢了好多包。但这个算法只会重传一个，而剩下的那些包只能等到RTO超时，于是，进入了恶梦模式——超时一个窗口就减半一下，多个超时会超成TCP的传输速度呈级数下降，而且也不会触发Fast Recovery算法了。 通常来说，正如我们前面所说的，SACK或D-SACK的方法可以让Fast Recovery或Sender在做决定时更聪明一些，但是并不是所有的TCP的实现都支持SACK（SACK需要两端都支持），所以，需要一个没有SACK的解决方案。而通过SACK进行拥塞控制的算法是FACK（后面会讲） TCP New Reno 于是，1995年，TCP New Reno（参见 RFC 6582 ）算法提出来，主要就是在没有SACK的支持下改进Fast Recovery算法的—— 当sender这边收到了3个Duplicated Acks，进入Fast Retransimit模式，开发重传重复Acks指示的那个包。如果只有这一个包丢了，那么，重传这个包后回来的Ack会把整个已经被sender传输出去的数据ack回来。如果没有的话，说明有多个包丢了。我们叫这个ACK为Partial ACK。 一旦Sender这边发现了Partial ACK出现，那么，sender就可以推理出来有多个包被丢了，于是乎继续重传sliding window里未被ack的第一个包。直到再也收不到了Partial Ack，才真正结束Fast Recovery这个过程 我们可以看到，这个“Fast Recovery的变更”是一个非常激进的玩法，他同时延长了Fast Retransmit和Fast Recovery的过程。 算法示意图下面我们来看一个简单的图示以同时看一下上面的各种算法的样子： FACK算法FACK全称Forward Acknowledgment 算法，论文地址在这里（PDF）Forward Acknowledgement: Refining TCP Congestion Control 这个算法是其于SACK的，前面我们说过SACK是使用了TCP扩展字段Ack了有哪些数据收到，哪些数据没有收到，他比Fast Retransmit的3 个duplicated acks好处在于，前者只知道有包丢了，不知道是一个还是多个，而SACK可以准确的知道有哪些包丢了。 所以，SACK可以让发送端这边在重传过程中，把那些丢掉的包重传，而不是一个一个的传，但这样的一来，如果重传的包数据比较多的话，又会导致本来就很忙的网络就更忙了。所以，FACK用来做重传过程中的拥塞流控。 这个算法会把SACK中最大的Sequence Number 保存在snd.fack这个变量中，snd.fack的更新由ack带秋，如果网络一切安好则和snd.una一样（snd.una就是还没有收到ack的地方，也就是前面sliding window里的category #2的第一个地方） 然后定义一个awnd = snd.nxt – snd.fack（snd.nxt指向发送端sliding window中正在要被发送的地方——前面sliding windows图示的category#3第一个位置），这样awnd的意思就是在网络上的数据。（所谓awnd意为：actual quantity of data outstanding in the network） 如果需要重传数据，那么，awnd = snd.nxt – snd.fack + retran_data，也就是说，awnd是传出去的数据 + 重传的数据。 然后触发Fast Recovery 的条件是： ( ( snd.fack – snd.una ) &gt; (3 * MSS) ) || (dupacks == 3) ) 。这样一来，就不需要等到3个duplicated acks才重传，而是只要sack中的最大的一个数据和ack的数据比较长了（3个MSS），那就触发重传。在整个重传过程中cwnd不变。直到当第一次丢包的snd.nxt&lt;=snd.una（也就是重传的数据都被确认了），然后进来拥塞避免机制——cwnd线性上涨。 我们可以看到如果没有FACK在，那么在丢包比较多的情况下，原来保守的算法会低估了需要使用的window的大小，而需要几个RTT的时间才会完成恢复，而FACK会比较激进地来干这事。 但是，FACK如果在一个网络包会被 reordering的网络里会有很大的问题。 其它拥塞控制算法简介TCP Vegas 拥塞控制算法这个算法1994年被提出，它主要对TCP Reno 做了些修改。这个算法通过对RTT的非常重的监控来计算一个基准RTT。然后通过这个基准RTT来估计当前的网络实际带宽，如果实际带宽比我们的期望的带宽要小或是要多的活，那么就开始线性地减少或增加cwnd的大小。如果这个计算出来的RTT大于了Timeout后，那么，不等ack超时就直接重传。（Vegas 的核心思想是用RTT的值来影响拥塞窗口，而不是通过丢包） 这个算法的论文是《TCP Vegas: End to End Congestion Avoidance on a Global Internet》这篇论文给了Vegas和 New Reno的对比： 关于这个算法实现，你可以参看Linux源码：/net/ipv4/tcp_vegas.h， /net/ipv4/tcp_vegas.c HSTCP(High Speed TCP) 算法这个算法来自RFC 3649（Wikipedia词条）。其对最基础的算法进行了更改，他使得Congestion Window涨得快，减得慢。其中： 拥塞避免时的窗口增长方式： cwnd = cwnd + α(cwnd) / cwnd 丢包后窗口下降方式：cwnd = (1- β(cwnd)) * cwnd 注：α(cwnd)和β(cwnd)都是函数，如果你要让他们和标准的TCP一样，那么让α(cwnd)=1，β(cwnd)=0.5就可以了。 对于α(cwnd)和β(cwnd)的值是个动态的变换的东西。 关于这个算法的实现，你可以参看Linux源码：/net/ipv4/tcp_highspeed.c TCP BIC 算法2004年，产内出BIC算法。现在你还可以查得到相关的新闻《Google：美科学家研发BIC-TCP协议 速度是DSL六千倍》 BIC全称Binary Increase Congestion control，在Linux 2.6.8中是默认拥塞控制算法。BIC的发明者发这么多的拥塞控制算法都在努力找一个合适的cwnd – Congestion Window，而且BIC-TCP的提出者们看穿了事情的本质，其实这就是一个搜索的过程，所以BIC这个算法主要用的是Binary Search——二分查找来干这个事。 关于这个算法实现，你可以参看Linux源码：/net/ipv4/tcp_bic.c TCP WestWood算法westwood采用和Reno相同的慢启动算法、拥塞避免算法。westwood的主要改进方面：在发送端做带宽估计，当探测到丢包时，根据带宽值来设置拥塞窗口、慢启动阈值。 那么，这个算法是怎么测量带宽的？每个RTT时间，会测量一次带宽，测量带宽的公式很简单，就是这段RTT内成功被ack了多少字节。因为，这个带宽和用RTT计算RTO一样，也是需要从每个样本来平滑到一个值的——也是用一个加权移平均的公式。 另外，我们知道，如果一个网络的带宽是每秒可以发送X个字节，而RTT是一个数据发出去后确认需要的时候，所以，X RTT应该是我们缓冲区大小。所以，在这个算法中，ssthresh的值就是est_BD min-RTT(最小的RTT值)，如果丢包是Duplicated ACKs引起的，那么如果cwnd &gt; ssthresh，则 cwin = ssthresh。如果是RTO引起的，cwnd = 1，进入慢启动。 关于这个算法实现，你可以参看Linux源码： /net/ipv4/tcp_westwood.c 其它更多的算法，你可以从Wikipedia的 TCP Congestion Avoidance Algorithm 词条中找到相关的线索]]></content>
      <tags>
        <tag>tcp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP 协议中的 Window Size与吞吐量]]></title>
    <url>%2F2018%2F03%2F04%2Ftcp-window-size%2F</url>
    <content type="text"><![CDATA[摘要「rwnd」：接收窗口「cwnd」：拥塞窗口「ssthresh」：慢启动阈值 引自：TCP 协议中的 Window Size与吞吐量 TCP协议中影响实际业务流量的参数很多，这里主要分析一下窗口的影响。 ​TCP窗口目的为了获得最优的连接速率，使用TCP窗口来控制流速率（flow control），滑动窗口就是一种主要的机制。这个窗口允许源端在给定连接传送数据分段而不用等待目标端返回ACK，一句话描述： 窗口的大小决定在不需要对端响应（acknowledgement）情况下传送数据的数量。 ​官方定义：“The amount of octets that can be transmitted without receiving an acknowledgement from the other side”。 TCP窗口机制 - 接收窗口「rwnd」​​TCP header中有一个Window Size字段，它其实是指接收端的窗口，即接收窗口(「rwnd」)，用来告知发送端自己所能接收的数据量，从而达到一部分流控的目的。其实TCP在整个发送过程中，也在度量当前的网络状态，目的是为了维持一个健康稳定的发送过程，比如拥塞控制。因此，数据是在某些机制的控制下进行传输的，就是窗口机制。发送端的发送窗口是基于接收端的接收窗口来计算的，也就是我们常说的TCP是有连接的发送，数据传输需要对端确认，发送的数据分为如下四类来看 窗口滑动发送数据 已经发送并且对端确认（Sent/ACKed）：发送窗外缓冲区外 已经发送但未收到确认数据（Sent/UnACKed）： 发送窗内缓冲区内​ 允许发送但尚未防的数据​（Unsent/Inside）： 发送窗内缓冲区内​ 未发送暂不允许（Unsent/Outside）： 发送窗外缓冲区内​ TCP窗口就是这样逐渐滑动，发送新的数据，滑动的依据就是发送数据已经收到ACK，确认对端收到，才能继续窗口滑动发送新的数据。可以看到窗口大小对于吞吐量有着重要影响，同时ACK响应与系统延时又密切相关。 需要说明的是： 发送端的窗口过大：会引起接收端关闭窗口，处理不过来； 发送端的窗口设置较小：结果就是不能充分利用带宽； 所以仔细调节窗口对于适应不同延迟和带宽要求的系统很重要。 TCP接收窗口「rwnd」大小最早TCP协议涉及用来大范围网络传输时候，其实是没有超过56Kb/s的​连接速度的。因此，TCP包头中只保留了16bit用来标识窗口大小，允许的最大缓存大小不超过64KB。为了打破这一限制，RFC1323规定了TCP窗口尺寸选择，是在TCP连接开始的时候三步握手的时候协商的（SYN, SYN-ACK, ACK），会协商一个 Window size scaling factor，之后交互数据中的是Window size value，所以最终的窗口大小是二者的乘积. Window size value: 64 or 0000 0000 0100 0000 (16 bits) Window size scaling factor: 256 or 2 ^ 8 (as advertised by the 1st packet) The actual window size is 16,384 (64 window size value * 256 window size scaling factor) 这里的窗口大小就意味着，直到发送16384个字节，才会停止等待对方的ACK.随着双方回话继续，窗口的大小可以修改window size value 参数完成变窄或变宽，但是注意：Window size scaling factor 乘积因子必须保持不变。在RFC1323中规定的偏移（shift count）是14，也就是说最大的窗口可以达到Gbit,很大。 Wireshark抓包实例 这一机制并不总是默认开启的和系统有关，貌似Linux默认开启，Windows默认关闭。 ​TCP窗口参数设置TCP窗口起着控制流量的作用，实际使用时这是一个双端协调的过程，还涉及到TCP的慢启动​（Rapid Increase/Multiplicative Decrease），拥塞避免，拥塞窗口和拥塞控制。可以记住，发送速率是由min(拥塞窗口，接收窗口)，接收窗口在下文有讲。 TCP接收窗口「rwnd」优化设置​TCP接收窗口「rwnd」设置方法 一个简单的原则是2倍的BDP.这里的BDP的意思是bandwidth-delayproduct，也就是带宽和时延的乘积，带宽对于网络取最差连接的带宽。 buffer size = 2 * bandwidth * delay​ 还有一种简单的方式，使用ping来计算网络的环回时延（RTT），然后表达为： buffer size = bandwidth * RTT​ 接收窗口「rwnd」计算方法中为什么是2倍？因为可以这么想，如果滑动窗口是 bandwidth * delay，当发送一次数据最后一个字节刚到时，对端要回ACK才能继续发送，就需要等待一次单向时延的时间，所以当是2倍时，刚好就能在等ACK的时间继续发送数据，等收到ACK时数据刚好发送完成，这样就提高了效率。 举个例子 带宽是20Mbps,通过ping我们计算单向时延(RTT)是20ms;可以计算：20000000bps * 8 * 0.02 = 52,428bytes​因此我们最优窗口用 104,856bytes = 2 x 52,428所以说当发送者发送 104,856 bytes 数据后才需要等待一个ACK响应，当发送了一半的时候，对端已经收到并且返回ACK（理想情况），等到ACK回来，又把剩下的一半发送出去了，所以发送端就无需等待ACK返回。 发现了么？这里的窗口已经明显大于64KB了，所以机制改善了，上一级。 TCP窗口流量控制​​现在我们看看到底如何控制流量。TCP在传输数据时和 windows size 关系密切，本身窗口用来控制流量，在传输数据时，发送方数据超过接收方就会丢包，流量控制，流量控制要求数据传输双方在每次交互时声明各自的接收窗口「rwnd」大小，用来表示自己最大能保存多少数据，这主要是针对接收方而言的，通俗点儿说就是让发送方知道接收方能吃几碗饭，如果窗口衰减到零，也就是发送方不能再发了，那么就说明吃饱了，必须消化消化，如果硬撑胀漏了，那就是丢包了。 流量控制 慢启动 （ 拥塞窗口「cwnd」）虽然流量控制可以避免发送方过载接收方，但是却无法避免过载网络，这是因为接收窗口「rwnd」只反映了服务器个体的情况，却无法反映网络整体的情况。 为了避免网络过载，慢启动引入了拥塞窗口「cwnd」的概念，用来表示发送方在得到接收方确认前，最大允许传输的未经确认的数据。「cwnd」同「rwnd」相比不同的是：它只是发送方的一个内部参数，无需通知给接收方，其初始值往往比较小，然后随着数据包被接收方确认，窗口成倍扩大，有点类似于拳击比赛，开始时不了解敌情，往往是次拳试探，慢慢心里有底了，开始逐渐加大重拳进攻的力度。 拥塞窗口扩大 在慢启动的过程中，随着「cwnd」的增加，可能会出现网络过载，其外在表现就是丢包，一旦出现此类问题，「cwnd」的大小会迅速衰减，以便网络能够缓过来。 拥塞窗口与丢包 说明： 网络中实际传输的未经确认的数据大小取决于 min (「rwnd」和「cwnd」) 拥塞避免​ （ 慢启动阈值「ssthresh」）从慢启动的介绍中，我们能看到，发送方通过对「cwnd」大小的控制，能够避免网络过载，在此过程中，丢包与其说是一个网络问题，倒不如说是一种反馈机制，通过它我们可以感知到发生了网络拥塞，进而调整数据传输策略；实际上，这里还有一个慢启动阈值 「ssthresh」的概念， 「cwnd」 &lt; 「ssthresh」，那么表示在慢启动阶段； 「cwnd」 &gt; 「ssthresh」，那么表示在拥塞避免阶段，此时「cwnd」不再像慢启动阶段那样呈指数级增长，而是趋向于线性增长，以期避免网络拥塞，此阶段有多种算法实现，通常保持缺省即可，这里就不一一说明了。 如何调整 - 接收窗口「rwnd」很多时候TCP的传输速率异常偏低，很有可能是接收窗口「rwnd」过小导致，尤其对于时延较大的网络，实际上接收窗口「rwnd」的合理值取决于BDP的大小，也就是带宽和延迟的乘积。假设带宽是 100Mbps，延迟是 100ms，那么计算过程如下： BDP = 100Mbps 100ms = (100 / 8) (100 / 1000) = 1.25MB​ ​此问题下如果想最大限度提升吞度量，接收窗口「rwnd」的大小不应小于 1.25MB。 如何调整 - 拥塞窗口「cwnd」一般来说「cwnd」的初始值取决于MSS的大小，计算方法如下： min(4 MSS, max(2 MSS, 4380)) 以太网标准的MSS大小通常是1460，所以「cwnd」的初始值是3MSS。当我们浏览视频或者下载软件的时候，「cwnd」初始值的影响并不明显，这是因为传输的数据量比较大，时间比较长，相比之下，即便慢启动阶段「cwnd」初始值比较小，也会在相对很短的时间内加速到满窗口，基本上可以忽略不计。下图使用IxChariot完成一次设置​ 设置cwnd 不过当我们浏览网页的时候，情况就不一样了，这是因为传输的数据量比较小，时间比较短，相比之下，如果慢启动阶段「cwnd」初始值比较小，那么很可能还没来得及加速到满窗口，通讯就结束了。这就好比博尔特参加百米比赛，如果起跑慢的话，即便他的加速很快，也可能拿不到好成绩，因为还没等他完全跑起来，终点线已经到了]]></content>
      <tags>
        <tag>tcp</tag>
        <tag>tcp窗口</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP/2 的那些事儿]]></title>
    <url>%2F2018%2F03%2F02%2FHTTP-2%2F</url>
    <content type="text"><![CDATA[引自： HTTP2.0那些事 HTTP2.0那些事 HTTP 2.0 协议详解；待补充，图片不错 HTTP2.0的前世http2.0的前世是http1.0和http1.1这两兄弟。虽然之前仅仅只有两个版本，但这两个版本所包含的协议规范之庞大，足以让任何一个有经验的工程师为之头疼。http1.0诞生于1996年，协议文档足足60页。之后第三年，http1.1也随之出生，协议文档膨胀到了176页。不过和我们手机端app升级不同的是，网络协议新版本并不会马上取代旧版本。实际上，1.0和1.1在之后很长的一段时间内一直并存，这是由于网络基础设施更新缓慢所决定的。今天的http2.0也是一样，新版协议再好也需要业界的产品锤炼，需要基础设施逐年累月的升级换代才能普及。 HTTP站在TCP之上理解http协议之前一定要对TCP有一定基础的了解。HTTP是建立在TCP协议之上，TCP协议作为传输层协议其实离应用层并不远。HTTP协议的瓶颈及其优化技巧都是基于TCP协议本身的特性。比如TCP建立连接时三次握手有1.5个RTT（round-trip time）的延迟，为了避免每次请求的都经历握手带来的延迟，应用层会选择不同策略的http长链接方案。又比如TCP在建立连接的初期有慢启动（slow start）的特性，所以连接的重用总是比新建连接性能要好。 HTTP应用场景http诞生之初主要是应用于web端内容获取，那时候内容还不像现在这样丰富，排版也没那么精美，用户交互的场景几乎没有。对于这种简单的获取网页内容的场景，http表现得还算不错。但随着互联网的发展和web2.0的诞生，更多的内容开始被展示（更多的图片文件），排版变得更精美（更多的css），更复杂的交互也被引入（更多的js）。用户打开一个网站首页所加载的数据总量和请求的个数也在不断增加。今天绝大部分的门户网站首页大小都会超过2M，请求数量可以多达100个。另一个广泛的应用是在移动互联网的客户端app，不同性质的app对http的使用差异很大。对于电商类app，加载首页的请求也可能多达10多个。对于微信这类IM，http请求可能仅限于语音和图片文件的下载，请求出现的频率并不算高。 因为延迟，所以慢影响一个网络请求的因素主要有两个，带宽和延迟。今天的网络基础建设已经使得带宽得到极大的提升，大部分时候都是延迟在影响响应速度。http1.0被抱怨最多的就是连接无法复用，和head of line blocking这两个问题。理解这两个问题有一个十分重要的前提：客户端是依据域名来向服务器建立连接，一般PC端浏览器会针对单个域名的server同时建立6～8个连接，手机端的连接数则一般控制在4～6个。显然连接数并不是越多越好，资源开销和整体延迟都会随之增大。 连接无法复用会导致每次请求都经历三次握手和慢启动。三次握手在高延迟的场景下影响较明显，慢启动则对文件类大请求影响较大。 head of line blocking会导致带宽无法被充分利用，以及后续健康请求被阻塞。假设有5个请求同时发出，如下图： [图1] 对于http1.0的实现，在第一个请求没有收到回复之前，后续从应用层发出的请求只能排队，请求2，3，4，5只能等请求1的response回来之后才能逐个发出。网络通畅的时候性能影响不大，一旦请求1的request因为什么原因没有抵达服务器，或者response因为网络阻塞没有及时返回，影响的就是所有后续请求，问题就变得比较严重了。 解决连接无法复用http1.0协议头里可以设置Connection:Keep-Alive。在header里设置Keep-Alive可以在一定时间内复用连接，具体复用时间的长短可以由服务器控制，一般在15s左右。到http1.1之后Connection的默认值就是Keep-Alive，如果要关闭连接复用需要显式的设置Connection:Close。一段时间内的连接复用对PC端浏览器的体验帮助很大，因为大部分的请求在集中在一小段时间以内。但对移动app来说，成效不大，app端的请求比较分散且时间跨度相对较大。所以移动端app一般会从应用层寻求其它解决方案，长连接方案或者伪长连接方案： 方案一：基于tcp的长链接现在越来越多的移动端app都会建立一条自己的长链接通道，通道的实现是基于tcp协议。基于tcp的socket编程技术难度相对复杂很多，而且需要自己制定协议，但带来的回报也很大。信息的上报和推送变得更及时，在请求量爆发的时间点还能减轻服务器压力（http短连接模式会频繁的创建和销毁连接）。不止是IM app有这样的通道，像淘宝这类电商类app都有自己的专属长连接通道了。现在业界也有不少成熟的方案可供选择了，google的protobuf就是其中之一。 方案二：http long-pollinglong-polling可以用下图表示： [图2] 客户端在初始状态就会发送一个polling请求到服务器，服务器并不会马上返回业务数据，而是等待有新的业务数据产生的时候再返回。所以连接会一直被保持，一旦结束马上又会发起一个新的polling请求，如此反复，所以一直会有一个连接被保持。服务器有新的内容产生的时候，并不需要等待客户端建立一个新的连接。做法虽然简单，但有些难题需要攻克才能实现稳定可靠的业务框架： 和传统的http短链接相比，长连接会在用户增长的时候极大的增加服务器压力 移动端网络环境复杂，像wifi和4g的网络切换，进电梯导致网络临时断掉等，这些场景都需要考虑怎么重建健康的连接通道。 这种polling的方式稳定性并不好，需要做好数据可靠性的保证，比如重发和ack机制。 polling的response有可能会被中间代理cache住，要处理好业务数据的过期机制。 long-polling方式还有一些缺点是无法克服的，比如每次新的请求都会带上重复的header信息，还有数据通道是单向的，主动权掌握在server这边，客户端有新的业务请求的时候无法及时传送。 方案三：http streaminghttp streaming流程大致如下： [图3] 同long-polling不同的是，server并不会结束初始的streaming请求，而是持续的通过这个通道返回最新的业务数据。显然这个数据通道也是单向的。streaming是通过在server response的头部里增加”Transfer Encoding: chunked”来告诉客户端后续还会有新的数据到来。除了和long－polling相同的难点之外，streaming还有几个缺陷： 有些代理服务器会等待服务器的response结束之后才会将结果推送到请求客户端。对于streaming这种永远不会结束的方式来说，客户端就会一直处于等待response的过程中。 业务数据无法按照请求来做分割，所以客户端没收到一块数据都需要自己做协议解析，也就是说要做自己的协议定制。 streaming不会产生重复的header数据。 方案四：web socketWebSocket和传统的tcp socket连接相似，也是基于tcp协议，提供双向的数据通道。WebSocket优势在于提供了message的概念，比基于字节流的tcp socket使用更简单，同时又提供了传统的http所缺少的长连接功能。不过WebSocket相对较新，2010年才起草，并不是所有的浏览器都提供了支持。各大浏览器厂商最新的版本都提供了支持。 1.4 解决head of line blockingHead of line blocking(以下简称为holb)是http2.0之前网络体验的最大祸源。正如图1中所示，健康的请求会被不健康的请求影响，而且这种体验的损耗受网络环境影响，出现随机且难以监控。为了解决holb带来的延迟，协议设计者设计了一种新的pipelining机制。 http pipeliningpipelining的流程图可以用下图表示： [图4] 和图一相比最大的差别是，请求2，3，4，5不用等请求1的response返回之后才发出，而是几乎在同一时间把request发向了服务器。2，3，4，5及所有后续共用该连接的请求节约了等待的时间，极大的降低了整体延迟。下图可以清晰的看出这种新机制对延迟的改变： [图5] 不过pipelining并不是救世主，它也存在不少缺陷： pipelining只能适用于http1.1，一般来说，支持http1.1的server都要求支持pipelining。 只有幂等的请求（GET，HEAD）能使用pipelining，非幂等请求比如POST不能使用，因为请求之间可能会存在先后依赖关系。 head of line blocking并没有完全得到解决，server的response还是要求依次返回，遵循FIFO(first in first out)原则。也就是说如果请求1的response没有回来，2，3，4，5的response也不会被送回来。 绝大部分的http代理服务器不支持pipelining。 和不支持pipelining的老服务器协商有问题。 可能会导致新的Front of queue blocking问题。 正是因为有这么多的问题，各大浏览器厂商要么是根本就不支持pipelining，要么就是默认关掉了pipelining机制，而且启用的条件十分苛刻。可以参考chrome对于pipeling的问题描述。 1.5 其它奇技淫巧为了解决延迟带来的苦恼，永远都会有聪明的探索者找出新的捷径来。互联网的蓬勃兴盛催生出了各种新奇技巧，我们来依次看下这些“捷径”及各自的优缺点。 Spriting（图片合并）Spriting指的是将多个小图片合并到一张大的图片里，这样多个小的请求就被合并成了一个大的图片请求，然后再利用js或者css文件来取出其中的小张图片使用。好处显而易见，请求数减少，延迟自然低。坏处是文件的粒度变大了，有时候我们可能只需要其中一张小图，却不得不下载整张大图，cache处理也变得麻烦，在只有一张小图过期的情况下，为了获得最新的版本，不得不从服务器下载完整的大图，即使其它的小图都没有过期，显然浪费了流量。 Inlining（内容内嵌）Inlining的思考角度和spriting类似，是将额外的数据请求通过base64编码之后内嵌到一个总的文件当中。比如一个网页有一张背景图，我们可以通过如下代码嵌入： background: url(data:image/png;base64,) data部分是base64编码之后的字节码，这样也避免了一次多余的http请求。但这种做法也有着和spriting相同的问题，资源文件被绑定到了其它文件，粒度变得难以控制。 Concatenation（文件合并）Concatenation主要是针对js这类文件，现在前端开发交互越来越多，零散的js文件也在变多。将多个js文件合并到一个大的文件里在做一些压缩处理也可以减小延迟和传输的数据量。但同样也面临着粒度变大的问题，一个小的js代码改动会导致整个js文件被下载。 Domain Sharding（域名分片）前面我提到过很重要的一点，浏览器或者客户端是根据domain（域名）来建立连接的。比如针对www.example.com只允许同时建立2个连接，但mobile.example.com被认为是另一个域名，可以再建立两个新的连接。依次类推，如果我再多建立几个sub domain（子域名），那么同时可以建立的http请求就会更多，这就是Domain Sharding了。连接数变多之后，受限制的请求就不需要等待前面的请求完成才能发出了。这个技巧被大量的使用，一个颇具规模的网页请求数可以超过100，使用domain sharding之后同时建立的连接数可以多到50个甚至更多。 这么做当然增加了系统资源的消耗，但现在硬件资源升级非常之快，和用户宝贵的等待时机相比起来实在微不足道。 domain sharding还有一大好处，对于资源文件来说一般是不需要cookie的，将这些不同的静态资源文件分散在不同的域名服务器上，可以减小请求的size。 不过domain sharding只有在请求数非常之多的场景下才有明显的效果。而且请求数也不是越多越好，资源消耗是一方面，另一点是由于tcp的slow start会导致每个请求在初期都会经历slow start，还有tcp 三次握手，DNS查询的延迟。这一部分带来的时间损耗和请求排队同样重要，到底怎么去平衡这二者就需要取一个可靠的连接数中间值，这个值的最终确定要通过反复的测试。移动端浏览器场景建议不要使用domain sharding，具体细节参考这篇文章。 开拓者SPDYhttp1.0和1.1虽然存在这么多问题，业界也想出了各种优化的手段，但这些方法手段都是在尝试绕开协议本身的缺陷，都有种隔靴搔痒，治标不治本的感觉。直到2012年google如一声惊雷提出了SPDY的方案，大家才开始从正面看待和解决老版本http协议本身的问题，这也直接加速了http2.0的诞生。实际上，http2.0是以SPDY为原型进行讨论和标准化的。为了给http2.0让路，google已决定在2016年不再继续支持SPDY开发，但在http2.0出生之前，SPDY已经有了相当规模的应用，作为一个过渡方案恐怕在还将一段时间内继续存在。现在不少app客户端和server都已经使用了SPDY来提升体验，http2.0在老的设备和系统上还无法使用（iOS系统只有在iOS9+上才支持），所以可以预见未来几年spdy将和http2.0共同服务的情况。 SPDY的目标SPDY的目标在一开始就是瞄准http1.x的痛点，即延迟和安全性。我们上面通篇都在讨论延迟，至于安全性，由于http是明文协议，其安全性也一直被业界诟病，不过这是另一个大的话题。如果以降低延迟为目标，应用层的http和传输层的tcp都是都有调整的空间，不过tcp作为更底层协议存在已达数十年之久，其实现已深植全球的网络基础设施当中，如果要动必然伤经动骨，业界响应度必然不高，所以SPDY的手术刀对准的是http。 降低延迟，客户端的单连接单请求，server的FIFO响应队列都是延迟的大头。 http最初设计都是客户端发起请求，然后server响应，server无法主动push内容到客户端。 压缩http header，http1.x的header越来越膨胀，cookie和user agent很容易让header的size增至1kb大小，甚至更多。而且由于http的无状态特性，header必须每次request都重复携带，很浪费流量。 为了增加业界响应的可能性，聪明的google一开始就避开了从传输层动手，而且打算利用开源社区的力量以提高扩散的力度，对于协议使用者来说，也只需要在请求的header里设置user agent，然后在server端做好支持即可，极大的降低了部署的难度。SPDY的设计如下： [图6] SPDY位于HTTP之下，TCP和SSL之上，这样可以轻松兼容老版本的HTTP协议(将http1.x的内容封装成一种新的frame格式)，同时可以使用已有的SSL功能。SPDY的功能可以分为基础功能和高级功能两部分，基础功能默认启用，高级功能需要手动启用。 SPDY基础功能 多路复用（multiplexing）。多路复用通过多个请求stream共享一个tcp连接的方式，解决了http1.x holb（head of line blocking）的问题，降低了延迟同时提高了带宽的利用率。 请求优先级（request prioritization）。多路复用带来一个新的问题是，在连接共享的基础之上有可能会导致关键请求被阻塞。SPDY允许给每个request设置优先级，这样重要的请求就会优先得到响应。比如浏览器加载首页，首页的html内容应该优先展示，之后才是各种静态资源文件，脚本文件等加载，这样可以保证用户能第一时间看到网页内容。 header压缩。前面提到过几次http1.x的header很多时候都是重复多余的。选择合适的压缩算法可以减小包的大小和数量。SPDY对header的压缩率可以达到80%以上，低带宽环境下效果很大。 SPDY高级功能 server推送（server push）。http1.x只能由客户端发起请求，然后服务器被动的发送response。开启server push之后，server通过X-Associated-Content header（X-开头的header都属于非标准的，自定义header）告知客户端会有新的内容推送过来。在用户第一次打开网站首页的时候，server将资源主动推送过来可以极大的提升用户体验。 server暗示（server hint）。和server push不同的是，server hint并不会主动推送内容，只是告诉有新的内容产生，内容的下载还是需要客户端主动发起请求。server hint通过X-Subresources header来通知，一般应用场景是客户端需要先查询server状态，然后再下载资源，可以节约一次查询请求。 SPDY的成绩SPDY的成绩可以用google官方的一个数字来说明：页面加载时间相比于http1.x减少了64%。而且各大浏览器厂商在SPDY诞生之后的1年多里都陆续支持了SPDY，不少大厂app和server端框架也都将SPDY应用到了线上的产品当中。 google的官网也给出了他们自己做的一份测试数据。测试对象是25个访问量排名靠前的网站首页，家用网络%1的丢包率，每个网站测试10次取平均值。结果如下： [图7] 不开启ssl的时候提升在 27% - 60%，开启之后为39% - 55%。 这份测试结果有两点值得特别注意： 连接数的选择连接到底是基于域名来建立，还是不做区分所有子域名都共享一个连接，这个策略选择上值得商榷。google的测试结果测试了两种方案，看结果似乎是单一连接性能高于多域名连接方式。之所以出现这种情况是由于网页所有的资源请求并不是同一时间发出，后续发出的子域名请求如果能复用之前的tcp连接当然性能更好。实际应用场景下应该也是单连接共享模式表现好。 带宽的影响测试基于两种带宽环境，一慢一快。网速快的环境下对减小延迟的提升更大，单连接模式下可以提升至60%。原因也比较简单，带宽越大，复用连接的请求完成越快，由于三次握手和慢启动导致的延迟损耗就变得更明显。 出了连接模式和带宽之外，丢包率和RTT也是需要测试的参数。SPDY对header的压缩有80%以上，整体包大小能减少大概40%，发送的包越少，自然受丢包率影响也就越小，所以丢包率大的恶劣环境下SPDY反而更能提升体验。下图是受丢包率影响的测试结果，丢包率超过2.5％之后就没有提升了： [图8] RTT越大，延迟会越大，在高RTT的场景下，由于SPDY的request是并发进行的，所有对包的利用率更高，反而能更明显的减小总体延迟。测试结果如下： [图9] SPDY从2012年诞生到2016停止维护，时间跨度对于网络协议来说其实非常之短。如果HTTP2.0没有出来，google或许能收集到更多业界产品的真实反馈和数据，毕竟google自己的测试环境相对简单。但SPDY也完成了自己的使命，作为一贯扮演拓荒者角色的google应该也早就预见了这样的结局。SPDY对产品网络体验的提升到底如何，恐怕只有各大厂产品经理才清楚了。 救世主HTTP2.0SPDY的诞生和表现说明了两件事情：一是在现有互联网设施基础和http协议广泛使用的前提下，是可以通过修改协议层来优化http1.x的。二是针对http1.x的修改确实效果明显而且业界反馈很好。正是这两点让IETF（Internet Enginerring Task Force）开始正式考虑制定HTTP2.0的计划，最后决定以SPDY／3为蓝图起草HTTP2.0，SPDY的部分设计人员也被邀请参与了HTTP2.0的设计。 HTTP2.0需要考虑的问题HTTP2.0与SPDY的起点不同，SPDY可以说是google的“玩具”，最早出现在自家的chrome浏览器和server上，好不好玩以及别人会不会跟着一起玩对google来说无关痛痒。但HTTP2.0作为业界标准还没出生就是众人瞩目的焦点，一开始如果有什么瑕疵或者不兼容的问题影响可能又是数十年之久，所以考虑的问题和角度要非常之广。我们来看下HTTP2.0一些重要的设计前提： 客户端向server发送request这种基本模型不会变。 老的scheme不会变，使用http://和https://的服务和应用不会要做任何更改，不会有http2://。 使用http1.x的客户端和服务器可以无缝的通过代理方式转接到http2.0上。 不识别http2.0的代理服务器可以将请求降级到http1.x。 因为客户端和server之间在确立使用http1.x还是http2.0之前，必须要要确认对方是否支持http2.0，所以这里必须要有个协商的过程。最简单的协商也要有一问一答，客户端问server答，即使这种最简单的方式也多了一个RTT的延迟，我们之所以要修改http1.x就是为了降低延迟，显然这个RTT我们是无法接受的。google制定SPDY的时候也遇到了这个问题，他们的办法是强制SPDY走https，在SSL层完成这个协商过程。ssl层的协商在http协议通信之前，所以是最适合的载体。google为此做了一个tls的拓展，叫NPN（Next Protocol Negotiation），从名字上也可以看出，这个拓展主要目的就是为了协商下一个要使用的协议。HTTP2.0虽然也采用了相同的方式，不过HTTP2.0经过激烈的讨论，最终还是没有强制HTTP2.0要走ssl层，大部分浏览器厂商（除了IE）却只实现了基于https的2.0协议。HTTP2.0没有使用NPN，而是另一个tls的拓展叫ALPN（Application Layer Protocol Negotiation）。SPDY也打算从NPN迁移到ALPN了。 各浏览器（除了IE）之所以只实现了基于SSL的HTTP2.0，另一个原因是走SSL请求的成功率会更高，被SSL封装的request不会被监听和修改，这样网络中间的网络设备就无法基于http1.x的认知去干涉修改request，http2.0的request如果被意外的修改，请求的成功率自然会下降。 HTTP2.0协议没有强制使用SSL是因为听到了很多的反对声音，毕竟https和http相比，在不优化的前提下性能差了不少，要把https优化到几乎不增加延迟的程度又需要花费不少力气。IETF面对这种两难的处境做了妥协，但大部分浏览器厂商（除了IE）并不买帐，他们只认https2.0。对于app开发者来说，他们可以坚持使用没有ssl的http2.0，不过要承担一个多余的RTT延迟和请求可能被破坏的代价。 3.1 HTTP2.0主要改动HTTP2.0作为新版协议，改动细节必然很多，不过对应用开发者和服务提供商来说，影响较大的就几点。 新的二进制格式（Binary Format）http1.x诞生的时候是明文协议，其格式由三部分组成：start line（request line或者status line），header，body。要识别这3部分就要做协议解析，http1.x的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑http2.0的协议解析决定采用二进制格式，实现方便且健壮。 有人可能会觉得基于文本的http调试方便很多，像firebug，chrome，charles等不少工具都可以即时调试修改请求。实际上现在很多请求都是走https了，要调试https请求必须有私钥才行。http2.0的绝大部分request应该都是走https，所以调试方便无法作为一个有力的考虑因素了。curl，tcpdump，wireshark这些工具会更适合http2.0的调试。 http2.0用binary格式定义了一个一个的frame，和http1.x的格式对比如下图： [图10] http2.0的格式定义更接近tcp层的方式，这张二机制的方式十分高效且精简。length定义了整个frame的开始到结束，type定义frame的类型（一共10种），flags用bit位定义一些重要的参数，stream id用作流控制，剩下的payload就是request的正文了。 虽然看上去协议的格式和http1.x完全不同了，实际上http2.0并没有改变http1.x的语义，只是把原来http1.x的header和body部分用frame重新封装了一层而已。调试的时候浏览器甚至会把http2.0的frame自动还原成http1.x的格式。具体的协议关系可以用下图表示： [图11] 连接共享http2.0要解决的一大难题就是多路复用（MultiPlexing），即连接共享。上面协议解析中提到的stream id就是用作连接共享机制的。一个request对应一个stream并分配一个id，这样一个连接上可以有多个stream，每个stream的frame可以随机的混杂在一起，接收方可以根据stream id将frame再归属到各自不同的request里面。 前面还提到过连接共享之后，需要优先级和请求依赖的机制配合才能解决关键请求被阻塞的问题。http2.0里的每个stream都可以设置又优先级（Priority）和依赖（Dependency）。优先级高的stream会被server优先处理和返回给客户端，stream还可以依赖其它的sub streams。优先级和依赖都是可以动态调整的。动态调整在有些场景下很有用，假想用户在用你的app浏览商品的时候，快速的滑动到了商品列表的底部，但前面的请求先发出，如果不把后面的请求优先级设高，用户当前浏览的图片要到最后才能下载完成，显然体验没有设置优先级好。同理依赖在有些场景下也有妙用。 header压缩前面提到过http1.x的header由于cookie和user agent很容易膨胀，而且每次都要重复发送。http2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。高效的压缩算法可以很大的压缩header，减少发送包的数量从而降低延迟。 这里普及一个小知识点。现在大家都知道tcp有slow start的特性，三次握手之后开始发送tcp segment，第一次能发送的没有被ack的segment数量是由initial tcp window大小决定的。这个initial tcp window根据平台的实现会有差异，但一般是2个segment或者是4k的大小（一个segment大概是1500个字节），也就是说当你发送的包大小超过这个值的时候，要等前面的包被ack之后才能发送后续的包，显然这种情况下延迟更高。intial window也并不是越大越好，太大会导致网络节点的阻塞，丢包率就会增加，具体细节可以参考IETF这篇文章。http的header现在膨胀到有可能会超过这个intial window的值了，所以更显得压缩header的重要性。 压缩算法的选择SPDY/2使用的是gzip压缩算法，但后来出现的两种攻击方式BREACH和CRIME使得即使走ssl的SPDY也可以被破解内容，最后综合考虑采用的是一种叫HPACK的压缩算法。这两个漏洞和相关算法可以点击链接查看更多的细节，不过这种漏洞主要存在于浏览器端，因为需要通过javascript来注入内容并观察payload的变化。 重置连接表现更好很多app客户端都有取消图片下载的功能场景，对于http1.x来说，是通过设置tcp segment里的reset flag来通知对端关闭连接的。这种方式会直接断开连接，下次再发请求就必须重新建立连接。http2.0引入RST_STREAM类型的frame，可以在不断开连接的前提下取消某个request的stream，表现更好。 Server PushServer Push的功能前面已经提到过，http2.0能通过push的方式将客户端需要的内容预先推送过去，所以也叫“cache push”。另外有一点值得注意的是，客户端如果退出某个业务场景，出于流量或者其它因素需要取消server push，也可以通过发送RST_STREAM类型的frame来做到。 流量控制（Flow Control）TCP协议通过sliding window的算法来做流量控制。发送方有个sending window，接收方有receive window。http2.0的flow control是类似receive window的做法，数据的接收方通过告知对方自己的flow window大小表明自己还能接收多少数据。只有Data类型的frame才有flow control的功能。对于flow control，如果接收方在flow window为零的情况下依然更多的frame，则会返回block类型的frame，这张场景一般表明http2.0的部署出了问题。 Nagle Algorithm vs TCP Delayed Acktcp协议优化的一个经典场景是：Nagle算法和Berkeley的delayed ack算法的对立。http2.0并没有对tcp层做任何修改，所以这种对立导致的高延迟问题依然存在。要么通过TCP_NODELAY禁用Nagle算法，要么通过TCP_QUICKACK禁用delayed ack算法。貌似http2.0官方建议是设置TCP_NODELAY。 更安全的SSLHTTP2.0使用了tls的拓展ALPN来做协议升级，除此之外加密这块还有一个改动，HTTP2.0对tls的安全性做了近一步加强，通过黑名单机制禁用了几百种不再安全的加密算法，一些加密算法可能还在被继续使用。如果在ssl协商过程当中，客户端和server的cipher suite没有交集，直接就会导致协商失败，从而请求失败。在server端部署http2.0的时候要特别注意这一点。 HTTP2.0里的负能量SPDY和HTTP2.0之间的暧昧关系，以及google作为SPDY的创造者，这两点很容易让阴谋论者怀疑google是否会成为协议的最终收益方。这其实是废话，google当然会受益，任何新协议使用者都会从中受益，至于谁吃肉，谁喝汤看的是自己的本事。从整个协议的变迁史也可以粗略看出，新协议的诞生完全是针对业界现存问题对症下药，并没有google业务相关的痕迹存在，google至始至终只扮演了一个角色：you can you up。 HTTP2.0不会是万金油，但抹了也不会有副作用。HTTP2.0最大的亮点在于多路复用，而多路复用的好处只有在http请求量大的场景下才明显，所以有人会觉得只适用于浏览器浏览大型站点的时候。这么说其实没错，但http2.0的好处不仅仅是multiplexing，请求压缩，优先级控制，server push等等都是亮点。对于内容型移动端app来说，比如淘宝app，http请求量大，多路复用还是能产生明显的体验提升。多路复用对延迟的改变可以参考下这个测试网址。 HTTP2.0对于ssl的依赖使得有些开发者望而生畏。不少开发者对ssl还停留在高延迟，CPU性能损耗，配置麻烦的印象中。其实ssl于http结合对性能的影响已经可以优化到忽略的程度了，网上也有不少文章可以参考。HTTP2.0也可以不走ssl，有些场景确实可能不适合https，比如对代理服务器的cache依赖，对于内容安全性不敏感的get请求可以通过代理服务器缓存来优化体验。 HTTP2.0的现状HTTP2.0作为新版本的网络协议肯定需要一段时间去普及，但HTTP本身属于应用层协议，和当年的网络层协议IPV6不同，离底层协议越远，对网络基础硬件设施的影响就越小。HTTP2.0甚至还特意的考虑了与HTTP1.x的兼容问题，只是在HTTP1.x的下面做了一层framing layer，更使得其普及的阻力变小。所以不出意外，HTTP2.0的普及速度可能会远超大部分人的预期。 Firefox 2015年在其浏览器流量中检测到，有13%的http流量已经使用了http2.0，27%的https也是http2.0，而且还处于持续的增长当中。一般用户察觉不到是否使用了http2.0，不过可以装这样一个插件，安装之后如果网站是http2.0的，在地址栏的最右边会有个闪电图标。还可以使用这个网站来测试。对于开发者来说，可以通过Web Developer的Network来查看协议细节，如下图： [图12] 其中Version：HTTP／2.0已经很明确表明协议类型，Firefox还在header里面插入了X-Firefox-Spdy:“h2”，也可以看出是否使用http2.0。 Chrome在2015年检测到的http2.0流量大概有18%。不过这个数字本来会更高，因为Chrome现在很大一部分流量都在试验QUIC（google正在开辟的另一块疆土）。Chrome上也可以使用类似的插件来判断网站是否是使用http2.0。 移动端HTTP现状iOS下http现状iOS系统是从iOS8开始才通过NSURLSession来支持SPDY的，iOS9+开始自动支持http2.0。实际上apple对http2.0非常有信心，推广力度也很大。新版本ATS机制默认使用https来进行网络传输。APN（Apple Push Notifiction）在iOS9上也已经是通过http2.0来实现的了。iOS9 sdk里的NSURLSession默认使用http2.0，而且对开发者来说是完全透明的，甚至没有api来知道到底是用的哪个版本的http协议。 对于开发者来说到底怎么去配置最佳的http使用方案呢？在我看来，因app而异，主要从两方面来考虑：一是app本身http流量是否大而且密集，二是开发团队本身的技术条件。http2.0的部署相对容易很多，客户端开发者甚至不用做什么改动，只需要使用iOS9的SDK编译即可，但缺点是http2.0只能适用于iOS9的设备。SPDY的部署相对麻烦一些，但优点是可以兼顾iOS6+的设备。iOS端的SPDY可以使用twitter开发的CocoaSPDY方案，但有一点需要特别处理： 由于苹果的TLS实现不支持NPN，所以通过NPN协商使用SPDY就无法通过默认443端口来实现。有两种做法，一是客户端和server同时约定好使用另一个端口号来做NPN协商，二是server这边通过request header智能判断客户端是否支持SPDY而越过NPN协商过程。第一种方法会简单一点，不过需要从框架层将所有的http请求都map到另一个port，url mapping可以参考我之前的一篇文章。twitter自己的网站twitter.com使用的是第二种方法。 浏览器端（比如Chrome），server端（比如nginx）都陆续打算放弃支持spdy了，毕竟google官方都宣布要停止维护了。spdy会是一个过渡方案，会随着iOS9的普及会逐步消失，所以这部分的技术投入需要开发团队自己去衡量。 Android下http现状android和iOS情况类似，http2.0只能在新系统下支持，spdy作为过渡方案仍然有存在的必要。 对于使用webview的app来说，需要基于chrome内核的webview才能支持spdy和http2.0，而android系统的webview是从android4.4（KitKat）才改成基于chrome内核的。 对于使用native api调用的http请求来说，okhttp是同时支持spdy和http2.0的可行方案。如果使用ALPN，okhttp要求android系统5.0+(实际上，android4.4上就有了ALPN的实现，不过有bug，知道5.0才正式修复)，如果使用NPN，可以从android4.0+开始支持，不过NPN也是属于将要被淘汰的协议。 结束语以上是HTTP从1.x到SPDY，再到HTTP2.0的一些主要变迁技术点。HTTP2.0正处于逐步应用到线上产品和服务的阶段，可以预见未来会有不少新的坑产生和与之对应的优化技巧，HTTP1.x和SPDY也将在一段时间内继续发挥余热。作为工程师，需要了解这些协议背后的技术细节，才能打造高性能的网络框架，从而提升我们的产品体验。 来源：&nbsp;http://music4kid.github.io/blog/http2/?hmsr=toutiao.io]]></content>
      <tags>
        <tag>http</tag>
        <tag>http 2.0</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[servlet基础]]></title>
    <url>%2F2018%2F02%2F28%2Fservlet%2F</url>
    <content type="text"><![CDATA[Servlet没有main方法，它们受控于容器；服务器不是将请求交给servlet本身，而是交给部署该servlet的容器，由容器向servlet提供HTTP请求和响应，由容器调用servlet的方法，如doPost()何doGet()。 servlet交互流程 用户点击一个链接，请求指向一个servlet（ HttpServlet ）； 容器创建 HttpServletRequest和HttpServletResponse; 容器根据请求中的url，找到正确的servlet，为这个请求创建或分配一个线程。并将HttpServletRequest和HttpServletResponse对象传递给这个线程； 容易调用servlet的service()方法，根据请求的不同类型。service()方法调用doGet()、doPost()或其他方法； doGet()方法生成动态页面，并把这个页面“填入”响应对象（容器还有响应对象的一个引用）。 线程结束，容器把响应对象转换为一个HTTP响应，返回客户。删除请求和响应对象 web.xml容器读取web.xml（部署描述文件DD，位于WEB-INF文件夹中）中的servlet 123456789101112web.xml&lt;web-app...&gt; &lt;servlet&gt; &lt;servlet-name&gt;demo class name&lt;/servlet-name&gt; &lt;servlet-class&gt;demoClass&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;demo class name&lt;/servlet-name&gt; &lt;url-pattern&gt;/matchUrl&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; servlet线程安全容器运行多个线程，处理对一个servlet的多个请求对应每个请求会生成一对请求和响应对象 servlet生命周期 构造函数init() 运行中service() 销毁destory() servlet 初始化参数servlet初始化参数只能读一次容器建立servlet时，会读DD（web.xml），并为ServletConfig创建名/值对。此后容器不会再读初始化参数！一旦参数置于ServletConfig中，就不会再读了，除非重新部署Servlet。 初始化参数位于ServletConfig中 -&gt; 构造javax.servlet.HttpServlet通过调用init(servletConfig)方法，其中参数为javax.servlet.ServletConfig DD文件（web.xml）中，&lt;web-app&gt; - &lt;servlet&gt; - &lt;init-param&gt;，配置初始化参数 ： 123456789&lt;servlet&gt; &lt;servlet-name&gt;···&lt;servlet-name&gt; &lt;servlet-class&gt;···&lt;/servlet-name&gt; &lt;init-param&gt; &lt;param-name&gt;propertyName&lt;/param-name&gt; &lt;param-value&gt;propertyValue&lt;/param-value&gt; &lt;/init-param&gt;&lt;/servlet&gt; servlet代码中获取方式 extends HttpServlet1getServletConfig().getInitParameter(&quot;propertyName&quot;); servlet 初始化顺序 如果希望在部署（或服务器重启时）加载servlet，而不是等到第一个请求到来时才加载，可以在DD中使用&lt;load-on-startup&gt;元素。 通过将&lt;load-on-startup&gt;的值设置为非负（ ≥ 0 ） servlet默认加载顺序为DD文件（web.xml）中的配置熟悉怒 数值越大，加载时序越低（如果一个servlet的加载顺序设置为4，表示这个servlet应当在值小于4的其他servlet加载后再加载） 12345&lt;servlet&gt; ... ... &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt; servlet 上下文初始化参数 如果必须同步修改ServletContext中属性，可以通过对ServletContext加锁：synchronized(getServletContext()) { ... } context-param是针对整个应用的，所以不前套在servlet中 DD文件（web.xml）中，&lt;web-app&gt; - &lt;context-param&gt;，配置初始化参数 ：1234&lt;context-param&gt; &lt;param-name&gt;contextProperty&lt;/param-name&gt; &lt;param-value&gt;contextPropertyValue&lt;/param-value&gt;&lt;/context-param&gt; servlet代码中的获取方式 extends HttpServlet1getServletContext().getInitParameter(&quot;contextProperty&quot;); ServletConfig vs ServletCotext ServletConfig：servlet的一些配置属性，如servlet的初始化参数；用于访问ServletContext；HttpServlet的子类可以通过getServletConfig获取ServletConfig ServletContext：更适合叫做AppContext，每个web应用只有一个ServletContext，用于访问web应用参数 每个Servlet有一个对应的ServletConfig；每个应用有一个ServletContext 监听ServletContext的创建和销毁 - ServletContextListener（上下文作用域不是线程安全的）ServletContextListener.contextInitialized(ServletContextEvent)ServletContextListener.contextDestroyed(ServletContextEvent) 实现ServletContextListener接口1public class MyServletContextListener implements ServletContextListener &#123; ... &#125; xml配置方式123&lt;listener&gt; &lt;listener-class&gt;com.example.MyServletContextListener&lt;/listener-class&gt;&lt;/listener&gt; servlet 8个监听器 场景 listener 事件类型 希望知道一个Web应用上下文中是否增加、删除或替换一个属性 ServletContextAttributeListener ServletContextAttributeEvent 了解有多少并发用户 HttpSessionListener HttpSessionEvent 了解请求到达，比如需要建立记录日志 ServletRequestListener ServletRequestEvent 希望了解增加、删除或替换一个请求属性 ServletRequestAttributeListener ServletRequestAttributeEvent 有一个属性类（这个类表示的对象将放在一个属性中），希望这个类型的对象在绑定到一个会话或从会话删除时得到通知 HttpSessionBindingListener HttpSessionBindingEvent 希望了解增加、删除或替换一个会话属性 HttpSessionAttributeListener HttpSessionBindingEvent 了解是否创建或撤销一个上下文 ServletContextListener ServletContextEvent 有一个属性类，并希望这个类型的对象在其绑定的会话迁移到另一个JVM时，得到通知 HttpSessionActivationListener HttpSessionEvent 不是HttpSessionActivationEvent HttpSessionAttributeListener vs HttpSessionBindingListener HttpSessionAttributeListener：希望绘画中在增加、删除或替换某种类型的属性时能够知晓； HttpSessionBindingListener：有了HttpSessionBindingListener，属性本身才能够在增加到一个会话或者从会话删除时得到通知； HttpSessionBindingListener.valueBound(HttpSessionBindingEvent) HttpSessionBindingListener.valueUnbound(HttpSessionBindingEvent) 一些概念 上下文：ServletContext 请求：ServletRequest 会话：HttpSession RequestDispatcher让组件的其他部分接管这个请求；通过ServletContext获取RequestDispatcher RequestDispatcher.forward()RequestDispatcher.include() servlet重定向sendRedirect 拦截器 filter javax.servlet.Filter允许拦截请求，并且servlet对此一无所知；发生在调用servlet的service方法之前； 容器知道过滤器API：javax.servlet.Filter 容器管理过滤器的生命周期 都在DD中声明 拦截器Filter生命周期拥有类似于servlet的init()和destory()方法，init的传入参数为FilterConfig，对应于servlet的doGet()和doPost()，过滤器有doFilter()方法 init(FilterConfig)：初始化Filter doFilter()完成所有工作，参数为： 1) ServletRequest，而非HttpServletRequest 2) ServletResponse，而非HttpServletResponse 3) 一个FilterChain destory() 完成Filter的销毁 Filter声明方式声明Filter12345678&lt;filter&gt; &lt;filter-name&gt;filterName&lt;/filter-name&gt; &lt;filter-class&gt;filterClass&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;filterInitParamName&lt;/param-name&gt; &lt;param-value&gt;filterInitParamValue&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt; filter-mapping&lt;url-pattern&gt;或&lt;servlet-name&gt;元素必须二选一 声明对应URL模式的过滤器映射1234&lt;filter-mapping&gt; &lt;filter-name&gt;filterName&lt;/filter-name&gt; &lt;url-pattern&gt;*.filterUrlPattern&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 声明对应Servlet名的过滤器映射1234&lt;filter-mapping&gt; &lt;filter-name&gt;filterName&lt;/filter-name&gt; &lt;servlet-name&gt;servletName&lt;/servlet-name&gt;&lt;/filter-mapping&gt; Servlet 包装器 - *Wrapper一个使用场景需要对所有返回值response进行压缩； 当我们有操作request或response的需求时，可以增加一个Filter，并在执行过程中，将request或response替换为包装类（Wrapper），实现功能的修改 [容器] -&gt; doFilter(req, resp) -&gt; [Filter.filter()] -&gt; chain.doFilter(req, respWrapper) -&gt; [Servlet] 包装类的优势自定义ServletRequest, ServletResponse需要实现过多细节，而预定义的Wrapper刚好解决了这个问题，我们只需要覆写所需的方法； servlet预提供的wrapper ServletRequestWrapper HttpServletRequestWrapper ServletResponseWrapper HttpServletResponseWrapper 压缩返回值的🌰12345678910111213141516171819202122232425class CompressionResponseWrapper extends HttpServletResponseWrapper &#123; // 覆盖想定制的方法，对返回流进行压缩 public ServletOutputStream getOutputStream() throws ... &#123; ... return new GzipSos(resp.getOutputStream()); &#125;&#125;class MyCompressionFilter implements Filter &#123; public void init(FilterConfig cfg) &#123; ... &#125; public void doFilter( request, response, chain) &#123; // 这里用定义的包装器类‘包装’响应response CompressionResponseWrapper wrappedResp = new CompressionResponseWrapper(response); chain.doFilter(request, wrappedResp); // 完成压缩逻辑 &#125; public void destroy() &#123; ... &#125;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[(翻译) Dapper分布式跟踪系统]]></title>
    <url>%2F2018%2F02%2F27%2FTranslation-Articles-Dapper-a-Large-Scale-Distributed-Systems-Tracing-Infrastructure%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[词法]]></title>
    <url>%2F2018%2F02%2F27%2Fphrase%2F</url>
    <content type="text"><![CDATA[APM: 应用性能管理]]></content>
      <tags>
        <tag>phrase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[trace of distributed services]]></title>
    <url>%2F2018%2F02%2F27%2Ftrace-of-distributed-services%2F</url>
    <content type="text"><![CDATA[Google Dapper 翻译 # 现代互联网服务：复杂的大规模分布式系统 Requst Tracing 中的三个基本诉求 低损耗 应用透明的 大范围部署 ubiquitous deployment(无所不在的部署), and continuous monitoring(持续的监控). Key Word 采样率 trace context span Point安全性由于安全和隐私问题是不可忽略的，dapper中的虽然存储RPC方法的名称，但在这个时候不记录任何有效载荷数据。相反，应用程序级别的Annotation提供了一个方便的可选机制：应用程序开发人员可以在span中选择关联那些为以后分析提供价值的数据。 Dapper还提供了一些安全上的便利，是它的设计者事先没有预料到的。通过跟踪公开的安全协议参数，Dapper可以通过相应级别的认证或加密，来监视应用程序是否满足安全策略。例如。Dapper还可以提供信息，以基于策略的的隔离系统按预期执行，例如支撑敏感数据的应用程序不与未经授权的系统组件进行了交互。这样的测算提供了比源码审核更强大的保障。 Dapper代码Dapper代码中中最关键的部分，就是对基础RPC、线程控制和流程控制的组件库的植入，其中包括span的创建，采样率的设置，以及把日志写入本地磁盘 Dapper损耗 4.1 生成跟踪的损耗生成跟踪的开销是Dapper性能影响中最关键的部分，因为收集和分析可以更容易在紧急情况下被关闭。Dapper运行库中最重要的跟踪生成消耗在于创建和销毁span和annotation，并记录到本地磁盘供后续的收集。根span的创建和销毁需要损耗平均204纳秒的时间，而同样的操作在其他span上需要消耗176纳秒。时间上的差别主要在于需要在跟span上给这次跟踪分配一个全局唯一的ID。如果一个span没有被采样的话，那么这个额外的span下创建annotation的成本几乎可以忽略不计，他由在Dapper运行期对ThreadLocal查找操作构成，这平均只消耗9纳秒。如果这个span被计入采样的话，会用一个用字符串进行标注–在图4中有展现–平均需要消耗40纳秒。这些数据都是在2.2GHz的x86服务器上采集的。 在Dapper运行期写入到本地磁盘是最昂贵的操作，但是他们的可见损耗大大减少，因为写入日志文件和操作相对于被跟踪的应用系统来说都是异步的。不过，日志写入的操作如果在大流量的情况，尤其是每一个请求都被跟踪的情况下就会变得可以察觉到。我们记录了在4.3节展示了一次Web搜索的负载下的性能消耗。 4.2 跟踪收集的消耗 读出跟踪数据也会对正在被监控的负载产生干扰。表1展示的是最坏情况下，Dapper收集日志的守护进程在高于实际情况的负载基准下进行测试时的cpu使用率。在生产环境下，跟踪数据处理中，这个守护进程从来没有超过0.3%的单核cpu使用率，而且只有很少量的内存使用（以及堆碎片的噪音）。我们还限制了Dapper守护进程为内核scheduler最低的优先级，以防在一台高负载的服务器上发生cpu竞争。 Dapper也是一个带宽资源的轻量级的消费者，每一个span在我们的仓库中传输只占用了平均426的byte。作为网络行为中的极小部分，Dapper的数据收集在Google的生产环境中的只占用了0.01%的网络资源。 4.3 在生产环境下对负载的影响 每个请求都会利用到大量的服务器的高吞吐量的线上服务，这是对有效跟踪最主要的需求之一；这种情况需要生成大量的跟踪数据，并且他们对性能的影响是最敏感的。在表2中我们用集群下的网络搜索服务作为例子，我们通过调整采样率，来衡量Dapper在延迟和吞吐量方面对性能的影响。 我们看到，虽然对吞吐量的影响不是很明显，但为了避免明显的延迟，跟踪的采样还是必要的。然而，延迟和吞吐量的带来的损失在把采样率调整到小于1/16之后就全部在实验误差范围内。在实践中，我们发现即便采样率调整到1/1024仍然是有足够量的跟踪数据的用来跟踪大量的服务。保持Dapper的性能损耗基线在一个非常低的水平是很重要的，因为它为那些应用提供了一个宽松的环境使用完整的Annotation API而无惧性能损失。使用较低的采样率还有额外的好处，可以让持久化到硬盘中的跟踪数据在垃圾回收机制处理之前保留更长的时间，这样为Dapper的收集组件给了更多的灵活性。 4.4 可变采样(根据流量自动调节采样率) 任何给定进程的Dapper的消耗和每个进程单位时间的跟踪的采样率成正比。Dapper的第一个生产版本在Google内部的所有进程上使用统一的采样率，为1/1024。这个简单的方案是对我们的高吞吐量的线上服务来说是非常有用，因为那些感兴趣的事件(在大吞吐量的情况下)仍然很有可能经常出现，并且通常足以被捕捉到。 然而，在较低的采样率和较低的传输负载下可能会导致错过重要事件，而想用较高的采样率就需要能接受的性能损耗。对于这样的系统的解决方案就是覆盖默认的采样率，这需要手动干预的，这种情况是我们试图避免在dapper中出现的。 我们在部署可变采样的过程中，参数化配置采样率时，不是使用一个统一的采样方案，而是使用一个采样期望率来标识单位时间内采样的追踪。这样一来，低流量低负载自动提高采样率，而在高流量高负载的情况下会降低采样率，使损耗一直保持在控制之下。实际使用的采样率会随着跟踪本身记录下来，这有利于从Dapper的跟踪数据中准确的分析。 4.5 应对积极采样(Coping with aggressive sampling) 新的Dapper用户往往觉得低采样率–在高吞吐量的服务下经常低至0.01％–将会不利于他们的分析。我们在Google的经验使我们相信，对于高吞吐量服务，积极采样(aggressive sampling)并不妨碍最重要的分析。如果一个显着的操作在系统中出现一次，他就会出现上千次。低吞吐量的服务–也许是每秒请求几十次，而不是几十万–可以负担得起跟踪每一个请求，这是促使我们下决心使用自适应采样率的原因。 4.6 在收集过程中额外的采样 上述采样机制被设计为尽量减少与Dapper运行库协作的应用程序中明显的性能损耗。Dapper的团队还需要控制写入中央资料库的数据的总规模，因此为达到这个目的，我们结合了二级采样。 目前我们的生产集群每天产生超过1TB的采样跟踪数据。Dapper的用户希望生产环境下的进程的跟踪数据从被记录之后能保存至少两周的时间。逐渐增长的追踪数据的密度必须和Dapper中央仓库所消耗的服务器及硬盘存储进行权衡。对请求的高采样率还使得Dapper收集器接近写入吞吐量的上限。 为了维持物质资源的需求和渐增的Bigtable的吞吐之间的灵活性，我们在收集系统自身上增加了额外的采样率的支持。我们充分利用所有span都来自一个特定的跟踪并分享同一个跟踪ID这个事实，虽然这些span有可能横跨了数千个主机。对于在收集系统中的每一个span，我们用hash算法把跟踪ID转成一个标量Z，这里0&lt;=Z&lt;=1。如果Z比我们收集系统中的系数低的话，我们就保留这个span信息，并写入到Bigtable中。反之，我们就抛弃他。通过在采样决策中的跟踪ID，我们要么保存、要么抛弃整个跟踪，而不是单独处理跟踪内的span。我们发现，有了这个额外的配置参数使管理我们的收集管道变得简单多了，因为我们可以很容易地在配置文件中调整我们的全局写入率这个参数。 如果整个跟踪过程和收集系统只使用一个采样率参数确实会简单一些，但是这就不能应对快速调整在所有部署的节点上的运行期采样率配置的这个要求。我们选择了运行期采样率，这样就可以优雅的去掉我们无法写入到仓库中的多余数据，我们还可以通过调节收集系统中的二级采样率系数来调整这个运行期采样率。Dapper的管道维护变得更容易，因为我们就可以通过修改我们的二级采样率的配置，直接增加或减少我们的全局覆盖率和写入速度。 引文1当然Dapper设计之初，参考了一些其他分布式系统的理念，尤其是Magpie和X-Trace，但是我们之所以能成功应用在生产环境上，还需要一些画龙点睛之笔，例如采样率的使用以及把代码植入限制在一小部分公共库的改造上。 123The basic idea behind request tracing is relatively straightforward: specific inflexion points must be identified within a system, application, network, and middleware -- or indeed any point on a path of a (typically user-initiated) request -- and instrumented. These points are of particular interest as they typically represent forks in execution flow, such as the parallelization of processing using multiple threads, a computation being made asynchronously, or an out-of-process network call being made. All of the independently generated trace data must be collected, coordinated and collated to provide a meaningful view of a request’s flow through the system. google: dapper(Stubby) twitter: zipkin(Finagle) OpenTracing]]></content>
  </entry>
  <entry>
    <title><![CDATA[CentOS命令行下安装VMware tools]]></title>
    <url>%2F2018%2F02%2F25%2Fvmware-tools%2F</url>
    <content type="text"><![CDATA[依赖 perl gcc kernel net-tools(需要其中的ifconfig) 命令行安装VMware tools 虚拟光驱 12mkdir /mnt/cdrommount -t iso9660 /dev/cdrom /mnt/cdrom 拷贝VMWarexxx.tar.gz到/tmp： 1cp /mnt/cdrom/VMWarexxx.tar.gz /tmp 解压 12cd /tmptar zxf VMWarexxx.tar.gz 安装执行 12cd vmware-tools-disxx./vmware-install.pl]]></content>
      <tags>
        <tag>VMware Funsion</tag>
        <tag>VMware tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shallow and retained sizes]]></title>
    <url>%2F2018%2F02%2F18%2Fjava-heap%2F</url>
    <content type="text"><![CDATA[NotionShallow sizeShallow size of an object is the amount of memory allocated to store the object itself, not taking into account the referenced objects (指自身，不含引用). Shallow size of a regular (non-array) object depends on the number and types of its fields(非数组时，依赖自身field的数量和类型). Shallow size of an array depends on the array length and the type of its elements (objects, primitive types)(数组时，数组长度及每个element的类型). Shallow size of a set of objects represents the sum of shallow sizes of all objects in the set. Retained sizeRetained size of an object is its shallow size plus the shallow sizes of the objects that are accessible, (自身的shallow size及直接或间接引用对象(仅从此对象)的shallow size) directly or indirectly, only from this object. In other words, the retained size represents the amount of memory that will be freed by the garbage collector when this object is collected(Retained size指，释放该对象时，能够释放的所有内存；如果A引用S、C也引用S，则释放A时，不会释放S，因此，S不被计算进A的Retained Size). I.E.To better understand the notion of the retained size, let us look at the following examples: In order to measure the retained sizes, all objects in memory are treated as nodes of a graph where its edges represent references from objects to objects.There are also special nodes - GC root objects, which will not be collected by Garbage Collector at the time of measuring (read more about GC roots). The pictures below show the same set of objects, but with varying internal references. figure 1 figure 2 Let us consider obj1.As you can see, in both pictures we have highlighted all of the objects that are directly or indirectly accessed only by obj1.If you look at Figure 1, you will see that obj3 is not highlighted,because it is also referenced by a GC root object. On Figure 2, however, it is already included intothe retained set, unlike obj5, which is still referenced by GC root. Thus, the retained size of obj1 will represent the following respective values: For Figure 1: the sum of shallow sizes of obj1, obj2 and obj4 For Figure 2: the sum of shallow sizes of obj1, obj2, obj3 and obj4 Looking at obj2, however, we see that its retained size in the above cases will be: For Figure 1: the sum of shallow sizes of obj2 and obj4 For Figure 2: the sum of shallow sizes of obj2, obj3 and obj4 In general, retained size is an integral measure, which helps to understand the structure (clustering) of memoryand the dependencies between object subgraphs, as well as find potential roots of those subgraphs. 英文原文：Shallow and retained sizes]]></content>
      <tags>
        <tag>java</tag>
        <tag>heap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java性能调优]]></title>
    <url>%2F2018%2F02%2F15%2Fjava-performance%2F</url>
    <content type="text"><![CDATA[coggle.it java 性能调优脑图 coggle.it jvm trouble shooting 堆和栈堆和栈是程序运行的关键，很有必要把他们的关系说清楚。 栈是运行时的单位，而堆是存储的单位。 栈解决程序的运行问题，即程序如何执行，或者说如何处理数据；堆解决的是数据存储的问题，即数据怎么放、放在哪儿。 导论 性能测试方法 java线程状态首先要清楚线程的状态 线程的状态有：new、runnable、running、waiting、timed_waiting、blocked、dead 各状态说明： New: 当线程对象创建时存在的状态，此时线程不可能执行； Runnable：当调用thread.start()后，线程变成为Runnable状态。只要得到CPU，就可以执行； Running：线程正在执行； Waiting：执行thread.join()或在锁对象调用obj.wait()等情况就会进该状态，表明线程正处于等待某个资源或条件发生来唤醒自己； Timed_Waiting：执行Thread.sleep(long)、thread.join(long)或obj.wait(long)等就会进该状态，与Waiting的区别在于Timed_Waiting的等待有时间限制； Blocked：如果进入同步方法或同步代码块，没有获取到锁，则会进入该状态； Dead：线程执行完毕，或者抛出了未捕获的异常之后，会进入dead状态，表示该线程结束 其次，对于jstack日志，我们要着重关注如下关键信息 Deadlock：表示有死锁 Waiting on condition ：等待某个资源或条件发生来唤醒自己。具体需要结合jstacktrace来分析，比如线程正在sleep，网络读写繁忙而等待 Blocked：阻塞 Waiting on monitor entry：在等待获取锁 in Object.wait()：获取锁后又执行obj.wait()放弃锁 对于Waiting on monitor entry 和 in Object.wait()的详细描述：Monitor是 Java中用以实现线程之间的互斥与协作的主要手段，它可以看成是对象或者 Class的锁。每一个对象都有，也仅有一个 monitor。从下图中可以看出，每个 Monitor在某个时刻，只能被一个线程拥有，该线程就是 “Active Thread”，而其它线程都是 “Waiting Thread”，分别在两个队列 “ Entry Set”和 “Wait Set”里面等候。在 “Entry Set”中等待的线程状态是 “Waiting for monitor entry”，而在 “Wait Set”中等待的线程状态是 “in Object.wait()” java性能调优工具 Linux PerformanceLinux performance 系统性能大牛 -&gt; brendangregg.com，本节图片来源 Linux perf tools full Linux observability tools | Linux 性能观测工具 Linux performance benchmarking tools | Linux 性能测评工具 Linux performance tuning tools | Linux 性能调优工具 Linux static tools Linux observability: sar Linux performance observability tools: perf-toolsperf-tools github Linux bcc/BPF Tracing Toolsbcc-tools github linux性能工具cpu使用率用户状态时间和系统状态时间，任何使用系统底层资源的操作，都会导致应用占用更多的系统状态时间； 性能调优的目的 在尽可能短的时间内让CPU使用率尽可能高 CPU为什么会空闲 应用被同步原语阻塞，知道锁释放才能继续执行； 应用在等待某些东西，例如数据库调用锁返回的响应； 应用的确无所事事； 监控可运行的线程数运行队列（run queue） vmstat不错的整理，output info图片来源vmstat命令可以查看系统CPU/内存、swap、io等情况： 上面的命令每隔1秒采样一次，一共采样四次。CPU占用率很高，上下文切换频繁，说明系统有线程正在频繁切换，这可能是你的程序开启了大量的线程存在资源竞争的情况。另外swap也是值得关注的指标，如果swpd过高则可能系统能使用的物理内存不足，不得不使用交换区内存，还有一个例外就是某些程序优先使用swap，导致swap飙升，而物理内存还有很多空余，这些情况是需要注意的。 vmstat output info 123456789101112131415161718192021222324252627282930313233343536收下未整理的资料三.实际分析1. r:运行队列的等待进程数r（run:运行队列正在执行进程数）和 b(block等待CPU资源的进程个数)。当r超过了CPU数目，就会出现CPU瓶颈了。查看CPU的核的数量：cat /proc/cpuinfo|grep processor|wc -l在评估cpu的性能优劣时完全照搬网上说的几倍几倍是不准确的，不能只看top里的参数，还得你自己动手看看vmstat显示的run值和blocked值，当出现明 显较多的blocked的时候，就说明cpu产生了瓶颈。而top命令和uptime命令显示的负载均值，只能作为判断系统过去某个时间段的状态的参照， 与cpu的性能关系不大。当r值超过了CPU个数，就会出现CPU瓶颈，解决办法大体几种：1. 最简单的就是增加CPU个数和核数2. 通过调整任务执行时间，如大任务放到系统不繁忙的情况下进行执行，进尔平衡系统任务3. 调整已有任务的优先级(tips:vmstat中CPU的度量是百分比的。当us＋sy的值接近100的时候，表示CPU正在接近满负荷工作。但要注意的是，CPU 满负荷工作并不能说明什么，Linux总是试图要CPU尽可能的繁忙，使得任务的吞吐量最大化。唯一能够确定CPU瓶颈的还是r（运行队列）的值。)2.cpu使用率如果CPU的id(空闲率)长期低于10%，那么表示CPU的资源已经非常紧张，应该考虑进程优化或添加更多地CPU。wa(等待IO)表示CPU因等待IO资源而被迫处于空闲状态，这时候的CPU并没有处于运算状态，而是被白白浪费了，所以“等待IO应该越小越好。”【top命令和uptime命令显示的负载均值，只能作为判断系统过去某个时间段的状态的参照， 与cpu的性能关系不大。】文章推荐：关于CPU的运行队列与系统负载 ：http://www.cnblogs.com/hecy/p/4128605.htmlvmstat详解 (包含实例分析)：http://blog.chinaunix.net/uid-20775448-id-3668337.html top 通过TOP命令可以详细看出当前系统的CPU、内存、负载以及各进程状态（PID、进程占用CPU、内存、用户）等。从上面的结果看出该系统上安装了MySQL、java，可以看到他们各自的进程ID，假如这时Java进程占用较高的CPU和内存，那么你就要留心了，如果程序中没有计算量特别大、占用内存特别多的代码，可能你的java程序出现了未知的问题，可以根据进程ID做进一步的跟踪。 vmstat vs top相比top，可以看到整个机器的CPU,内存,IO的使用情况，而不是单单看到各个进程的CPU使用率和内存使用率(使用场景不一样)。 pidstat查看系统指标，还有一个第三方工具：pidstat，这个工具还是很好用的，需要先安装： yum install sysstat 该命令监控进程id为3618的CPU状态，每隔1秒采样一次，一共采样四次。“%CPU”表示CPU使用情况，“CPU”则表示正在使用哪个核的CPU，这里为0表示正在使用第一个核。如果还要显示线程ID，则可以使用： pidstat -p 3618 -u -t 1 4 如果要监控磁盘读写情况，这可以使用： pidstat还有其他的参数，可以通过pidstat –help获取，再次不再赘述。 磁盘使用率磁盘速度赶不上IO请求时，会导致问题完成I/O：w_await iostat网络使用率nicstat，netstatuptime(系统基本状态) [root@centos7_template ~]# uptime10:31:42 up 4 days, 1:01, 1 user,load average: 0.02, 0.02, 0.05 1234567810:31:42 // 当前系统时间up 4 days, 1:01 // 持续运行时间,时间越大，说明你的机器越稳定。 1 user // 用户连接数，是总连接数而不是用户数 load average: 0.02, 0.02, 0.05 // 统平均负载，统计最近1，5，15分钟的系统平均负载该命令将显示目前服务器持续运行的时间，以及负载情况。 通过这个命令，可以最简便的看出系统当前基本状态信息，这里面最有用是负载指标，如果你还想查看当前系统的CPU/内存以及相关的进程状态，可以使用TOP命令。 Java监控工具Oracle Monitoring Tools，Java Troubleshooting Guide(官方目录) Tool or Option Description and Usage Java Mission Control Java Mission Control (JMC) is a new JDK profiling and diagnostic tools platform for HotSpot JVM. It s a tool suite basic monitoring, managing, and production time profiling and diagnostics with high performance. Java Mission Control minimizes the performance overhead that’s usually an issue with profiling tools. See Java Mission Control. jcmd utility The jcmd utility is used to send diagnostic command requests to the JVM, where these requests are useful for controlling Java Flight Recordings. The JFRs are used to troubleshoot and diagnose JVM and Java Applications with flight recording events. See The jcmd Utility. Java VisualVM This utility provides a visual interface for viewing detailed information about Java applications while they are running on a Java Virtual Machine. This information can be used in troubleshooting local and remote applications, as well as for profiling local applications. See Java VisualVM. JConsole utility This utility is a monitoring tool that is based on Java Management Extensions (JMX). The tool uses the built-in JMX instrumentation in the Java Virtual Machine to provide information about performance and resource consumption of running applications. See JConsole. jmap utility This utility can obtain memory map information, including a heap histogram, from a Java process, a core file, or a remote debug server. See The jmap Utility. jps utility This utility lists the instrumented Java HotSpot VMs on the target system. The utility is very useful in environments where the VM is embedded, that is, it is started using the JNI Invocation API rather than the java launcher. See The jps Utility. jstack utility This utility can obtain Java and native stack information from a Java process. On Oracle Solaris and Linux operating systems the utility can alos get the information from a core file or a remote debug server. See The jstack Utility. jstat utility This utility uses the built-in instrumentation in Java to provide information about performance and resource consumption of running applications. The tool can be used when diagnosing performance issues, especially those related to heap sizing and garbage collection. See The jstat Utility. jstatd daemon This tool is a Remote Method Invocation (RMI) server application that monitors the creation and termination of instrumented Java Virtual Machines and provides an interface to allow remote monitoring tools to attach to VMs running on the local host. See The jstatd Daemon. visualgc utility This utility provides a graphical view of the garbage collection system. As with jstat, it uses the built-in instrumentation of Java HotSpot VM. See The visualgc Tool. Native tools Each operating system has native tools and utilities that can be useful for monitoring purposes. For example, the dynamic tracing (DTrace) capability introduced in Oracle Solaris 10 operating system performs advanced monitoring. See Native Operating System Tools. Java Web Start 工具 用途 javaws Monitor Java Applications 工具 用途 jconsole GUI监控工具 jvisualvm GUI监控工具 Monitor the JVM 工具 用途 jps 列出已装载的JVM，获取进程ID jstat(性能分析) JVM监控统计信息 jstatd 远程JVM监控统计信息 jmc(新) jmc：Java Mission Control；jfr：Java Flight Recorder Troubleshooting 工具 用途 jcmd(新)(建议替代jmap,jstack) 打印Java进程设计的基本类、线程和VM信息(向正在运行的JVM发送诊断信息请求,是从JDK1.7开始提供可以说是jstack和jps的结合体) jinfo 输出JVM配置信息(无需重启，动态调整jvm参数) jhat(对jmap导出的堆信息进行分析) 堆离线分析工具(Java Head Analyse Tool)，类比MAT、VisualVM jmap(查看内存，建议使用jcmd) 打印JVM堆内对象情况 jsadebugd jstack(查看线程，建议使用jcmd) 打印线程堆栈信息 Detailjps 可以看到jps命令直接罗列出了当前系统中存在的java进程，获取进程ID jinfo(无需重启，动态调整jvm参数)jstat用于输出java程序内存使用情况，包括新生代、老年代、元数据区容量、垃圾回收情况。 -class -compiler -gc -gccapacity -gccause -gcnew -gcnewcapacity -gcold -gcoldcapacity -gcpermcapacity -gcutil -printcompilation 具体日志输出含义，看手册。 上述命令输出进程ID为3618的内存使用情况（每2000毫秒输出一次，一共输出20次） 12345678910S0：幸存1区当前使用比例S1：幸存2区当前使用比例E：伊甸园区使用比例O：老年代使用比例M：元数据区使用比例CCS：压缩使用比例YGC：年轻代垃圾回收次数FGC：老年代垃圾回收次数FGCT：老年代垃圾回收消耗时间GCT：垃圾回收消耗总时间 jcmd (1.7后 建议替代jmap, jstack) from jdk1.7 jstack + jps 向正在运行的JVM发送诊断信息请求 jcmd常用指令 实例查看当前java进程 1$ jcmd 查看目标jvm中能获取到的信息 123456789101112131415161718192021$ jcmd 4876 help4876:The following commands are available:VM.native_memoryVM.commercial_featuresManagementAgent.stopManagementAgent.start_localManagementAgent.startThread.printGC.class_histogramGC.heap_dumpGC.run_finalizationGC.runVM.uptimeVM.flagsVM.system_propertiesVM.command_lineVM.versionhelp···· 查看目标jvm进程的版本信息 1$ jcmd 4876 VM.version 查看目标JVM进程的properties 1$ jcmd 4876 VM.system_properties 查看虚拟机启动时间 1$ jcmd 4876 VM.uptime 查看目标进程的参数 1$ jcmd 4876 VM.flags 查看类柱形图（ 同 jmap -histo pid） 1$ jcmd 4876 GC.class_histogram 查看JVM性能相关的参数 1$ jcmd 4876 PerfCounter.print 显示所有线程栈 1$ jcmd 4876 Thread.print | more dump出hprof文件 1$ jcmd 4876 GC.heap_dump dump.bin 执行一次finalization操作，相当于执行java.lang.System.runFinalization() 1$ jcmd 4876 GC.run_finalization jcmd helpjcmd [ options ]jcmd [ pid | main-class ] PerfCounter.printjcmd [ pid | main-class ] command [ arguments ]jcmd [ pid | main-class ] -f file main-class接收诊断命令请求的进程的main类 PerfCounter.print打印目标进程的性能计数器 file从文件file中读取命令，然后在目标Java进程上调用这些命令。在file中，每个命令必须写在单独的一行。以”#”开头的行会被忽略。当所有行的命令被调用完毕后，或者读取到含有stop关键字的命令，将会终止对file的处理。 jmap(1.7后 建议使用jcmd)使用jmap生成heapdump123456789101112131415161718Usage: jmap -clstats &lt;pid&gt; to connect to running process and print class loader statistics jmap -finalizerinfo &lt;pid&gt; to connect to running process and print information on objects awaiting finalization jmap -histo[:live] &lt;pid&gt; to connect to running process and print histogram of java object heap if the &quot;live&quot; suboption is specified, only count live objects jmap -dump:&lt;dump-options&gt; &lt;pid&gt; to connect to running process and dump java heap dump-options: live dump only live objects; if not specified, all objects in the heap are dumped. format=b binary format file=&lt;file&gt; dump heap to &lt;file&gt; Example: jmap -dump:live,format=b,file=heap.bin &lt;pid&gt; 用于输出java程序中内存对象的情况，包括有哪些对象，对象的数量。 打印JVM堆内对象情况，常用参数有：（具体描述见手册） -dump:[live,]format=b,file=&lt; filename&gt; 使用hprof二进制形式,输出jvm的heap内容到文件=. live子选项是可选的，假如指定live选项,那么只输出活的对象到文件。 -finalizerinfo 打印正等候回收的对象的信息。 -heap 打印heap的概要信息，GC使用的算法，heap的配置及wise heap的使用情况。 -histo[:live] 打印每个class的实例数目、内存占用、类全名信息。VM的内部类名字开头会加上前缀“*”。如果live子参数加上后,只统计活的对象数量。 -clstats 打印classload的信息。包含每个classloader的名字、活泼性、地址、父classloader和加载的class数量。 -F 在pid没有响应的时候强制使用-dump或者-histo参数。在这个模式下，live子参数无效。 jmap -histo 3618 上述命令打印出进程ID为3618的内存情况。但我们常用的方式是将指定进程的内存heap输出到外部文件，再由专门的heap分析工具进行分析,例如mat（Memory Analysis Tool），所以我们常用的命令是： jmap -dump:live,format=b,file=heap.hprof 3618 将heap.hprof传输出来到window电脑上使用mat工具分析： jstack(1.7后 建议使用jcmd)不仅能够导出线程堆栈，还能自动进行死锁检测，输出线程死锁原因； 用户输出java程序线程栈的情况，常用于定位因为某些线程问题造成的故障或性能问题。 jstack 3618 &gt; jstack.out jhat主要是用来分析java堆的命令，可以将堆中的对象以html的形式显示出来，包括对象的数量，大小等等，并支持对象查询语言。 用于对JAVA heap进行离线分析的工具，可以对不同虚拟机中导出的heap信息文件进行分析。详细使用见手册。 垃圾回收 堆内存 原生内存 线程和同步的性能 JavaEE性能调优 JavaSE优化 JIT即时编译]]></content>
      <tags>
        <tag>jvm</tag>
        <tag>性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CMS 垃圾回收启动的时机]]></title>
    <url>%2F2018%2F02%2F14%2Fcms-gc-timing%2F</url>
    <content type="text"><![CDATA[CMS(Concurrent-Mark-Sweep)是 Hotspot 虚拟机中目前使用最广泛的老年代垃圾回收器，在响应时间这个GC 指标上表现优异。CMS 在什么时机开始工作？触发的条件都有哪些？今天我们可以从 OpenJDK 中 CMS 这一块的实现来分析一下，该实现主要位于concurrentMarkSweepGeneration 和 ConcurrentMarkThread 这两个类中。 检查的时机由 CMS 垃圾回收线程执行垃圾回收的 检查逻辑。 ConcurrentMarkThread.cpp1234567891011121314void ConcurrentMarkThread::run() &#123; // 全局初始化 while (!_should_terminate) &#123; // 一直等待，直到可以开始垃圾回收 sleepBeforeNextCycle(); //... //... // 执行具体的垃圾回收逻辑 //... //... &#125;&#125; sleepBeforeNextCycle 的 实现如下： ConcurrentMarkThread.cpp123456789101112131415161718192021void ConcurrentMarkSweepThread::sleepBeforeNextCycle() &#123; while (!_should_terminate) &#123; if (CMSIncrementalMode) &#123; icms_wait(); if(CMSWaitDuration &gt;= 0) &#123; wait_on_cms_lock_for_scavenge(CMSWaitDuration); &#125; return; &#125; else &#123; if(CMSWaitDuration &gt;= 0) &#123; wait_on_cms_lock_for_scavenge(CMSWaitDuration); &#125; else &#123; wait_on_cms_lock(CMSCheckInterval); &#125; &#125; // 检查是否开始新一轮 CMS 回收周期 if (_collector-&gt;shouldConcurrentCollect()) &#123; return; &#125; &#125;&#125; 注： CMSWaitDuration：指的是 CMS 线程用于等待 Young GC 的时间，默认值是2000ms； CMSIncrementalMode ：标识 CMS 是否使用 增量垃圾回收模式，默认为false； _wait_on_cms_lock_for_scavenge_：这个函数可以让线程 sleep 一段时间，除非有同步 GC 或者 Full GC 发生。 检查的过程是否需要开始新一轮的 CMS 垃圾回收，主要实现在 shouldConcurrentCollect(); 主动触发 GC如果应用主动请求 GC（System.gc()），则直接触发 （当然要设置 ExplicitGCInvokesConcurrent 参数才会使用 CMS 来完成 Full GC），判断的代码如下： ConcurrentMarkSweepGeneration.cpp1234567if (_full_gc_requested) &#123; if (Verbose &amp;&amp; PrintGCDetails) &#123; gclog_or_tty-&gt;print_cr(&quot;CMSCollector: collect because of explicit &quot; &quot; gc request (or gc_locker)&quot;); &#125; return true;&#125; 被动触发检查未设置 -XX:+UseCMSInitiatingOccupancyOnly 如果统计开启了，且 CMS 完成时间小于 CMS 中各代剩余空间被填满的时间，则触发一次 CMS； 统计不可用，（第一次没有统计信息)，年老代大于__bootstrap_occupancy_，则触发 CMS ； ConcurrentMarkSweepGeneration.cpp1234567891011121314151617181920//CMSBootstrapOccupancy 是一个可配置的参数，其值介于 0 到 100 之间。_bootstrap_occupancy = ((double) CMSBootstrapOccupancy) / (double) 100;if (!UseCMSInitiatingOccupancyOnly) &#123; if (stats().valid()) &#123; if (stats().time_until_cms_start() == 0.0) &#123; return true; &#125; &#125; else &#123; if (_cmsGen-&gt;occupancy() &gt;= _bootstrap_occupancy) &#123; if (Verbose &amp;&amp; PrintGCDetails) &#123; gclog_or_tty-&gt;print_cr( &quot; CMSCollector: collect for bootstrapping statistics:&quot; &quot; occupancy = %f, boot occupancy = %f&quot;, _cmsGen-&gt;occupancy(), _bootstrap_occupancy); &#125; return true; &#125; &#125;&#125; 设置了 -XX:+UseCMSInitiatingOccupancyOnly 首先判断老年代内存使用决定是否回收，核心代码在 _should_concurrent_collect_ ，为 true 则触发 CMS； 根据增量模式收集是否失败决定是否回收，_incremental_collection_will_fail_，为 true 则触发 CMS，返回为 true 的主要条件有两个： 老年代的可用内存大小 &lt; Eden 区的内存使用量 + From 区的内存使用量 老年代的可用内存大小 &lt; YGC 时晋升到老年代对象大小的平均值 根据元空间的内存使用决定是否回收， _MetaspaceGC::should_concurrent_collect()_，true 则触发 CMS ； 最后根据触发间隔(CMSTriggerInterval)，其值默认为-1，所以一般不走这个逻辑); ConcurrentMarkThread.cpp12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 根据内存使用是否满足回收的条件进行判定if (_cmsGen-&gt;should_concurrent_collect()) &#123; if (Verbose &amp;&amp; PrintGCDetails) &#123; gclog_or_tty-&gt;print_cr(&quot;CMS old gen initiated&quot;); &#125; return true;&#125;// 根据CMS是否存在回收失败的风险进行判定GenCollectedHeap *gch = GenCollectedHeap::heap();assert(gch-&gt;collector_policy()-&gt;is_two_generation_policy(), &quot;You may want to check the correctness of the following&quot;);if (gch-&gt;incremental_collection_will_fail(true /* consult_young */)) &#123; if (Verbose &amp;&amp; PrintGCDetails) &#123; gclog_or_tty-&gt;print(&quot;CMSCollector: collect because incremental collection will fail &quot;); &#125; return true;&#125;// 根据元空间剩余空间大小判定if (MetaspaceGC::should_concurrent_collect()) &#123; if (Verbose &amp;&amp; PrintGCDetails) &#123; gclog_or_tty-&gt;print(&quot;CMSCollector: collect for metadata allocation &quot;); &#125; return true;&#125;// 根据 CMS 触发的周期判定：// a. 如果配置为0则返回为 true// b. 如果自cms触发到现在为止的时间大于触发周期，返回 trueif (CMSTriggerInterval &gt;= 0) &#123; if (CMSTriggerInterval == 0) &#123; // Trigger always return true; &#125; if (stats().cms_time_since_begin() &gt;= (CMSTriggerInterval / ((double) MILLIUNITS))) &#123; if (Verbose &amp;&amp; PrintGCDetails) &#123; if (stats().valid()) &#123; gclog_or_tty-&gt;print_cr( &quot;CMSCollector: collect because of trigger interval (time since last begin %3.7f secs)&quot;, stats().cms_time_since_begin()); &#125; else &#123; gclog_or_tty-&gt;print_cr(&quot;CMSCollector: collect because of trigger interval (first collection)&quot;); &#125; &#125; return true; &#125;&#125; _should_concurrent_collect_ 被用于判断是否应触发 CMS 回收老年代，核心判断如下： 判断 occupancy() 是否大于 _init_occupancy()（通过-XX:CMSInitiatingOccupancyFraction=n 初始化）_，大于则触发； 如果设置了 -XX:+UseCMSInitiatingOccupancyOnly，直接返回，不再继续后面逻辑； 如果没有设置 -XX:+UseCMSInitiatingOccupancyOnly，则根据空闲链表（记录了还可以分配的内存）的使用，返回对应的 bool 值，这里就不具体展开了。 其中 i_nit_occupancy()_ 可以获取 变量 _initiating_occupancy_ 的值，后者是通过 JVM 的启动参数 CMSInitiatingOccupancyFraction 初始化的。 ConcurrentMarkSweepGeneration.cpp12345678910111213141516171819202122232425262728bool ConcurrentMarkSweepGeneration::should_concurrent_collect() const &#123; assert_lock_strong(freelistLock()); if (occupancy() &gt; initiating_occupancy()) &#123; if (PrintGCDetails &amp;&amp; Verbose) &#123; gclog_or_tty-&gt;print(&quot; %s: collect because of occupancy %f / %f &quot;, short_name(), occupancy(), initiating_occupancy()); &#125; return true; &#125; if (UseCMSInitiatingOccupancyOnly) &#123; return false; &#125; if (expansion_cause() == CMSExpansionCause::_satisfy_allocation) &#123; if (PrintGCDetails &amp;&amp; Verbose) &#123; gclog_or_tty-&gt;print(&quot; %s: collect because expanded for allocation &quot;, short_name()); &#125; return true; &#125; if (_cmsSpace-&gt;should_concurrent_collect()) &#123; if (PrintGCDetails &amp;&amp; Verbose) &#123; gclog_or_tty-&gt;print(&quot; %s: collect because cmsSpace says so &quot;, short_name()); &#125; return true; &#125; return false;&#125; 在 CompactibleFreeListSpace.cpp 中，实现了__cmsSpace_→_should_concurrent_collect()_： CompactibleFreeListSpace.cpp123456// Support for concurrent collection policy decisions.bool CompactibleFreeListSpace::should_concurrent_collect() const &#123; // In the future we might want to add in frgamentation stats -- // including erosion of the &quot;mountain&quot; into this decision as well. return !adaptive_freelists() &amp;&amp; linearAllocationWouldFail();&#125; 过程总结是否进行CMS回收，归纳如下： 如果应用主动请求 GC，直接触发； 是否设置 UseCMSInitiatingOccupancyOnly； 没有设置 UseCMSInitiatingOccupancyOnly 统计开启（stats.valid），统计的cms完成时间小于cms剩余空间被填满的时间，则触发； 统计不可用，（第一次没有统计信息，!stats.valid)，年老代大于 __bootstrap_occupancy_，则触发； 设置 UseCMSInitiatingOccupancyOnly 根据指定年老代的判断逻辑 _should_concurrent_collect_，true 则触发； 根据增量模式收集是否失败，_incremental_collection_will_fail_，true 则触发； 根据元数据区的判断逻辑 _should_concurrent_collect_，true 则触发； 最后根据触发间隔(CMSTriggerInterval，默认为-1，所以一般不走这个逻辑);]]></content>
      <tags>
        <tag>jvm</tag>
        <tag>gc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[垃圾回收的算法与实现]]></title>
    <url>%2F2018%2F02%2F14%2Fjdk-gc-algorithm%2F</url>
    <content type="text"><![CDATA[序章 GC 把程序不用的内存空间视为垃圾, 是管理堆中已分配对象的机制， GC 要做的有两件事 找到内存空间里的垃圾 回收垃圾，让程序员能再次利用这部分空间 分配到内存空间中的对象中那些能通过mutator 引用的对象称为“活动对象”。反过来，把分配到堆中那些不能通过程序引用的对象称为“非活动对象”。也就是说，不能通过程序引用的对象已经没有人搭理了，所以死掉了。死掉的对象（即非活动对象）我们就称为“垃圾”。 不使用GC 会导致的问题 忘记释放内存：内存泄漏 忘记初始化指向释放对象的内存空间的指针：野指针/悬垂指针（dangling pointer） 错误释放了使用中的内存空间的情况 …… 算法篇学习GC之前 在GC 的世界中，对象表示的是“通过应用程序利用的数据的集合”。对象由头（header）和域（field）构成。对象中保存对象本身信息的部分称为“头”。头主要含有：对象的大小和对象的种类；对象使用者在对象中可访问的部分称为“域“。 根（root）这个词的意思是“根基”“根底”。在GC 的世界里，根是指向对象的指针的“起点”部分。调用栈、寄存器以及全局变量空间都是根。 GC 算法性能 吞吐量：GC管理的堆大小 / GC所花费的时间。 最大暂停时间：因执行GC 而暂停执行mutator 的最长时间。 堆使用效率：，堆使用效率和吞吐量，以及最大暂停时间不可兼得。简单地说就是：可用的堆越大，GC 运行越快；相反，越想有效地利用有限的堆，GC 花费的时间就越长。 访问的局部性：具有引用关系的对象之间通常很可能存在连续访问的情况。这在多数程序中都很常见，称为“访问的局部性”。考虑到访问的局部性，把具有引用关系的对象安排在堆中较近的位置，就能提高在缓存中读取到想利用的数据的概率，令mutator 高速运行。 GC-清除算法 算法概述： GC 标记- 清除算法由标记阶段和清除阶段构成。标记阶段是把所有活动对象都做上标记的阶段。清除阶段是把那些没有标记的对象，也就是非活动对象回收的阶段。通过这两个阶段，就可以令不能利用的内存空间重新得到利用。 伪代码实现： 1234mark_sweep() &#123; mark_phase() sweep_phase() &#125; 标记的两个阶段： 标记阶段：标记阶段就是“遍历对象并标记”的处理过程。 清除阶段：在清除阶段中，collector 会遍历整个堆，回收没有打上标记的对象（即垃圾），使其能再次得到利用。回收对象就是把对象作为分块，连接到被称为“空闲链表”的单向链表。在之后进行分配时只要遍历这个空闲链表，就可以找到分块了。在清除阶段，程序会遍历所有堆，进行垃圾回收。也就是说，所花费时间与堆大小成正比。堆越大，清除阶段所花费的时间就会越长。 搜索对象并进行标记时使用的是深度优先搜索（depth -first search）。这是尽可能从深度上搜索树形结构的方法。另一方面，还有广度优先搜索（breadth -first search）方法。这是尽可能从广度上搜索树形结构的方法。 GC 会搜索所有对象。不管使用什么搜索方法，搜索相关的步骤数（调查的对象数量）都不会有差别。另一方面，比较一下内存使用量（已存储的对象数量）就可以知道，深度优先搜索比广度优先搜索更能压低内存使用量。因此我们在标记阶段经常用到深度优先搜索。 GC 标记- 清除算法 优点: 算法简单，实现容易；与保守式GC 算法兼容。 缺点：碎片化，分配速度，与写时复制技术不兼容。 GC 标记- 清除算法中分块不是连续的，因此每次分配都必须遍历空闲链表，找到足够大的分块。 GC 标记- 清除算法就存在一个问题—与写时复制技术不兼容。即使没重写对象，GC 也会设置所有活动对象的标志位，这样就会频繁发生本不应该发生的复制，压迫到内存空间。 标记- 清除算法在“清除”阶段并非只是把分块放在1个“空闲链表”中，事实上，会按照分块大小创建不同的“空闲链表”，同时用一个数组来存储指向这些链表的地址。这样一来，只要按照mutator 所申请的分块大小选择空闲链表，就能在短时间内找到符合条件的分块了。P32 BiBOP 法：把堆分割成固定大小的块，让每个块只能配置同样大小的对象。因为每个块中只能配置同样大小的对象，所以不可能出现大小不均的分块。 BiBOP 法原本是为了消除碎片化，提高堆使用效率而采用的方法。但若在多个块中分散残留着同样大小的对象，反而会降低堆使用效率。P34 位图标记：只收集各个对象的标志位并表格化，不跟对象一起管理。在标记的时候，不在对象的头里置位，而是在这个表格中的特定场所置位。像这样集合了用于标记的位的表格称为“位图表格”（bitmap table），利用这个表格进行标记的行为称为“位图标记”。位图表格的实现方法有多种，例如散列表和树形结构等。 位图标记具有与与写时复制技术兼容、清除操作更高效的优点。 引用计数法 引用计数法中引入了一个概念，那就是“计数器”。计数器表示的是对象的人气指数，也就是有多少程序引用了这个对象（被引用数）。 引用计数法优点： 可即刻回收垃圾：当被引用数的值为0 时，对象马上就会把自己作为空闲空间连接到空闲链表。也就是说，各个对象在变成垃圾的同时就会立刻被回收。 最大暂停时间短：每次通过执行mutator 生成垃圾时这部分垃圾都会被回收，因而大幅度地削减了mutator 的最大暂停时间。 没有必要沿指针查找：没必要由根沿指针查找。 引用计数法缺点： 计数器值的增减处理繁重。 计数器需要占用很多位。 实现烦琐复杂。 循环引用无法回收。 GC复制法 GC 复制算法是利用From 空间进行分配的。当From 空间被完全占满时，GC 会将活动对象全部复制到To 空间。当复制完成后，该算法会把From 空间和To 空间互换，GC 也就结束了。From 空间和To 空间大小必须一致。这是为了保证能把From 空间中的所有活动对象都收纳到To 空间里。 GC 复制算法优点： 优秀的吞吐量：GC 复制算法消耗的时间是与活动对象的数量成比例的。GC 标记- 清除算法消耗的吞吐量是搜索活动对象（标记阶段）所花费的时间和搜索整体堆（清除阶段）所花费的时间之和； 可实现高速分配：GC 复制算法不使用空闲链表。这是因为分块是一个连续的内存空间。因此，调查这个分块的大小，只要这个分块大小不小于所申请的大小，那么移动$free 指针就可以进行分配了； 不会发生碎片化：复制后把对象重新集中，放在堆的一端； 与缓存兼容：GC 复制算法中有引用关系的对象会被安排在堆里离彼此较近的位置。 GC 复制算法缺点： 堆使用效率低下：只有一半堆能被使用； 不兼容保守式GC 算法：GC 复制算法必须移动对象重写指针跟保守式GC 算法不相容； 递归调用函数：复制某个对象时要递归复制它的子对象，使用了递归。递归效率较低，同时还有栈溢出的风险。Cheney 的GC 复制算法使用了迭代代替了递归调用。 Fenichel 和Yochelson 的GC 复制算法采用的是深度优先搜索，而Cheney 的复制算法采用的则是广度优先搜索。堆兼用作队列，正是Cheney 算法的一大优点。不用特意为队列留出多余的内存空间就能进行搜索。 多空间复制算法: 把堆N 等分，对其中2 块空间执行GC 复制算法，对剩下的（N-2）块空间执行GC 标记- 清除算法. 多空间复制法优缺点： 优点：多空间复制算法没有将堆二等分，而是分割成了更多块空间，从而更有效地利用了堆。以往的GC 复制算法只能使用半个堆，而多空间复制算法仅仅需要空出一个分块，不能使用的只有1/N 个堆。 缺点：执行GC 复制算法的只有N 等分中的两块空间，对于剩下的（N-2）块空间执行的是GC标记- 清除算法。因此就出现了GC 标记- 清除算法固有的问题—分配耗费时间、分块碎片化等。 GC标记-压缩算法 GC 标记- 压缩算法由标记阶段和压缩阶段构成。标记阶段和GC 标记- 清除算法段完全一样，压缩阶段通过数次搜索堆来重新装填活动对象。压缩阶段并不会改变对象的排列顺序，只是缩小了它们之间的空隙，把它们聚集到了堆的一端。 优点：可有效利用堆。堆使用效率几乎是GC 复制算法的2 倍，同时也避免了管GC 标记- 清除算法中碎片化的缺点。 缺点：压缩花费计算成本。Lisp2 算法的压缩中，必须对整个堆进行3 次搜索，Two-Finger算法需要搜索2 次堆。 保守GC 保守式GC（Conservative GC）指的是“不能识别指针和非指针的GC”。在运行GC 时采取的是一种保守的态度，即“把可疑的东西看作指针，稳妥处理”。 寄存器、调用栈和全局变量空间中的根都是不明确的根。 保守式GC 在检查不明确的根时所进行的基本项目： 是不是被正确对齐的值？（在32 位CPU 的情况下，为4 的倍数） 是不是指着堆内？ 是不是指着对象的开头？ 保守式GC优缺点： 优点：语言处理程序不依赖于GC； 缺点：识别指针和非指针需要付出成本、能够使用的GC 算法有限、错误识别指针会压迫堆。 准确式GC（Exact GC）和保守式GC 正好相反，它是能正确识别指针和非指针的GC。GC 之后，堆里只会留下活动对象。缺点是当创建准确式GC 时，语言处理程序必须对GC 进行一些支援。 保守式GC 有个缺点，就是“不能使用GC 复制算法等移动对象的算法”。解决这个问题的方法之一就是“间接引用”，即可经由根和对象之间的句柄（handle）来间接地处理对象。缺点是会拉低访问对象内数据的速度，这会关系到整个语言处理程序的速度。 分代垃圾回收 刚生成的对象称为新生代对象，到达一定年龄的对象则称为老年代对象。，经历过一次GC 后活下来的对象年龄为1 岁。 新生代对象不只会被根和新生代空间引用，也可能被老年代对象引用。 记录集用来记录从老年代对象到新生代对象的引用。这样在新生代GC 时就可以不搜索老年代空间的所有对象，只通过搜索记录集来发现从老年代对象到新生代对象的引用。新生代GC时将记录集看成根（像根一样的东西），并进行搜索，以发现指向新生代空间的指针。 在Ungar 的分代垃圾回收中，对象的头部中除了包含对象的种类和大小之外，还有以下这3 条信息。 对象的年龄（age） 已经复制完毕的标志（forwarded） 已经向记录集记录完毕的标志（remembered） forwarded是用来防止重复复制相同对象的标志； remembered 用来防止向记录集中重复记录的标志；remembered 只用于老年代对象，age 和forwarded 只用于新生代对象。 在分代垃圾回收中，为了将老年代对象记录到记录集里，我们利用写入屏障（write barrier）。在mutator 更新对象间的指针的操作中，写入屏障是不可或缺的。 通常的GC 复制算法把空间二等分为From 空间和To 空间，即使From 空间里的对象都还活着，也确保能把它们收纳到To 空间里去。不过在Ungar 的分代垃圾回收里，To 幸存空间必须收纳From 幸存空间以及生成空间中的活动对象。From 幸存空间和生存空间的点大小比To 幸存空间大，所以如果活动对象很多，To 幸存空间就无法容纳下它们。当发生这种情况时，稳妥起见只能把老年代空间作为复制的目标空间。当然，如果频繁发生这种情况，分代垃圾回收的优点就会淡化。 分代垃圾回收优点： 正如Ungar所说的那样：“据实验表明，分代垃圾回收花费的时间是GC 复制算法的1/4。”可见分代垃圾回收的导入非常明显地改善了吞吐量。 写入屏障导致的额外负担降低了吞吐量。只有当新生代GC 带来的速度提升效果大于写入屏障对速度造成的影响时，分代垃圾回收才能够更好地发挥作用。当这个大小关系不成立时，分代垃圾回收就没有什么作用，或者说反而可能会起到反作用。 多代垃圾回收（Multi-generational GC）中，除了最老的那一代之外，每代都有一个记录集。X 代的记录集只记录来自比X 老的其他代的引用。 分为2 代或者3 代是最好的。P157 列车垃圾回收（Train GC）:将老年代空间按照一定大小划分，每个划分出来的空间称为车厢，由1个以上的车厢连接成的东西就叫作列车。它是为了在分代垃圾回收中利用老年代GC 而采用的算法，可以控制老年代GC 中暂停时间的增长。 列车垃圾回收只在记录集中记录了从后面车厢（列车）到前面车厢（列车）的引用，没有记录从前面车厢到后面车厢的引用。 增量式垃圾回收 增量式垃圾回收（Incremental GC）是一种通过逐渐推进垃圾回收来控制mutator 最大暂停时间的方法。 增量式垃圾回收是将GC 和mutator 一点点交替运行的手法。执行GC时 mutator 完全停止运行的GC 叫作停止型GC。 增量式垃圾回收的三色标记算法（Tri-color marking）： 白色：还未搜索过的对象 灰色：正在搜索的对象 黑色：搜索完成的对象 搜索过程如下 GC 开始运行前所有的对象都是白色。GC 一开始运行，所有从根能到达的对象都会被标 记，然后被堆到栈里。GC 只是发现了这样的对象，但还没有搜索完它们，所以这些对象就 成了灰色对象。 灰色对象会被依次从栈中取出，其子对象也会被涂成灰色。当其所有的子对象都被涂成 灰色时，对象就会被涂成黑色。 当GC 结束时已经不存在灰色对象了，活动对象全部为黑色，垃圾则为白色。 GC 标记- 清除算法增量式运行：在根查找阶段把能直接从根引用的对象涂成灰色。在标记阶段查找灰色对象，将其子对象也涂成灰色，查找结束后将灰色对象涂成黑色。在清除阶段则查找堆，将白色对象连接到空闲链表，将黑色对象变回白色。 优点：缩短最大暂停时间。增量式垃圾回收适合那些比起提高吞吐量，更重视缩短最大暂停时间的应用程序。 缺点：降低了吞吐量。主要是因为存在写入屏障。]]></content>
      <tags>
        <tag>jvm</tag>
        <tag>gc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 内存溢出]]></title>
    <url>%2F2018%2F02%2F14%2Fjava-out-of-memory%2F</url>
    <content type="text"><![CDATA[堆溢出报错信息：java.lang.OutOfMemoryError: Java heap space 原因 堆中（新生代和老年代）无法继续分配对象了； 某些对象的引用长期被持有没有被释放，垃圾回收器无法回收； 使用了大量的 Finalizer 对象，这些对象并不在 GC 的回收周期内。 解决方法 将堆内存 dump 下来，使用 MAT 分析一下，解决内存泄漏； 如果没有内存泄漏，使用 -Xmx 增大堆内存； 如果有自定义的 Finalizable 对象，考虑其存在的必要性。 GC超载溢出报错信息：java.lang.OutOfMemoryError：GC overhead limit exceeded 原因垃圾回收器超过98%的时间用来做垃圾回收，但回收了不到2%的堆内存。 解决方法 添加 -XX:-UseGCOverheadLimit 这个启动参数去掉报警，但这只是一种掩耳盗铃的方式，一般出现 GC overhead limit exceeded 说明离真正的 OOM 也不远了； 将堆内存 dump 下来，使用 MAT 分析一下，解决内存泄漏； 如果没有内存泄漏，使用 -Xmx 增大堆内存； 永久代/元空间溢出报错信息：java.lang.OutOfMemoryError: PermGen space 或者java.lang.OutOfMemoryError: Metaspace（Java8及以上） 原因永久代是 HotSot 虚拟机对 方法区的具体实现，存放了已被虚拟机加载的类信息、常量、静态变量、JIT编译后的代码等。 需要注意的是，在Java8后，永久代有了一个新名字：元空间，元空间使用的是本地内存。永久代里存在的信息也有了若干变化： 字符串常量由永久代转移到堆中； 和永久代相关的JVM参数已移除。 出现永久代或元空间的溢出的原因可能有如下几种： 有频繁的常量池操作（eg. String.intern），这种情况只适用于Java7之前应用； 加载了大量的类信息，且没有及时卸载； 应用部署完后没有重启。 没有重启 JVM 进程一般发生在调试时，如下面 tomcat 官网的一个 FAQ： Why does the memory usage increase when I redeploy a web application?That is because your web application has a memory leak.A common issue are “PermGen” memory leaks. They happen because the Classloader (and the Class objects it loaded) cannot be recycled unless some requirements are met (). They are stored in the permanent heap generation by the JVM, and when you redeploy a new class loader is created, which loads another copy of all these classes. This can cause OufOfMemoryErrors eventually.(*) The requirement is that all classes loaded by this classloader should be able to be gc’ed at the same time. 解决方法永久代/元空间 溢出的原因比较简单，解决方法有如下几种： Java8前的应用：使用 -XX:MaxPermSize 增加永久代的大小（）； Java8及以后的应用：如果设置了 -XX:MaxMetaSpaceSize，调整其大小或者移除掉该参数。 尝试重启JVM。 方法栈溢出报错信息：java.lang.OutOfMemoryError : unable to create new native Thread 原因虚拟机在拓展栈空间时，无法申请到足够的内存空间。一般出现在内存空间过小，但是又创建了大量的线程的场景。 解决方法 通过 -Xss 降低的每个线程栈大小的容量，注意-Xms，-Xmx的影响； 线程总数也受到系统空闲内存和操作系统的限制，检查是否该系统下有此限制： /proc/sys/kernel/pid_max， /proc/sys/kernel/thread-max， max_user_process（ulimit -u） /proc/sys/vm/max_map_count 非常规溢出数组分配溢出报错信息 ：java.lang.OutOfMemoryError: Requested array size exceeds VM limit 这种情况一般是由于不合理的数组分配请求导致的，消除代码逻辑错误或者调整堆大小。 Swap分区溢出报错信息 ：java.lang.OutOfMemoryError: Out of swap space 这种情况一般是操作系统导致的，可能的原因有： swap 分区大小分配不足； 机器上其他进程消耗了所有的内存。 根据机器上的日志文件排查。 本地方法溢出报错信息 ：_java.lang.OutOfMemoryError: stack_trace_with_native_method_ 这种情况表明，本地方法在运行时出现了内存分配失败。和 java.lang.OutOfMemoryError : unable to create new native Thread 保存不同，方法栈溢出出现在 JVM 的代码层面，而本地方法溢出发生在JNI代码或本地方法处。]]></content>
      <tags>
        <tag>jvm</tag>
        <tag>out of memory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux，Java 监控工具]]></title>
    <url>%2F2018%2F02%2F14%2Flinux-monitor-tools%2F</url>
    <content type="text"><![CDATA[性能监控性能分析过程中一切都要可视化，从而了解应用内部及应用所在的环境发生了什么； http://java.net (已关闭，参见oracle) linux 监控工具uptime [root@centos7_template ~]# uptime10:31:42 up 4 days, 1:01, 1 user,load average: 0.02, 0.02, 0.05 1234567810:31:42 // 当前系统时间up 4 days, 1:01 // 持续运行时间,时间越大，说明你的机器越稳定。 1 user // 用户连接数，是总连接数而不是用户数 load average: 0.02, 0.02, 0.05 // 统平均负载，统计最近1，5，15分钟的系统平均负载该命令将显示目前服务器持续运行的时间，以及负载情况。 通过这个命令，可以最简便的看出系统当前基本状态信息，这里面最有用是负载指标，如果你还想查看当前系统的CPU/内存以及相关的进程状态，可以使用TOP命令。 top 通过TOP命令可以详细看出当前系统的CPU、内存、负载以及各进程状态（PID、进程占用CPU、内存、用户）等。从上面的结果看出该系统上安装了MySQL、java，可以看到他们各自的进程ID，假如这时Java进程占用较高的CPU和内存，那么你就要留心了，如果程序中没有计算量特别大、占用内存特别多的代码，可能你的java程序出现了未知的问题，可以根据进程ID做进一步的跟踪。除了通过TOP命令找到进程信息以外，还可以通过jdk自带的工具JPS直接找到java程序的进程号。 jps 可以看到jps命令直接罗列出了当前系统中存在的java进程，这里第一个是jps命令自己的java进程，而另外一个是我启动的nosql监控工具进程。通过这种方法查询到java程序的进程ID后，可以进一步通过： top12top -p 3618 // 这里的3618就是上面查询到的java程序的进程ID 通过此方法可以准确的查看指定java进程的CPU/内存使用情况。 vmstat除此之外，vmstat命令也可以查看系统CPU/内存、swap、io等情况： 上面的命令每隔1秒采样一次，一共采样四次。CPU占用率很高，上下文切换频繁，说明系统有线程正在频繁切换，这可能是你的程序开启了大量的线程存在资源竞争的情况。另外swap也是值得关注的指标，如果swpd过高则可能系统能使用的物理内存不足，不得不使用交换区内存，还有一个例外就是某些程序优先使用swap，导致swap飙升，而物理内存还有很多空余，这些情况是需要注意的。 vmstat vs top相比top，可以看到整个机器的CPU,内存,IO的使用情况，而不是单单看到各个进程的CPU使用率和内存使用率(使用场景不一样)。 pidstat查看系统指标，还有一个第三方工具：pidstat，这个工具还是很好用的，需要先安装： yum install sysstat 该命令监控进程id为3618的CPU状态，每隔1秒采样一次，一共采样四次。“%CPU”表示CPU使用情况，“CPU”则表示正在使用哪个核的CPU，这里为0表示正在使用第一个核。如果还要显示线程ID，则可以使用： pidstat -p 3618 -u -t 1 4 如果要监控磁盘读写情况，这可以使用： pidstat还有其他的参数，可以通过pidstat –help获取，再次不再赘述。 jdk 常用工具汇总下面再介绍几个JDK自带有用的工具：jps、jstat、jmap、jstack JDK常用内置工具 工具 用途 jps 列出已装载的JVM jstack 打印线程堆栈信息 jstat JVM监控统计信息 jmap 打印JVM堆内对象情况 jinfo 输出JVM配置信息 jconsole GUI监控工具 jvisualvm GUI监控工具 jhat 堆离线分析工具 jdb java进程调试工具 jstatd 远程JVM监控统计信息 jps上面我们已经使用过了，他可以罗列出目前再服务器上运行的java程序及进程ID； jstat用于输出java程序内存使用情况，包括新生代、老年代、元数据区容量、垃圾回收情况。 -class -compiler -gc -gccapacity -gccause -gcnew -gcnewcapacity -gcold -gcoldcapacity -gcpermcapacity -gcutil -printcompilation 具体日志输出含义，看手册。 上述命令输出进程ID为3618的内存使用情况（每2000毫秒输出一次，一共输出20次） 12345678910S0：幸存1区当前使用比例S1：幸存2区当前使用比例E：伊甸园区使用比例O：老年代使用比例M：元数据区使用比例CCS：压缩使用比例YGC：年轻代垃圾回收次数FGC：老年代垃圾回收次数FGCT：老年代垃圾回收消耗时间GCT：垃圾回收消耗总时间 jmap用于输出java程序中内存对象的情况，包括有哪些对象，对象的数量。 打印JVM堆内对象情况，常用参数有：（具体描述见手册） -dump:[live,]format=b,file=&lt; filename&gt; 使用hprof二进制形式,输出jvm的heap内容到文件=. live子选项是可选的，假如指定live选项,那么只输出活的对象到文件。 -finalizerinfo 打印正等候回收的对象的信息。 -heap 打印heap的概要信息，GC使用的算法，heap的配置及wise heap的使用情况。 -histo[:live] 打印每个class的实例数目、内存占用、类全名信息。VM的内部类名字开头会加上前缀“*”。如果live子参数加上后,只统计活的对象数量。 -clstats 打印classload的信息。包含每个classloader的名字、活泼性、地址、父classloader和加载的class数量。 -F 在pid没有响应的时候强制使用-dump或者-histo参数。在这个模式下，live子参数无效。 jmap -histo 3618 上述命令打印出进程ID为3618的内存情况。但我们常用的方式是将指定进程的内存heap输出到外部文件，再由专门的heap分析工具进行分析,例如mat（Memory Analysis Tool），所以我们常用的命令是： jmap -dump:live,format=b,file=heap.hprof 3618 将heap.hprof传输出来到window电脑上使用mat工具分析： jstack用户输出java程序线程栈的情况，常用于定位因为某些线程问题造成的故障或性能问题。 jstack 3618 &gt; jstack.out jhat用于对JAVA heap进行离线分析的工具，可以对不同虚拟机中导出的heap信息文件进行分析。详细使用见手册。 参考文献 Java Platform, Standard Edition Tools Reference JDK内置工具使用]]></content>
      <tags>
        <tag>jvm</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdk9-new-feature]]></title>
    <url>%2F2018%2F02%2F06%2Fjdk9-new-feature%2F</url>
    <content type="text"><![CDATA[Java 9版本于2017年9月21日发布，本文将主要介绍Java 9中引入的若干新特性。在介绍之前，还是很必要回顾一下Java 8发布的内容，毕竟Java 9中的若干新特性（例，Stream 流处理）也是在前者基础上的展开的。 Java 8特性回顾Java 8是Java自Java 5（发布于2004年）之后的最重要的版本。这个版本包含语言、编译器、库、工具和JVM等方面的十多个新特性。主要有： Java语言 方法引用 重复注解 类型推断 参数名称 拓宽注解的使用 Lambda表达式 接口的默认方法和静态方法 JDK新特性 Optional Streams Date/Time API Base64 并行数组 新增 StampedLock 原子性操作类添加新成员 优化HashMap JVM 使用 元空间（Metaspace）代替永久代（PermGen space） 使用 -XX:MetaSpaceSize和 -XX:MaxMetaspaceSize 代替原来的 -XX:PermSize和-XX:MaxPermSize。 工具/编译器 Nashorn引擎：jjs 类依赖分析器：jdeps Java 9的安装下载Java SE Development Kit 9 Downloads 使用将 JAVA_HOME 配置为 Java 9的路径后，查看 JDK 版本：1234java -versionjava version &quot;9.0.1&quot;Java(TM) SE Runtime Environment (build 9.0.1+11)Java HotSpot(TM) 64-Bit Server VM (build 9.0.1+11, mixed mode) 将 JAVA_HOME 配置为 Java 8的路径后，再次查看 JDK 版本：1234java -versionjava version &quot;1.8.0_92&quot;Java(TM) SE Runtime Environment (build 1.8.0_92-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.92-b14, mixed mode) 注意这里的一个细节：从 Java 9开始，Java 版本方案将根据业内软件版本编码的最佳实践进行修改，即Java版本字符串将依次包含如下三个部分：主版本号、小（维护）版本号和安全版本号。这一变化可能会导致目前解析版本字符串而有假定版本号开头为1或点的应用程序出现问题。例如： System.getProperty(“java.version”).indexof(‘.’);。 Java 9新特性概要Java语言 Jigsaw：模块化 接口中的私有方法 JDK 进程 API 增强 改进了 Stream API 集合类的工厂方法 Try-With-Resources 改进 HTTP/2 响应式流 Reactive Streams JVM 修改默认垃圾回收器 优化字符串占用空间 竞争锁的性能优化 代码分段缓存 工具/编译器 JShell：Java交互式REPL 改进的 Javadoc 多版本 JAR 详解新特性1：Jigsaw：模块化模块系统主要解决两个基本问题： Jar包膨胀：以类和接口进行面向对象的设计在系统规模越来越大时因为隔离粒度问题而难以真正地封装代码，因为在更高粒度层面（JAR 文件，如tool.jar, rt.jar），系统的不同部分之间没有明确的依赖关系的概念。 类使用的的安全性：类路径（classpath）中的任何其他类可以访问每个公共类，这会导致开发人员无意中使用不是公开API的类，严重影响系统后续维护升级。 模块化的引入使得JDK可以在更小的设备中使用，因为采用模块化系统的应用程序只需要这些应用程序所需的那部分 JDK 模块，而非是整个JDK框架了。 其次，模块化使得对 package 的控制更精细了，这与 maven 的通过依赖不同之处，在于 maven 使用了dependency 进行管理依赖，而 jigsaw 使用 requiure 进行管理依赖，通过 export，可以只暴露某个模块下指定的包给调用者（写到这里我联想到了 Javascript 里面的 requirejs 模块，Java 这两个关键字的灵感来自于此？）。 例子： 编写模块化的代码和没有模块化的代码区别并不大，Java 9 通过根目录下的 module-info.java 文件进行区分。 整个工程的结构为：1234567891011src└── main└── java├── com│ └── sk│ └── scalpel│ └── priviate│ └── PrivateClass.java│ └── common│ └── CommonClass.java└── module-info.java src/main/java/module-info.java 内容为：1234module commonClass.jigsaw &#123; exports com.sk.ocelot.common; requires sso;&#125; 在这个模块描述符中，通过 requires 语句来表示对其他模块的依赖，此外，exports 语句可以控制哪些package 可被其他模块使用。 Java 平台本身也使用自己的模块系统进行了模块化。通过封装 JDK 内部类，Java 平台变得更加安全并且让后续的持续演进变得容易得多。比如 rt.jar, tools.jar 两个核心 Jar包，被 JDK9/jmods 文件下若干个 *.jmod 文件所替代。 下图是 Java9 中的模块依赖图，可以看到，所有的模块都依赖了一个叫做 java.base 的模块，而 java.base 中包含了Java 语言层面的一些基础包，如 java.net、 java.nio、java、util等，具体可参考 Module java.base 新特性2：JShell：Java交互式REPLREPL是一种快速运行语句的命令行工具，很多语言都具备这个能力，如 Python、Scala 等。我们可以从控制台启动 jshell，然后直接输入和执行 Java 代码，jshell的即时反馈使它成为探索API和尝试语言特性的好工具。 12345678pwd/Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/Contents/Home/bin./jshell| 欢迎使用 JShell -- 版本 9.0.1| 要大致了解该版本, 请键入: /help introjshell&gt; System.out.println(&quot;Current process id: &quot; + ProcessHandle.current().pid());Current process id: 9022jshell&gt; 有了 JShell 后，测试 API 再也不用去新建一个工程了~ 新特性3：垃圾回收器Garbage First（G1）的设计初衷是，以更高的计算成本为代价最小化STW中断时间。Java 9 使用G1作为默认的垃圾收集器，替代了之前默认使用的 Parallel GC。事实上它从 JDK 8u40 开始就已经十分完善，足以作为默认的垃圾收集器了。 当然，这里也存在若干争议，可以看下一下这篇文章：Oracle Proposes G1 as the Default Garbage Collector for Java 9。 新特性4：字符串优化JDK 6 引入了可选的 Compressed String 功能，JDK 9 引入了 Compact String ，它们两者的设计目的都是优化字符串在 JVM 中的内存占用。因为 Java 内部使用 UTF-16，占用两个字节，但从统计角度来说只需 8 比特的情况占大多数，例如：LATIN-1。大多数情况下，字符串实例常占用比它实际需要的内存多一倍的空间。 Java 6中，在启动参数里使用 -XX:+UseCompressedStrings 可以启用 Compressed String 功能，字符串将以 byte[] 的形式存储，代替原来的 char[]，此功能最终在 JDK 7 中被移除，主要原因在于它将带来一些无法预料的性能问题（存储为 byte[] 后，字符串的操作方法都依赖于字符数组的表现形式，而非字节数组。介于此，很多的方法都需将压缩后的字节数组解压缩为字符数组，无形中影响了性能）。 Java 9重新采纳字符串压缩这一概念：通过引入了一个 final 修饰的成员变量 coder, 由它来保存当前字符串的编码信息。若该字符串为 LATIN-1 编码，则使用8个比特来存储，若干 UTF-16 编码，则使用16个比特来编码。代码如下：12345678910111213141516171819202122232425262728293031public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** * The value is used for character storage. * * @implNote This field is trusted by the VM, and is a subject to * constant folding if String instance is constant. Overwriting this * field after construction will cause problems. * * Additionally, it is marked with &#123;@link Stable&#125; to trust the contents * of the array. No other facility in JDK provides this functionality (yet). * &#123;@link Stable&#125; is safe here, because value is never null. */ @Stable private final byte[] value; /** * The identifier of the encoding used to encode the bytes in * &#123;@code value&#125;. The supported values in this implementation are * * LATIN1 * UTF16 * * @implNote This field is trusted by the VM, and is a subject to * constant folding if String instance is constant. Overwriting this * field after construction will cause problems. */ private final byte coder; //略&#125; 可以看到 新引入的 coder 字段的及其作用。 新特性5：HTTP/2HTTP/2标准是HTTP协议的最新版本，上一个版本HTTP/1.1诞生于1999年。 Java对 HTTP 的支持是基于 HTTP/1.0 展开的，当时最好的设计思想已经无法满足现在的需求（如 HTTPS 的大规模普及）。同时，JDK 内核对 HTTP 的支持已经无法跟上现实网络的发展步伐。实际上，甚至JDK8也只不过是交付了一个支持 HTTP/1.0 的客户端，然而，大多数的开发者早已转而使用第三方客户端库了，比如Apache的HttpComponents。 Java 9提供了一种HTTP调用的新方式。对于旧的“HttpURLConnetion”API来说，这个迟来的替换也添加了对 WebSockets和 HTTP/2 的支持。 Java 9当前的代码库只支持 HTTP/1.1，但是已经包含了新的 API。这使得在对 HTTP/2 支持完成对过程中，开发者可以实验性地使用和验证新的 API。如下面的异步发送请求功能：12345678910111213141516try &#123; HttpClient httpClient = HttpClient.newHttpClient(); HttpRequest httpRequest = HttpRequest.newBuilder().uri(new URI(&quot;https://www.bing.com/&quot;)).GET().build(); Map&lt; String, List &lt; String &gt;&gt; headers = httpRequest.headers().map(); CompletableFuture&lt;HttpResponse&lt; String &gt;&gt; asyncResponse = httpClient.sendAsync(httpRequest, HttpResponse.BodyHandler.asString()); if (!asyncResponse.isDone()) &#123; asyncResponse.cancel(true); System.out.println(&quot;Sedn async request failed...&quot;); return; &#125; HttpResponse response = asyncResponse.get(); System.out.println(&quot;Response body: &quot; + response.body()); &#125; catch (Exception e) &#123; System.out.println(&quot;message &quot; + e);&#125; 新特性6：接口中的私有方法Java 8使用两个新概念扩展了接口的含义：默认方法和静态方法。设想这样一个场景：在定义的接口中有几个默认方法，代码几乎相同，我们需要重构这些方法来调用包含共享功能的私有方法。现在的问题是：默认方法不能是私有的。使用共享代码创建另一个默认方法不是一个可行的解决方案，因为该帮助方法会成为公共API的一部分。在Java 9中，可以向接口添加私有的帮助方法来解决此问题：1234567891011121314151617public interface IInterfaceDemo &#123; default void method1() &#123; init(); // do something &#125; default void method2() &#123; init(); // do something &#125; // 公共方法声明为私有 private void init() &#123; System.out.println(&quot;Current process id: &quot; + ProcessHandle.current().pid()); &#125; &#125; 新特性7：进程增强API新增加的 API 提供了一种java程序和操作系统交互的能力，我们可以在代码中来获取关于进程的一些信息，java 9中新增了一个类 ProcessHandle，使用这个类可以很方便的查询进程的一些信息。 下面略举几个例子，具体可参考 ProcessHandleImpl 这个实现类~ 1234567891011121314151617// 获取当前进程的PIDlong pid = ProcessHandle.current().pid(); // 获取当前进程的所有子进程Stream&lt;ProcessHandle&gt; children = ProcessHandle.current().children(); // 获取进程的存活状态boolean isProcessAlive = ProcessHandle.current().isAlive(); // 通过静态方法获取所有进程ProcessHandle.allProcesses().forEach(new Consumer&lt;ProcessHandle&gt;() &#123; @Override public void accept(ProcessHandle processHandle) &#123; if (processHandle.pid() == pid) &#123; System.out.println(&quot;I&apos;m the Current Process:&quot; + pid + &quot;\n&quot; + processHandle.info()); &#125; &#125;&#125;); 新特性8：改进了Stream APIStream 接口新增方法：1234default Stream&lt;T&gt; dropWhile(Predicate&lt;? super T&gt; predicate)default Stream&lt;T&gt; takeWhile(Predicate&lt;? super T&gt; predicate)static &lt;T&gt; Stream&lt;T&gt; ofNullable(T t)static &lt;T&gt; Stream&lt;T&gt; iterate(T seed, Predicate&lt;? super T&gt; hasNext, UnaryOperator&lt;T&gt; next) 用法举例：1234567// 以下代码片段会生成包含1到100之间的所有整数的流：Stream.iterate(1, n -&gt; n &lt;= 100, n -&gt; n + 1) // 以下代码输出 5, 6, 7List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7);list.stream().dropWhile(x -&gt; x &lt; 5).forEach(System.out::println); Collectors 类 新增方法 filtering 和 flatMapping： 12&lt;T,A,R&gt; Collector&lt;T,?,R&gt; filtering(Predicate&lt;? super T&gt; predicate, Collector&lt;? super T,A,R&gt; downstream)&lt;T,U,A,R&gt; Collector&lt;T,?,R&gt; flatMapping(Function&lt;? super T,? extends Stream&lt;? extends U&gt;&gt; mapper, Collector&lt;? super U,A,R&gt; downstream) 用法举例：123456789101112131415Map&lt;String, List&lt;String&gt;&gt; keyValues = list.stream() .collect(Collectors.toMap(String::valueOf, x -&gt; List.of(String.valueOf(x), String.valueOf(x)))); keyValues.forEach((key, value) -&gt; System.out.println(&quot;key: &quot; + key + &quot;, value: &quot; + value));/** * 输出如下 * key: 1, value: [1, 1] * key: 2, value: [2, 2] * key: 3, value: [3, 3] * key: 4, value: [4, 4] * key: 5, value: [5, 5] * key: 6, value: [6, 6] * key: 7, value: [7, 7] */List&lt;String&gt; values = keyValues.values() .stream() .collect(Collectors.flatMapping(e -&gt; e.stream().distinct(), Collectors.toList()));values.stream().forEach(System.out::print);// 输出 12345678 新特性9：集合类的工厂方法在java 9中，分别为List、Set、Map增加了of静态工厂方法，来获取一个不可变的List、Set、Map。不变的对象在单线程和多线程下执行是没有区别的，即不会有线程安全问题，会降低并发编程带来的风险。 Java 8 里：12345// 声明空集合List&lt;String&gt; emptyList = Collections.emptyList();// 声明一个单个元素的集合List&lt;String&gt; singleItemList = Collections.singletonList(&quot;singleItem&quot;);// 声明一个不可变的集合List&lt;String&gt; unmodifiableList = Collections.unmodifiableList(new ArrayList&lt;&gt;(Arrays.asList(&quot;item1&quot;, &quot;item2&quot;))); Java 9里简化了声明：12345// 声明空集合List&lt;String&gt; emptyList = List.of();// 声明一个单个元素的集合List&lt;String&gt; singleItemList = List.of(&quot;singleItem&quot;);// 声明一个不可变的集合List&lt;String&gt; unmodifiableList = List.of(&quot;item1&quot;, &quot;item2&quot;); 建议通过工厂类进行Collection类的声明。除了更简洁和更好阅读之外，这些方法还可以让开发人员不必为选择特定的集合类实现而“头痛”。事实上，从工厂方法返回的集合实现是根据初始化时输入的元素数量高度优化过的。 新特性10：Try-With-Resources改进在 java 7 以前，程序中使用的资源需要被明确地关闭，这个体验有点繁琐。try-with-resources 语句会确保在 try 语句结束时关闭所有资源。实现了java.lang.AutoCloseable 或 java.io.Closeable 的对象都可以做为资源。 Java 7 之前的文件处理代码1234567891011121314151617private static void printFileBeforeJava7() throws IOException &#123; InputStream input = null; try &#123; input = new FileInputStream(&quot;file.txt&quot;); int data = input.read(); while (data != -1) &#123; System.out.print((char) data); data = input.read(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (input != null) &#123; input.close(); &#125; &#125;&#125; Java 7 或 Java 8里面里的文件处理代码1234567891011121314private static void printFileJava7OrJava8() throws IOException &#123; FileInputStream input = new FileInputStream(&quot;file.txt&quot;) // 注意这里需要重新定义资源 try (FileInputStream newInput = input) &#123; int data = newInput.read(); while (data != -1) &#123; System.out.print((char) data); data = newInput.read(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; Java 9 里的文件处理代码1234567891011121314private static void printFileInJava9() throws IOException &#123; FileInputStream input = new FileInputStream(&quot;file.txt&quot;) // 注意这里不需要重新定义资源 try (input) &#123; int data = input.read(); while (data != -1) &#123; System.out.print((char) data); data = input.read(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 新特性11：多版本JAR当新版本的Java出来时，某个类库的所有用户通常需要几年时间才能切换到这个新版本。这意味着类库必须向后兼容需要支持的最旧版本的Java（例如，在许多情况下为Java 6或7）。这实际上意味着很长一段时间内类库开发者无法在代码中使用Java 9的新功能。多版本JAR功能允许开发人员创建仅在特定Java版本上运行库时使用的类的备用版本： 新建一个工程，打包为JAR 内部结构看起来像这样： 123456789multiVesionJarTest.jar├── META-INF│ └── versions│ └── 9│ └── package│ └── Test.class├── package│ └──Test.class└ └──Main.class Java 8 或更早的版本会在直接使用 package 下面的 Test 类，但新版本会使在 META-INFO/versions 子目录中去找合适的内容来代替默认的，代码更为清爽。 新特性12：响应式流 Reactive StreamsJDK9中的 Flow API 对应响应式流规范，响应式流规范是一种事实标准，目标是使用非阻塞背压方式提供一个标准的异步流处理。 更确切地说，响应式流目的是“找到最小的一组接口，方法和协议，用来描述必要的操作和实体以实现这样的目标：以非阻塞背压方式实现数据的异步流”，更详细的介绍，可参考文章：响应式流Reactive Streams java.util.concurrent.Flow包含的接口如下： Flow.Processor（处理器） Flow.Publisher（发布者） Flow.Subscriber（订阅者） Flow.Subscription（订阅管理器） 下面给一个具体的例子:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import java.util.List;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Flow;import java.util.concurrent.SubmissionPublisher; /** * Created by yves on 2017/11/4. */public class FlowTest &#123; private static final ExecutorService PUBLISHE_EXECUTOR = Executors.newFixedThreadPool(1); private static final int MAX_CAPACITY = 1024; public static void main(String[] args) &#123; // 创建生产者 SubmissionPublisher&lt;String&gt; oracle = new SubmissionPublisher&lt;&gt;(PUBLISHE_EXECUTOR, MAX_CAPACITY); // 创建消费组 StrugglingDeveloper&lt;String&gt; developers = new StrugglingDeveloper&lt;&gt;(); oracle.subscribe(developers); // 发布消息 List.of(&quot;2011年7月7日：Java 7发布了&quot;, &quot;2014年3月19日：Java 8发布了&quot;, &quot;2017年9月21日：Java 9发布了&quot;) .forEach(oracle::submit); oracle.close(); System.out.println(&quot;&lt;Ready to publish item..&gt;&quot;); PUBLISHE_EXECUTOR.submit(() -&gt; &#123; //发布任务结束 &#125;); PUBLISHE_EXECUTOR.shutdownNow(); &#125; static class StrugglingDeveloper&lt;T&gt; implements Flow.Subscriber&lt;T&gt; &#123; @Override public void onSubscribe(Flow.Subscription subscription) &#123; subscription.request(5); System.out.println(&quot;&lt;Start to Receive&gt;&quot;); &#125; @Override public void onNext(T item) &#123; System.out.println(&quot;&lt;Received&gt;:&quot; + item); &#125; @Override public void onError(Throwable t) &#123; t.printStackTrace(); &#125; @Override public void onComplete() &#123; System.out.println(&quot;&lt;onComplete&gt;&quot;); &#125; &#125;&#125; 输出如下：123456&lt;Start to Receive&gt;&lt;Ready to publish item..&gt;&lt;Received&gt;:2011年7月7日：Java 7发布了&lt;Received&gt;:2014年3月19日：Java 8发布了&lt;Received&gt;:2017年9月21日：Java 9发布了&lt;onComplete&gt; 新特性13：代码分段缓存Java 9的另一个性能提升来自于 JIT(Just-in-time) 编译器. 当某段代码被大量重复执行的时候, 虚拟机会把这段代码编译成机器码(native code)并储存在代码缓存里面, 进而通过访问缓存中不同分段的代码来提升编译器的效率。 和原来的单一缓存区域不同的是, 新的代码缓存根据代码自身的生命周期而分为三种: 永驻代码(JVM 内置 / 非方法代码) 短期代码(仅在某些条件下适用的配置性(profiled)代码) 长期代码(非配置性代码) 缓存分段会在各个方面提升程序的性能, 比如做垃圾回收扫描的时候可以直接跳过非方法代码(永驻代码), 从而提升效率 更多内容，请参考：JEP 197: Segmented Code Cache 新特性14：其他新特性 轻量级 JSON API Optional的流式处理 改进的Javadoc（支持搜索 + 支持HTML5） 改进了竞争锁 (JEP 143: Improve Contended Locking)]]></content>
      <tags>
        <tag>jdk9</tag>
        <tag>feature</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm_garbage_collect]]></title>
    <url>%2F2017%2F12%2F20%2Fjvm-garbage-collect%2F</url>
    <content type="text"><![CDATA[Java和C++之间有一堵由内存分配和垃圾回收技术所围成的高墙，在里面的人想出来，不在里面的人想进去。C++程序员必须承担每一个对象生命开始到终结的责任，而Java程序员无须为每一个new 出来的对象执行 delete/free 操作，不容易出现内存泄漏和内存溢出问题。 1. JVM内存模型1.1. 内存结构根据《Java虚拟机规范（Java SE 7版本）》规定，JVM包括下面几个运行时的内存区域： 共分为下面五个部分： 程序计数器：当前线程所执行的字节码的行号指示器； 方法区：方法区用于存储已经被虚拟机加载的类信息、final常量、静态变量、编译器即时编译后的代码等数据； 本地方法栈：执行 Native 方法时的栈存储区域； JVM 虚拟机栈：Java方法执行时的栈帧，存储局部变量表、操作数栈、动态链接、方法接口 等信息； 堆区：所有的对象实例以及数组。 下图是 Hot-Spot 虚拟机的内存划分： 注意： HotSpot虚拟机把本地方法栈和虚拟机栈合二为一； 方法区 ≠ 永久代，后者是HotSpot虚拟机中的特定概念，是分代算法的延伸。 JAVA进程内存 = JVM进程内存 + Heap内存 + 永久代内存 + 本地方法栈内存 + 线程栈内存 + 堆外内存 + Socket 缓冲区内存。 方法区在JDK各个版本中的演进？ 在 Java 6 中，方法区中包含的数据，除了 JIT 编译生成的代码存放在 Native memory 的 CodeCach 区域，其他都存放在永久代； 在 Java 7 中，符号引用迁移至系统内存(Native Memory)，字符串字面量迁移至Java堆(Java Heap)，二者均属于常量池的内容； 在 Java 8 中，永久代被彻底移除，取而代之的是另一块与堆不相连的本地内存——元空间（Metaspace）,‑XX:MaxPermSize 参数失去了意义，取而代之的是-XX:MaxMetaspaceSize。 1.2. 内存溢出程序计数器是JMM中唯一不会发生 OOM 的地方。OOM的种类、根源及解决方法： 堆内存溢出（关键字：OutOfMemoryError，Java heap space） 产生原因：堆中无法存放新的对象，同时垃圾回收机制也无法回收对象； 解决方法：通过Dump内存，明确是内存溢出还是内存泄漏，然后确定方案； 栈内存溢出（关键字：StackOverflowError 或 StackOutOfMemoryError） 产生原因：栈深度大于虚拟机锁允许的最大深度 或 拓展栈时无法申请到足够的内存空间； 解决方法：配置 -Xss 增大栈内存容量，但这会减少工作线程数，因此需要权衡。 方法区溢出（关键字：OutOfMemoryError，PermGen space） 产生原因：常量池溢出或动态生成了大量的Class而未卸载； 解决方法：JDK6 中谨慎使用intern()，卸载不使用的类数据。 2. 垃圾回收策略2.1. 基本概念2.1.1. 关键术语 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行，而垃圾收集程序运行于另一个CPU上。 STW（Stop The World）：在执行垃圾收集算法时，除了垃圾收集线程外，Java应用程序的其他线程都被挂起的现象（Native 代码可以执行）。 引用（Reference）：从JDK 1.2版本开始，把对象的引用分为4种级别，从而使程序能更加灵活地控制对象的生命周期。这4种级别由高到低依次为：强引用、软引用、弱引用和虚引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它，其他的引用类型都会被回收。 2.1.2. 垃圾的定义GC 把程序不用的内存空间视为垃圾, 是管理堆中已分配对象的机制， GC 要做的有两件事： 查找内存中不再使用的对象 释放这些对象占用的内存 怎么确保内存空间已经不被使用？ 引用计数法 可达性分析 2.1.2.1. 引用计数法给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值加1；当引用失效时，计数器减1；任何时刻计数器都为0的对象就是不可能再被使用的。下图为 Python 中通过引用计数法定义的核心结构体。 1234typedef struct_object &#123; int ob_refcnt; struct_typeobject *ob_type;&#125; PyObject; 引用计数算法的实现简单，判断效率也很高，在大部分情况下它都是一个不错的算法。但是Java语言中没有选用引用计数算法来管理内存，其中最主要的一个原因是它很难解决对象之间相互循环引用的问题。Python 就通过通过标记-清除和分代收集两种机制补充引用计数的不足。 2.1.2.2. 可达性分析在主流的商用程序语言中(Java和C#)，都是使用可达性分析算法判断对象是否存活的。这个算法的基本思路是通过一系列名为 GC Roots 的对象作为起始点，从这些根节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到 GC Roots 没有任何引用链相连时，则证明此对象是不可用的，就可以纳入可回收的范围。 在 Java 语言里，可作为 GC Roots 对象的包括如下几种： 虚拟机栈(栈桢中的本地变量表)中的引用的对象； 方法区中的类静态属性引用的对象； 方法区中的常量引用的对象； 本地方法栈中 JNI 的引用的对象。 2.1.3. 垃圾回收的内存区域垃圾回收主要是在回收堆（Heap）内存，下面将详细叙述。 对于属于堆外内存（Non-Heap）的永久代，Java虚拟机规范中没有规定要回收，但是永久代也是需要回收的，不过频率较低，主要做的工作是常量池回收和类型卸载。常量池回收比较简单，通过判断字面量是否有对象引用即可；对于类型卸载，可是通过以下三条规则判断一个类是否是无用的类： 该类所有的实例都已经被回收，也就是java堆中不存在该类的任何实例。 加载该类的ClassLoader已经被回收。 该类对应的java.lang.Class对象没有任何地方被引用，无法在任何地方通过反射访问该类的方法。 使用堆外内存时的注意点? 堆外内存就是把内存对象分配在Java虚拟机的堆以外的内存，包括JVM本身在运行过程中分配的内存，CodeCache，JNI 里分配的内存、DirectByteBuffer 分配的内存等等，这些内存直接受操作系统管理（而不是 JVM ），如 Netty 中使用 java.nio.DirectByteBuffer 创建的内存。 优点：结果就是能够在一定程度上减少垃圾回收对应用程序造成的影响，执行 Flush 到远端的操作时，也节省了复制到直接内存这部分的时间。 缺点：JVM 不会直接管理这些堆外内存，存在 OOM 的风险。可以在 JVM 启动参数里加上 -XX:MaxDirectMemorySize，对可申请的堆外内存大小进行限制（注意：这个参数的配置直接会影响 Full GC 的频率）。不直接管理的含义：JDK 中使用 DirectByteBuffer 对象来表示堆外内存，DirectByteBuffer 对象里持有 Cleaner 对象，后者唯一保存了堆外内存的数据（开始地址、大小和容量。在创建完成后的下一次 FGC 时，Cleaner对象会进行堆外内存的回收。 申请堆外内存时，如果申请的内存大小超出限制，则会调用 System.gc() 以期望触发垃圾回收，并将当前线程 sleep 100毫秒，之后再尝试申请，如果此时申请失败，则抛出 OOM 报错，这种场景多出现在禁用了显式GC（-XX:+DisableExplicitGC）的环境下。 2.1.4. 垃圾回收的分类2.2. 垃圾回收算法2.2.1. 垃圾回收算法性能 吞吐量（Throughput）：应用程序线程用时 / 程序总用时的比例。吞吐量越高，则算法越好。 最大暂停时间（pause times）：因执行 GC 而暂停应用程序线程线程的最长时间。暂停时间越短，则算法越好。 堆使用效率：堆使用效率和吞吐量，以及最大暂停时间不可兼得。简单地说就是：可用的堆越大，GC 运行越快；相反，越想有效地利用有限的堆，GC 花费的时间就越长。 访问的局部性：具有引用关系的对象之间通常很可能存在连续访问的情况。这在多数程序中都很常见，称为“访问的局部性”。考虑到访问的局部性，把具有引用关系的对象安排在堆中较近的位置，就能提高在缓存中读取到想利用的数据的概率，令mutator 高速运行。 高吞吐量和低暂停时间是竞争关系，为了获得最大吞吐量，JVM 必须尽可能少地运行 GC，只有在迫不得已的情况下(比如新生代或者老年代已经满了）才运行GC。但是，推迟运行 GC 的结果是，每次运行GC时需要做的事情会很多，比如有更多的对象积累在堆上等待回收，每次的GC时间会很高，由此引起的平均和最大暂停时间也会很高，这就要求 GC 不能推迟运行的时机。 2.2.2. 常用垃圾回收算法推荐阅读《垃圾回收的算法与实现》这一本书，这里有我的读书笔记：垃圾回收的算法与实现。 标记-清除算法（Mark-Sweep）：GC 标记- 清除算法由标记阶段和清除阶段构成。标记阶段是把所有活动对象都做上标记的阶段。清除阶段是把那些没有标记的对象，也就是非活动对象回收的阶段。通过这两个阶段，就可以令不能利用的内存空间重新得到利用。 标记-压缩算法（Mark-Compact）：GC 标记-压缩算法由标记阶段和压缩阶段构成。标记阶段和 GC 标记-清除算法段完全一样，压缩阶段通过数次搜索堆来重新装填活动对象。压缩阶段并不会改变对象的排列顺序，只是缩小了它们之间的空隙，把它们聚集到了堆的一端。 复制算法（Copying）：GC 复制算法是将可用内存划分为两块区域(通常为相等大小)：From、to，当有新的活动对象加入空闲内存，利用 From 空间进行分配，当From 空间被完全占满时，GC 会将活动对象全部复制到 To 空间。当复制完成后，该算法会把From 空间和 To 空间互换，GC 也就结束了。From 空间和 To 空间大小必须一致。这是为了保证能把 From 空间中的所有活动对象都收纳到 To 空间里。 分代算法(Generational GC)：根据对象的不同生命周期分别管理，HotSpot JVM 中将对象分为我们熟悉的新生代、老年代和永久代分别管理。这样做的好处就是可以根据不同类型对象进行不同策略的管理，例如新生代中对象更新速度快，就会使用效率较高的复制算法。老年代中内存空间相对分配较大，而且时效性不如新生代强，就会常常使用Mark-Sweep-Compact(标记-清除-压缩)算法。 比较前三种算法： 注意：Mark-Compact 与 Copying 都涉及移动对象，但取决于具体算法， Mark-Compact 可能要先计算一次对象的目标地址，然后修正指针，然后再移动对象；Copying 则可以把这几件事情合为一体来做，所以可以快一些。 2.3. 垃圾回收器2.3.1. 垃圾回收器分类垃圾回收算法是垃圾回收的方法论，垃圾回收器是垃圾回收算法的具体实践。Java虚拟机规范中对垃圾回收器该如何实现并没有任何规定，因此不同的厂商、不同的版本虚拟机提供的垃圾回收器都有很大的差别。下图是JDK 7 Update 4中的垃圾回收器。 组合起来有以下几种: Serial + Serial Old (+XX:+UseSerialGC): GC 线程在做事情时, 其他所有的用户线程都必须停止 (即 STW, stop the world)； Serial + CMS: 一般不会这样配合使用； ParNew + CMS (+XX:+UseConcMarkSweepGC): 新生代的 GC 使用 ParNew, 有多个 GC 线程同时进行 Young GC (主要是在多核的环境用多线程效果会好); 而老生代使用 CMS； ParNew + Serial Old (+XX:+UseParNewGC): 新生代用 ParNew 的时候, 也可以选择老生代不用 CMS, 而用 Serial Old, 这个组合也不太常用； Parallel Scavenge + Serial Old (+XX:+UseParallelGC): Parallel Scavenge 收集器的目的是达到一个可控制的吞吐率 (适用于各种计算任务); 这个组合中老生代仍旧使用 Serial Old； Parallel Scavenge + Parallel Old (+XX:+UseParallelOldGC): 新生代使用 Parallel Scavenge, 而 Parallel Old 是老年代版本的 Parallel Scavenge； G1 (-XX:+UseG1GC)：新生代和老年代都使用 G1 垃圾回收器。 垃圾收集器搭配注意事项: CMS 只能配 Serial 或 ParNew；Pa- rallel Scavenge 只能配 Serial Old 或 Parallel Old； Serial 不能配 Parallel Old； UseParallelGC vs. UseParallelOldGC, 如果没有调好配置, UseParallelOldGC 有可能比 UseParallelGC 的性能还要差 (参考)。 2.3.2. 垃圾回收器的选择我应该选用哪一种垃圾回收器？ 客户端程序: 一般使用 -XX:+UseSerialGC (Serial + Serial Old). 特别注意, 当一台机器上起多个 JVM, 每个 JVM 也可以采用这种 GC 组合； 吞吐率优先的服务端程序（eg. 计算密集型）: -XX:+UseParallelGC 或者 -XX:+UseParallelOldGC； 响应时间优先的服务端程序: -XX:+UseConcMarkSweepGC； 响应时间优先同时也要兼顾吞吐率的服务端程序：-XX:+UseG1GC。 2.3.3. 新生代垃圾回收器新生代 GC（Young GC），主要通过复制算法来实现，利用了复制算法时间开销较低的特点。 需要注意，新生代垃圾回收大多数是 STW 的， 停顿时间与 GC 后存活的对象成正比。 2.3.4. 老年代垃圾回收：CMSCMS 全称为 Concurrent Mark Sweep，是现在非常主流的一款老年代的垃圾回收器，CMS 是以牺牲吞吐量为代价来获得最短回收停顿时间的垃圾回收器。对于要求服务器响应速度的应用上，这种垃圾回收器非常适合。在启动JVM参数加上 -XX:+UseConcMarkSweepGC ，这个参数表示对于老年代的回收采用 CMS。 CMS 采用的基础算法是：标记—清除 算法。IBM 的专门研究表明，新生代中的对象98%是朝生夕死的，所以并不需要按照1∶1的比例来划分内存空间，而是将内存分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 和其中的一块 Survivor。当回收时，将 Eden 和 Survivor 中还存活着的对象一次性地拷贝到另外一块 Survivor 空间上，最后清理掉 Eden 和刚才用过的 Survivor 的空间。 2.3.4.1. CMS 的优缺点优点： 并发收集，低停顿时间。缺点： 会产生空间碎片。CMS 垃圾回收器采用的基础算法是 Mark-Sweep，没有内存整理的过程，所以经过 CMS 收集的堆会产生空间碎片。 对CPU资源非常敏感。为了让应用程序不停顿，CMS 线程需要和应用程序线程并发执行，这样就需要有更多的 CPU，同时会使得总吞吐量降低。 需要更大的堆空间。因为 CMS 在标记阶段应用程序的线程还是在执行的，那么就会有堆空间继续分配的情况，为了保证在 CMS 回收完堆之前还有空间分配给正在运行的应用程序，必须预留一部分空间。 2.3.4.2. CMS 执行过程CMS 是老年代垃圾回收算法，老年代回收时，本身不会先进行 Minor GC。因为老年代很多对象都会引用到新生代的对象，我们可以通过配置先进行一次Minor GC，再执行老年代 GC，提高老年代 GC 的速度。比如老年代使用CMS时，设置 CMSScavengeBeforeRemark优化，让CMS remark之前先进行一次Minor GC。CMS 的回收过程主要分为下面的几个步骤： 初始标记(STW initial mark) 并发标记(Concurrent marking) 并发预清理(Concurrent pre-cleaning) 重新标记(STW remark) 并发清理(Concurrent sweeping) 并发重置(Concurrent reset) 2.3.4.2.1. 初始标记初始标记也就是标记一下 GC roots 关联到的对象（并不是所有活动对象），这个过程会出现 STW。注意：CMS 虽然是老年代算法，但也是需要扫描新生代区域的。 2.3.4.2.2. 并发标记并发标记就需要标记出 GC roots 关联到的对象 的引用对象有哪些。比如说 A -&gt; B (A 引用 B，假设 A 是 GC Roots 关联到的对象)，那么这个阶段就是标记出 B 对象， A 对象会在初始标记中标记出来。 2.3.4.2.3. 并发预清理预清理也属于并发处理阶段。这个阶段主要并发查找在做并发标记阶段时从新生代晋升到老年代的对象或老年代新分配的对象(大对象直接进入老年代)或被用户线程更新的对象，来减少重新标记阶段的工作量。如何处理并发阶段被修改了的对象？ 场景：初始标记阶段的引用关系为：A -&gt; B -&gt; C，并发标记时引用关系由用户现场改成了 A -&gt; C，即 B 不再引用 C。由于 C 在并发阶段无法被标记，就会被回收，这样是不允许的。该问题可以通过三色标记算法解决。 三色标记法把 GC 中的对象划分成三种情况： 白色：还没有搜索过的对象（白色对象会被当成垃圾对象） 灰色：正在搜索的对象 黑色：搜索完成的对象（不会当成垃圾对象，不会被 GC） 在初始标记阶段，A 会被标记成灰色（证明现在正在搜索 A 相关的），然后搜索 A 的引用，把 B 变成了灰色，然后 A 就搜索完成了，A 就变成了黑色。在并发标记阶段，如果用户线程不在引用 B 对象，而是变成了 A-&gt;C，此时线程会将 C 这个对象会设置为已标记（把 C 变成灰色），这个过程就称之为写入屏障（ Write Barrier）。伪代码描述如下：1234567write_barrier(obj,field,newobj)&#123; if(newobj.mark == FALSE)&#123; newobj.mark = TRUE push(newobj,$mark_stack) &#125; *field = newobj&#125; 并发预清理阶段可能会出现 Young GC（是否出现 Young GC 由 CMSScheduleRemarkEdenSizeThreshold、CMSScheduleRemarkEdenPenetration、CMSMaxAbortablePrecleanTime 这个三个 GC 参数来保证）。出现老年代引用新生代的对象，GC 怎么处理？JVM采用了 Card Marking(卡片标记)的方法，避免了在做Minor GC时需要对整个老年代扫描。具体的方法：将老年代按照一定大小分片，每一片对应 Cards中的一项，如果老年代老年代的对象发生了修改，或者老年代对象指向了新生代对象，就把这个老年代对象所在的 Card 标记为脏 dirty。Young GC 时，dirty card 加入待扫描的 GC Roots 范围，避免扫描整个老年代。 2.3.4.2.4. 重新标记重新标记是干什么的呢？就是由于在并发标记和并发预清理这个阶段，用户线程和GC 线程并发，假如这个阶段用户线程产生了新的对象，总不能被 GC 掉吧。这个阶段就是为了让这些对象重新标记。这个过程会出现 STW，所有用户线程会暂停工作，GC 线程重新扫描堆中的对象，进行可达性分析，标记活着的对象。 2.3.4.2.5. 并发清理这个阶段的目的就是移除那些不用的对象，回收他们占用的空间并且为将来使用。注意这个阶段会产生新的垃圾，新的垃圾在此次GC无法清除，只能等到下次清理。这些垃圾有个专业名词：浮动垃圾。 2.3.4.2.6. 并发重置这个阶段并发执行，重新设置 CMS 算法内部的数据结构，准备下一个 CMS 生命周期的使用。 2.3.4.3. CMS 触发条件注意分为下面两类： 如果应用主动请求 GC，直接触发； 是否设置 UseCMSInitiatingOccupancyOnly； 没有设置 UseCMSInitiatingOccupancyOnly 统计开启（stats.valid），统计的cms完成时间小于cms剩余空间被填满的时间，则触发； 统计不可用，（第一次没有统计信息，!stats.valid)，年老代大于 _bootstrap_occupancy，则触发； 设置 UseCMSInitiatingOccupancyOnly 根据指定年老代的判断逻辑 should_concurrent_collect，true 则触发； 根据增量模式收集是否失败，incremental_collection_will_fail，true 则触发； 根据元数据区的判断逻辑 should_concurrent_collect，true 则触发； 最后根据触发间隔(CMSTriggerInterval，默认为-1，所以一般不走这个逻辑); should_concurrent_collect的逻辑实现 判断occupancy是否大于init_occupancy，大于则触发； 如果设置了UseCMSInitiatingOccupancyOnly，直接返回，不再继续后面逻辑； 2.3.4.4. CMS 降级当 CMS 进行并发操作时，如果剩余的内存已经无法满足用户线程（ 比如 执行CMS 的阈值为 90%堆内存，假设这个时候用户线程需要 20% 的内存）了，此时老年代垃圾回收器自动降级为 Serial Old，这个时候你会在 GC 日志里看到 Concurrent Mode Failure。串行回收时，会出现 STW，也就不存在垃圾持续增长的问题了。 2.3.4.5. CMS 调优参数这里介绍几个重要的调优参数，更详细的参数请参考 CMS 描述文档。-XX:CMSInitiatingOccupancyFraction=70 该值代表老年代堆空间的使用率，默认值是92。比如，value=70 意味着第一次 CMS 垃圾收集会在老年代被占用 70% 时被触发，该数字为经验值。 -XX:+UseCMSCompactAtFullCollection-XX:CMSFullGCsBeforeCompaction=4 上面两个参数表示执行4次不压缩的 Full GC 后，会执行一次内存压缩的过程，用来消除 CMS 引入的空间碎片。 -XX:+CMSScavengeBeforeRemark 使用上述参数，会在重新标记阶段前强制进行一次 Young GC。 *-XX：ConcGCThreads 定义并发 CMS 过程运行时的线程数。CMS 默认的回收线程数是( CPU 个数+3)/4，意思是当 CPU 大于4个时,保证回收线程占用至少25%的 CPU 资源，这样用户线程占用75%的 CPU。更多的线程会加快并发 CMS 过程，但其也会带来额外的同步开销。 一些简单的调优策略：新生代优化: Young GC 频率高 -&gt; 增大新生代 Young GC 时间长 -&gt; 减小新生代老年代优化： 尽量避免内存整理，整理会 STW，可以通过优化新生代到老生代的提升率事项； 设置合理的 -XX:CMSInitiatingOccupancyFraction=n 值，过大或让 STW 时间变长，过小会影响吞吐率。 一个原则：尽量让 Young GC 回收大部分的垃圾。 2.3.5. 全局垃圾回收器：G1 Garbage First（G1）的设计初衷是，以更高的计算成本为代价最小化 STW 中断时间。通常来说，限制 GC 中断时间比最大化吞吐量更重要。对大部分用户而言，与面向吞吐量的收集器相比（如并行垃圾收集器），切换到中断时间短的垃圾收集器（如 G1），可以获得更好的整体体验。在Java9里，G1 已经成为了默认的垃圾回收器。 CMS 算法中，GC 管理的内存被划分为新生代、老年代和永久代/元空间。这些空间必须是地址连续的。在G1算法中，采用了另外一种完全不同的方式组织堆内存，堆内存被划分为多个大小相等的内存块（Region），每个Region是逻辑连续的一段内存，Region的大小可以通过 -XX:G1HeapRegionSize 参数指定，如果没有设置，默认把堆内存按照2048份均分，最后得到一个合理的大小。 在G1中，还有一种特殊的区域，叫 Humongous 区域。 如果一个对象占用的空间超过了分区容量 50% 以上，G1 收集器就认为这是一个巨型对象。这些巨型对象，默认直接会被分配在年老代，但是如果它是一个短期存在的巨型对象，就会对垃圾收集器造成负面影响。为了解决这个问题，G1 划分了一个 Humongous 区，它用来专门存放巨型对象。 2.3.5.1. G1 的优缺点G1 和 CMS相比，有一些显而易见的优点。 简单可行的性能调优：使用 -XX:+UseG1GC -Xmx32g 这两个参数就可以用于生产环境的 Java 应用（使用-XX:MaxGCPauseMillis=n设置期望的暂停时间）。 取消了老年代的物理空间划分，无需对每个代进行空间大小的设置。 只不过不过，目前 G1 垃圾回收器存在使用场景的限制： 许多公开的基准测试都表明，在内存占用相对较小的应用程序中，CMS 的性能往往要胜过 G1，这与 Oracle 对G1的描述一致，即 G1 适用于堆大小为6GB及以上的服务器应用程序。 Elasticsearch 社区的建议： 像 Elasticsearch 这样低延迟需求的软件的最佳垃圾收集器。官方建议使用 CMS。Lucene 的测试套件表明 G1 GC 一直都无法完全胜任测试场景下的 GC 工作(Don’t Touch These Settings)。 JVM 大佬 RednaxelaFX: 其实CMS在较小的堆、合适的workload的条件下暂停时间可以很轻松的短于G1。在2011年的时候Ramki告诉我堆大小的分水岭大概在10GB～15GB左右：以下的-Xmx更适合CMS，以上的才适合试用G1。现在到了2014年，G1的实现经过一定调优，大概在6GB～8GB也可以跟CMS有一比，我之前见过有在-Xmx4g的环境里G1比CMS的暂停时间更短的案例。 2.3.5.2. G1 执行过程G1 垃圾收集器会执行一个全局的并发标记阶段来决定堆中的对象的活跃度。之后标记阶段就完成了。G1 收集器知道哪个区域基本上是空的。它首先会收集那些产出大量空闲空间的区域。这就是为什么这个垃圾收集的方法叫做垃圾优先的原因。 有若干介绍 G1 执行垃圾回收过程博客，大多数作者是将其与 CMS 的垃圾回收过程做了类比，即分为了6个阶段（Phase），个人认为这样是不太合适的。比较 CMS 是一个老年代的垃圾回收期，而 G1 的回收，同时涉及到了新生代和老年代。在这里我采用 RednaxelaFX 的解释来叙述 G1 的垃圾回收过程。 从全局来看看，G1垃圾回收可以分为两大部分： 全局并发标记（Global Concurrent Marking） 拷贝存活对象（Evacuation） 2.3.5.2.1. Global Concurrent MarkingGlobal Concurrent Marking 是基于 SATB 形式的并发标记，SATB（snapshot-at-the-beginning）是一种比CMS收集器更快的算法。Global Concurrent Marking 具体分为下面几个阶段： 初始标记（STW initial marking）：扫描根集合，标记所有从根集合可直接到达的对象并将它们的字段压入扫描栈。在分代式G1模式中，初始标记阶段借用 Young GC 的暂停，因而没有额外的、单独的暂停阶段。 并发标记（concrrent marking）：这个阶段可以并发执行，GC 线程 不断从扫描栈取出引用，进行递归标记，直到扫描栈清空。 最终标记（STW final marking，在实现中也叫Remarking）：重新标记写入屏障（ Write Barrier）标记的对象，这个阶段也进行弱引用处理（reference processing）。 清理（STW cleanup）：统计每个 Region 被标记为活的对象有多少，如果发现完全没有活对象的 Region 就会将其整体回收到可分配 Region 列表中。 2.3.5.2.2. EvacuationEvacuation阶段是全暂停的。它负责把一部分 Region 里的活对象拷贝到空 Region 里去，然后回收原本的 Region 的空间。 2.3.5.3. G1 分代回收可以分为 Young GC 和 Mixed GC 两种类型： Young GC：选定所有 新生代 里的 Region 。通过控制 新生代 的 Region 个数来控制 Young GC 的开销。 Mixed GC：选定所有 新生代 里的 Region ，外加根据 Global Concurrent Marking 统计得出收集收益高的若干老年代 Region 。在用户指定的开销目标范围内尽可能选择收益高的老年代 Region 。分代式 G1 的正常工作流程就是在 Young GC 与 Mixed GC之间视情况切换，背后定期做做全局并发标记。Initial marking 默认搭在 Young GC 上执行；当全局并发标记正在工作时，G1 不会选择做 Mixed GC，反之如果有 Mixed GC 正在进行中 G1 也不会启动 initial marking。同 CMS 一样，当所有 Eden Region 被耗尽无法申请内存时，Young GC 就会被触发。一个假想的混合的STW时间线：123456789101112131415161718-&gt; young GC-&gt; young GC-&gt; young GC-&gt; young GC + initial marking(... concurrent marking ...)-&gt; young GC (... concurrent marking ...)(... concurrent marking ...)-&gt; young GC (... concurrent marking ...)-&gt; final marking-&gt; cleanup-&gt; mixed GC-&gt; mixed GC-&gt; mixed GC...-&gt; mixed GC-&gt; young GC + initial marking(... concurrent marking ...)... 注意：G1 里不存在Full GC，在正常工作流程中没有 Full GC 的概念，老年代的收集全靠 Mixed GC 来完成，当 Region 无法继续分配对象后，G1 将会 退化成 Serial old 。 2.3.5.4. G1 调优参数-XX:MaxGCPauseMillis=n 设置垃圾收集暂停时间最大值指标，注意这个目标不一定能满足，Java虚拟机将尽最大努力实现它，不建议设置得过小（ &lt; 50ms ）;-XX:InitiatingHeapOccupancyPercent=n 触发并发垃圾收集周期的整个堆空间的占用比例。 最佳实践1：不要设置新生代的大小通过 -Xmn 显式地设置新生代大小会干扰 G1 的垃圾回收策略： 设置的最大暂停时间指标将不再有效，事实上，设置新生代大小后，将不会启用暂停时间目标。 G1收集器将不能按需调整新生代的大小空间。 最佳实践2：避免晋升失败带来的副作用晋升失败后，如果此时 JVM 堆内存也耗尽了，就会 出现 Evacuation Failure，在 GC 日志里将会看到 to-space overflow 的日志。 Evacuation Failure 的开销是巨大的，为了避免这种情况，可以执行下面的步骤： 增加 -XX:G1ReservePercent 选项的值（并相应增加总的堆大小），为“目标空间”增加预留内存量； 通过减少 -XX:InitiatingHeapOccupancyPercent 提前启动标记周期。 通过设置 -XX:ConcGCThreads=n 增加并行标记线程的数量； 2.3.6. 易混淆的概念CMS 和 G1 启动 GC 的时机？ 对于 CMS，配置 -XX:CMSInitiatingOccupancyFraction=n 即可，注意这这里的n表示垃圾对象在老年代的空间占比。 对于G1，配置 -XX:InitiatingHeapOccupancyPercent=n，表示垃圾对象在整个G1堆内存的空间占比（Mixed GC）。 什么时间会出现 Full GC？对于CMS垃圾回收器： Concurrent-mode-failure：当 CMS GC 正进行时，此时有新的对象要进行老年代，但是老年代空间不足造成的； Promotion-failed：当进行 Young GC 时，有部分新生代代对象仍然可用，但是S0或S1放不下，因此需要放到老年代，但此时老年代空间无法容纳这些对象。 对于 G1 垃圾回收器： 如果 Mixed GC 实在无法跟上程序分配内存的速度，导致老年代填满无法继续进行 Mixed GC，就会切换到 G1之外的 Serial old GC 来收集整个GC Heap（注意，包括young、old、perm），所以，对于 正常工作的G1 垃圾回收期是不能存在Full GC，如果真出现了，估计就很悲剧了，毕竟单线程 + 大内存 + 整个堆，时间开销可想而知。 Full GC、Magjor GC、Minor GC、Young GC、Old GC 之间的关系？ Minor GC == Young GC ，只回收新生代的空间；Old GC是回收老年代的GC；Major GC指的是对老年代/永久代的 STW 的 GC; Full GC 是针对整个新生代、老生代、元空间（metaspace，java8以上版本取代 perm gen）的全局范围的GC，是一种不正常的 GC 活动； Jstat 命令里的 FGCC、FGCT： 统计的数据里：Full GC的次数 = 老年代GC时 STW 的次数，Full GC的时间 = 老年代GC时 stop the world 的总时间; CMS 不等于Full GC，我们可以看到 CMS 分为多个阶段，只有 STW 的阶段被计算到了Full GC 的次数和时间，而和业务线程并发的 GC 的次数和时间则不被认为是 Full GC; 2.4. JVM调优步骤完成一个JVM的性能测试，了解程序当前的状态，确定瓶颈点；明确调优的目标，比如减少 FULL GC 的次数、降低暂停的时间、提高吞吐量等、减少GC的总时间等；调整参数后再进行多次的测试、分析、对比，最终达到一个较为理想的状态，各种参数要根据场景选择，没有统一的解决方案。 3. 推荐阅读垃圾回收的算法与实现深入理解Java虚拟机请教G1算法的原理(R大的回答)Getting Started with the G1 Garbage Collector]]></content>
  </entry>
  <entry>
    <title><![CDATA[Longest-Palindromic-Substring]]></title>
    <url>%2F2017%2F10%2F18%2FLongest-Palindromic-Substring%2F</url>
    <content type="text"><![CDATA[SummaryThis article is for intermediate readers. It introduces the following ideas:Palindrome, Dynamic Programming and String Manipulation. Make sure you understand what a palindrome means. A palindrome is a string which reads the same in both directions. For example, ”aba” is a palindome, ”abc” is not. Solution Approach #1 (Longest Common Substring) [Accepted]Common mistake Some people will be tempted to come up with a quick solution, which is unfortunately flawed (however can be corrected easily): Reverse S and become S​′​​. Find the longest common substring between S and S​′​​, which must also be the longest palindromic substring. This seemed to work, let’s see some examples below. For example, S=”caba”, S​′​​=”abac”. The longest common substring between S and S​′​​ is ”aba”, which is the answer. Let’s try another example: S=”abacdfgdcaba”, S​′​​=”abacdgfdcaba”. The longest common substring between S and S​′​​ is ”abacd”. Clearly, this is not a valid palindrome. Algorithm We could see that the longest common substring method fails when there exists a reversed copy of a non-palindromic substring in some other part of S. To rectify this, each time we find a longest common substring candidate, we check if the substring’s indices are the same as the reversed substring’s original indices. If it is, then we attempt to update the longest palindrome found so far; if not, we skip this and find the next candidate. This gives us an $O(n​^2​​)$ Dynamic Programming solution which uses $O(n​​^2​)$ space (could be improved to use $O(n)$ space). Please read more about Longest Common Substring here. Approach #2 (Brute Force) [Time Limit Exceeded]The obvious brute force solution is to pick all possible starting and ending positions for a substring, and verify if it is a palindrome. Complexity Analysis Time complexity : $O(n​^3​​)$. Assume that n is the length of the input string, there are a total of $\binom{n}{2} = \frac{n(n-1)}{2}$ such substrings (excluding the trivial solution where a character itself is a palindrome). Since verifying each substring takes $O(n)$ time, the run time complexity is $O(n^3)$. Space complexity : $O(1)$. Approach #3 (Dynamic Programming) [Accepted]To improve over the brute force solution, we first observe how we can avoid unnecessary re-computation while validating palindromes. Consider the case ”ababa”. If we already knew that ”bab” is a palindrome, it is obvious that ”ababa” must be a palindrome since the two left and right end letters are the same. We define P(i,j) as following: $$f(n) =\begin{cases}true, &amp; \text{if the substring $S_i…S_j$ is a palindrome}\\false, &amp; \text{otherwise}\end{cases}$$ Therefore, $$P(i, j) = (P(i+1,j−1) and S_i==S_j)$$ The base cases are: $$P(i, i) = true$$ $$P(i, i+1) = (S_i == S_{i+1})$$ This yields a straight forward DP solution, which we first initialize the one and two letters palindromes, and work our way up finding all three letters palindromes, and so on… Complexity Analysis Time complexity : $O(n^2)$. This gives us a runtime complexity of O(n​2​^​). Space complexity : O(n^​2​​). It uses O(n^​2​​) space to store the table. Additional Exercise Could you improve the above space complexity further and how? Approach #4 (Expand Around Center) [Accepted]In fact, we could solve it in $O(n^2)$ time using only constant space. We observe that a palindrome mirrors around its center. Therefore, a palindrome can be expanded from its center, and there are only 2n−12n - 12n−1 such centers. You might be asking why there are 2n−12n - 12n−1 but not nnn centers? The reason is the center of a palindrome can be in between two letters. Such palindromes have even number of letters (such as ”abba”\textrm{‘’abba’’}”abba”) and its center are between the two ’b’\textrm{‘b’}’b’s. 123456789101112131415161718192021public StringlongestPalindrome(String s)&#123;int start =0, end = 0; for (int i = 0; i &lt; s.length(); i++) &#123; int len1 = expandAroundCenter(s, i, i); int len2 = expandAroundCenter(s, i, i + 1); int len = Math.max(len1, len2); if (len &gt; end - start) &#123; start = i - (len - 1) / 2; end = i + len / 2; &#125; &#125; return s.substring(start, end + 1);&#125;private int expandAroundCenter(String s, int left, int right) &#123; int L = left, R = right; while (L &gt;= 0 &amp;&amp; R &lt; s.length() &amp;&amp; s.charAt(L) == s.charAt(R)) &#123; L--; R++; &#125; return R - L - 1;&#125; Complexity Analysis Time complexity : O(n2)O(n^2)O(n​2​​). Since expanding a palindrome around its center could take O(n)O(n)O(n) time, the overall complexity is O(n2)O(n^2)O(n​2​​). Space complexity : O(1)O(1)O(1). Approach #5 (Manacher’s Algorithm) [Accepted]There is even an O(n)O(n)O(n) algorithm called Manacher’s algorithm, explained here in detail. However, it is a non-trivial algorithm, and no one expects you to come up with this algorithm in a 45 minutes coding session. But, please go ahead and understand it, I promise it will be a lot of fun.]]></content>
      <tags>
        <tag>-- algo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo命令]]></title>
    <url>%2F2017%2F10%2F08%2Fhexo-common-command%2F</url>
    <content type="text"><![CDATA[引用参考:hexo常用命令笔记 hexonpm install hexo -g # 安装 npm update hexo -g # 升级 hexo init # 初始化 简写hexo n &quot;我的博客&quot; == hexo new &quot;我的博客&quot; #新建文章hexo p == hexo publishhexo g == hexo generate # 生成hexo s == hexo server # 启动服务预览hexo d == hexo deploy # 部署 服务器hexo server # Hexo 会监视文件变动并自动更新，您无须重启服务器。 hexo server -s # 静态模式 hexo server -p 5000 # 更改端口 hexo server -i 192.168.1.1 # 自定义 IP hexo clean # 清除缓存 网页正常情况下可以忽略此条命令 hexo g # 生成静态网页 hexo d # 开始部署 监视文件变动hexo generate # 使用 Hexo 生成静态文件快速而且简单 hexo generate --watch # 监视文件变动 完成后部署generate deploy先后顺序可以调换，功能相同 hexo generate --deploy hexo deploy --generate hexo deploy -g hexo server -g 草稿hexo publish [layout] &lt;title&gt; 模版hexo new &quot;postName&quot; # 新建文章 hexo new page &quot;pageName&quot; # 新建页面 hexo generate # 生成静态页面至public目录 hexo server # 开启预览访问端口（默认端口4000，&apos;ctrl + c&apos;关闭server） hexo deploy # 将.deploy目录部署到GitHub hexo new [layout] &lt;title&gt; hexo new photo &quot;My Gallery&quot; hexo new &quot;Hello World&quot; --lang tw 变量 描述 layout 布局 title 标题 date 文件建立日期 title: 使用Hexo搭建个人博客 layout: post date: 2014-03-03 19:07:43 comments: true categories: Blog tags: [Hexo] keywords: Hexo, Blog description: 生命在于折腾，又把博客折腾到Hexo了。给Hexo点赞。 模版（Scaffold）hexo new photo &quot;My Gallery&quot; 变量 描述 layout 布局 title 标题 date 文件建立日期 设置文章摘要以上是文章摘要 &lt;!--more--&gt; 以下是余下全文 写作hexo new page &lt;title&gt; hexo new post &lt;title&gt; 变量 描述 :title 标题 :year 建立的年份（4 位数） :month 建立的月份（2 位数） :i_month 建立的月份（去掉开头的零） :day 建立的日期（2 位数） :i_day 建立的日期（去掉开头的零） 推送到服务器上hexo n # 写文章 hexo g # 生成 hexo d # 部署 可与hexo g合并为 hexo d -g]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[algo-graph-theory-shortest-path]]></title>
    <url>%2F2017%2F10%2F08%2Falgo-graph-theory-shortest-path%2F</url>
    <content type="text"><![CDATA[最短路径算法 深度、广度优先搜索算法 弗洛伊德算法 迪杰斯特拉算法 Bellman-Ford算法 名词边：(u,v)边上的代价或值：ci,j 深度、广度优先搜索算法（解决单元最短路径问题）从起始结点（单源）开始访问所有的深度或广度优先路径，则到达终点结点的路径有多条，取其中路径权值最短的一条则为最短路径（取源点到终点间最短路径） 弗洛伊德算法（解决多源最短路径）时间复杂度O($n^3$),空间复杂度O($n^2$) 测试文本 $F_{\mu}$]]></content>
      <tags>
        <tag>algo</tag>
        <tag>shortest path</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[algo-mst]]></title>
    <url>%2F2017%2F10%2F08%2Falgo-mst%2F</url>
    <content type="text"><![CDATA[PrimKruskal]]></content>
      <tags>
        <tag>algo</tag>
        <tag>mst</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法名词]]></title>
    <url>%2F2017%2F08%2F07%2Falgo-phrase%2F</url>
    <content type="text"><![CDATA[名词常规算法分治 Divide and Conqeuer （DC）动态规划 Dynamic Programming （DP）贪心 Greedy Algoritym （GA）数据缓存 Memorization 树二叉查找树 Binary Search Tree (BST)：是一棵二叉树，每个节点都大于其左子树的任意节点的键，且小于右子树的任意节点的键（投影到同一条直线上，是有序的；中根遍历是有序的） 其他快速傅里叶变化 Fast Fourier Transform（FFT）：将多项式相乘的计算时间有O(n^2)变为O(nlogn) 测试的内容 VSAVL树，红黑树，B树，B+树，Trie树AVL是一种高度平衡的二叉树，所以通常的结果是，维护这种高度平衡所付出的代价比从中获得的效率收益还大，故而实际的应用不多，更多的地方是用追求局部而不是非常严格整体平衡的红黑树。当然，如果场景中对插入删除不频繁，只是对查找特别有要求，AVL还是优于红黑的。红黑树的应用就很多了，除了上面同学提到的STL，还有 著名的linux进程调度Completely Fair Scheduler,用红黑树管理进程控制块 epoll在内核中的实现，用红黑树管理事件块 nginx中，用红黑树管理timer等 Java的TreeMap实现 B和B+主要用在文件系统以及数据库中做索引等，比如Mysql：B-Tree Index in MySqltrie 树的一个典型应用是前缀匹配，比如下面这个很常见的场景，在我们输入时，搜索引擎会给予提示；还有比如IP选路，也是前缀匹配，一定程度会用到trie]]></content>
      <tags>
        <tag>算法</tag>
        <tag>algo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最优化问题 (DC, DP, GA)]]></title>
    <url>%2F2017%2F08%2F05%2Fdynamic-programming%2F</url>
    <content type="text"><![CDATA[Divide Conquer (DC) , Dynamic Programming (DP), Greedy Algorithm (GA)定义、关联、差别 最优化问题递归 Divide Conquer (DC)动态规划 Dynamic Programming (DP)动态规划(dynamic programming)是 运筹学 的一个分支，是求解决策过程(decision process)最优化的数学方法。通常应用于最优化问题此类问题通常有多种可行解，希望找出多个解中的最优（最大或最小）解(an optimal solution)。DP = Divide and Conquer + Memorization（programming指规划，而非写计算机代码） 前提条件 最优子结构和子问题重叠 DP算法设计 描述最优解的结构 递归定义最优解的值 按照自底向上的方式，计算最优解的值（DC是自顶向下） 由计算出的结果构造一个最优解 DP 分类线性动规拦截导弹，合唱队形，挖地雷，建学校，剑客决斗等； 区域动规石子合并， 加分二叉树，统计单词个数，炮兵布阵等； 树形动规贪吃的九头龙，二分查找树，聚会的欢乐，数字三角形等； 背包问题01背包问题，完全背包问题，分组背包问题，二维背包，装箱问题，挤牛奶（同济ACM第1132题）等 概念意义动态规划问世以来，在经济管理、生产调度、工程技术和最优控制等方面得到了广泛的应用。例如最短路线、库存管理、资源分配、设备更新、排序、装载等问题，用动态规划方法比用其它方法求解更为方便。虽然动态规划主要用于求解以时间划分阶段的动态过程的优化问题，但是一些与时间无关的静态规划(如线性规划、非线性规划)，只要人为地引进时间因素，把它视为多阶段决策过程，也可以用动态规划方法方便地求解。动态规划程序设计是对解最优化问题的一种途径、一种方法，而不是一种特殊算法。不像搜索或数值计算那样，具有一个标准的数学表达式和明确清晰的解题方法。动态规划程序设计往往是针对一种最优化问题，由于各种问题的性质不同，确定最优解的条件也互不相同，因而动态规划的设计方法对不同的问题，有各具特色的解题方法，而不存在一种万能的动态规划算法，可以解决各类最优化问题。因此读者在学习时，除了要对基本概念和方法正确理解外，必须具体问题具体分析处理，以丰富的想象力去建立模型，用创造性的技巧去求解。我们也可以通过对若干有代表性的问题的动态规划算法进行分析、讨论，逐渐学会并掌握这一设计方法。 贪心算法 Greedy Algorithm (GA)使所做的选择当前看起来都是最佳的，期望通过所做的局部最优解产生一个全局最优解贪婪不是“只顾眼前利益的贪婪”，而是“看穿一切，一往无前的气魄”。 关联与差别DC vs DPDC 将原问题划分为独立的子问题，递归的求解子问题的解DP 子问题不是独立的，子问题又依赖子子问题（如果使用DC会有重复计算） DP vs GA在使用 GA 前，首先考虑 DP ；证明总能通过GA的选择得到最优解； 贪婪是优化了选择的策略，而非与动态规划背道而驰，Greedy算法仅仅是动态规划的一个平凡态罢了 动态规划的执行过程是什么每次决策依赖当前状态，又随即引起状态转移 DP = Divide and Conquer + Memoization DP 可視做是 Divide and Conquer 的延伸版本。當運用 Divide and Conquer 所遞迴分割出來的子問題都非常相像的時候，並且當同樣的子問題一而再、再而三出現的時候──就運用 Memoization 儲存全部子問題的答案，節省重複計算相同問題的時間，以空間來換取時間。 a method for solving a complex problem by breaking it down into a collection of simpler subproblems, solving each of those subproblems just once, and storing their solutions. The next time the same subproblem occurs, instead of recomputing its solution, one simply looks up the previously computed solution, thereby saving computation time at the expense of a (hopefully) modest expenditure in storage space. (Each of the subproblem solutions is indexed in some way, typically based on the values of its input parameters, so as to facilitate its lookup.) The technique of storing solutions to subproblems instead of recomputing them is called “memoization”. (引用自 wikipedia ) 动态规划 VS 分治适合于用动态规划法求解的问题，经分解后得到的子问题往往不是互相独立的（即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解（重用中间结果） 矩阵动态规划的精髓所在：一个问题的解依附于其子问题的解 动态规划利用低阶数据的性质，使其具体表现为二位矩阵 对比已证明的贪婪算法、未证明的贪婪算法（GA, Greedy Algorithm），动态规划（DP, Dynamic Programming），暴力搜索Greedy ⊂ DP ⊂ Searching 多维解空间和不完全贪心 很多时候，问题的解空间并不适合用一维来描述，当解空间在一维以上，比如……还记得经典的0-1背包问题么？那就是一个典型的二维解空间问题。 贪心算法与动态规划的效率区别从动态规划优化到贪心算法真的提高了算法效率吗？未必。这取决于动态规划中计算所有可选的策略的代价，如果代价是常数的，那么将其贪心优化并不会带来时间复杂度的下降（本文的两个例子都是如此），该走的解空间还是要走，只是不保存其中的一些值而已，可能会带来空间复杂度的下降。有趣的是，当计算策略的代价并非常数（如Floyd全局最短路算法）时，往往并不只有一个策略，因而不能贪心优化。因此，贪心算法不会降低从其对应的动态规划解法的时间复杂度，如果你发现它降低了，那么一定存在更好的解空间建模，更好的动态规划算法。 贪心算法确实可能比其对应的动态规划快不少，因为它的常数可能小得多。但是，当你试图对同一解空间的不同点进行多次查询时，你会发现贪心可能会得不偿失，在均摊时间上输给不贪心的动态规划。 贪心优化是否失去了什么贪心在于其抛弃了部分子结构的解。 如顺带要求出方案而不仅仅是最大价值的0-1背包问题，本来使用不优化空间的解法完全能够保留倒推回去的线索，如PAT 1068 Find More Coins 解题报告 所说一般。如果抛弃了动态规划带来的一些解，很有可能在其衍生的问题上得不偿失。 NPC问题NP问题(Non-deterministic Polynomial )：多项式复杂程度的非确定性问题，这些问题无法根据公式直接地计算出来。比如，找大质数的问题（有没有一个公式，你一套公式，就可以一步步推算出来，下一个质数应该是多少呢？这样的公式是没有的）；再比如，大的合数分解质因数的问题（有没有一个公式，把合数代进去，就直接可以算出，它的因子各自是多少？也没有这样的公式）。 NPC问题(Non-deterministic Polynomial complete)：NP完全问题，可以这么认为，这种问题只有把解域里面的所有可能都穷举了之后才能得出答案，这样的问题是NP里面最难，但是这样算法的复杂程度，是指数关系。一般说来，如果要证明一个问题是NPC问题的话，可以拿已经是NPC问题的一个问题经过多项式时间的变化变成所需要证明的问题，那么所要证明的问题就是一个NPC问题了。NPC问题是一个问题族，如果里面任意一个问题有了多项式的解，即找到一个算法，那么所有的问题都可以有多项式的解。 著名的NPC问题： 背包问题（Knapsack problem）：01背包是在M件物品取出若干件放在空间为W的背包里，每件物品的体积为W1，W2……Wn，与之相对应的价值为V1,V2……Vn。求出获得最大价值的方案。 旅行商问题（Traveling Saleman Problem，TSP），该问题是在寻求单一旅行者由起点出发，通过所有给定的需求点之后，最后再回到原点的最小路径成本。 哈密顿路径问题（Hamiltonian path problem）与哈密顿环路问题（Hamiltonian cycle problem）为旅行推销员问题的特殊案例。哈密顿图：由指定的起点前往指定的终点，途中经过所有其他节点且只经过一次。 欧拉回路（从图的某一个顶点出发，图中每条边走且仅走一次，最后回到出发点；如果这样的回路存在，则称之为欧拉回路。）与欧拉路径（从图的某一个顶点出发，图中每条边走且仅走一次，最后到达某一个点；如果这样的路径存在，则称之为欧拉路径。） 无向图欧拉回路存在条件：所有顶点的度数均为偶数。无向图欧拉路径存在条件：至多有两个顶点的度数为奇数，其他顶点的度数均为偶数。有向图欧拉回路存在条件：所有顶点的入度和出度相等。有向图欧拉路径存在条件：至多有两个顶点的入度和出度绝对值差1（若有两个这样的顶点，则必须其中一个出度大于入度，另一个入度大于出度）,其他顶点的入度与出度相等。]]></content>
      <tags>
        <tag>算法</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python vs Java]]></title>
    <url>%2F2017%2F05%2F30%2Fpython-vs-java%2F</url>
    <content type="text"><![CDATA[静态语言 和 动态语言 鸭子类型并不要求严格的继承体系，一个对象只要“看起来像鸭子，走起路来像鸭子”，那它就可以被看做是鸭子。 静态语言Java，如果需要传入Animal类型，则传入的对象必须是Animal类型或者它的子类。动态语言python，不一定传入Animal类型，只需要保证其中有run方法即可1234567891011class Animal(object): def run(self): print(&apos;Animal is running...&apos;)def run_twice(animal): animal.run() animal.run()class Timer(object): def run(self): print(&apos;Start...&apos;)]]></content>
      <tags>
        <tag>java</tag>
        <tag>python</tag>
        <tag>vs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django数据库]]></title>
    <url>%2F2017%2F05%2F28%2Fdjango-db%2F</url>
    <content type="text"><![CDATA[the three-step guide to making model changes Change your models (in models.py). Run python manage.py makemigrations to create migrations for those changes Run python manage.py migrate to apply those changes to the database.]]></content>
      <tags>
        <tag>python</tag>
        <tag>django</tag>
        <tag>orm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django Index]]></title>
    <url>%2F2017%2F05%2F24%2Fpython-Django%2F</url>
    <content type="text"><![CDATA[QApython3 &amp; mysql connectorMySQLdb并不支持该版本的Python3，可以使用pymysql替换替换方法：-- __init__.py中增加以下代码 import pymysql pymysql.install_as_MySQLdb() INDEXThe Python Package Index (PyPI)ORM python modulepython curses（ibm）python curses使用]]></content>
      <tags>
        <tag>python</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础语法]]></title>
    <url>%2F2017%2F05%2F23%2Fpython-phrase%2F</url>
    <content type="text"><![CDATA[mark下 入门贴 python 与 机器学习 python 3.x 基础学习资料 python3 改变urlparse.urljoinpython3对urllib和urllib2进行了重构，拆分成了urllib.request, urllib.response, urllib.parse, urllib.error等几个子模块 对比java python中没有类似java中的interface的概念 list 常用操作[] list 操作符 表达式 结果 描述 len([1, 2, 3]) 3 长度 [1, 2, 3] + [4, 5, 6] [1, 2, 3, 4, 5, 6] 组合 [&#39;Hi!&#39;] * 4 [‘Hi!’, ‘Hi!’, ‘Hi!’, ‘Hi!’] 重复 3 in [1, 2, 3] True 元素是否存在于列表中 for x in [1, 2, 3]: print x 1 2 3 迭代 list 截取定义原始样例list L = [&#39;v1&#39;, &#39;v2&#39;, &#39;v3&#39;] 表达式 结果 描述 L[2] ‘v3’ 读取列表中第三个元素 L[-2] ‘v2’ 读取列表中倒数第二个元素 L[1:] [‘v2’, ‘v3’] 从第二个元素开始截取列表 反转list以下source代表list，ie: source=[1,2,3,4,5,6,7,8,9] 使用reversed()函数 1b=list(reversed(source)) 使用sorted()函数 1c=sorted(source,cmp=None, key=None, reverse=True) 使用分片 1d=source[::-1] 其中[::-1]代表从后向前取值，每次步进值为1 默认参数，单星号参数，双星号参数 默认值函数参数第一个有默认值的参数后的每一个参数都必须提供默认值。传参时，可以直接传参，也可以以“默认值参数名=value”的形式传参。 单星号函数参数单星号函数参数接收的参数组成一个元组 &#39;()&#39;。 双星号函数参数双星号函数参数接收的参数组成一个字典 &#39;{}&#39;。 一个星号（*）的函数参数 不传参数参数位置被解析为空元组() 传多个值多个参数被解析为一个元组 传多个元组解析后的元组中的每个元素都是元组 参数是元组，并希望作为星号参数的参数值（不被再套一层元组）传入元组参数前加一个星号 * 两个星号（**）的函数参数 不传参数参数位置被解析为空map{} 传多个值，每个参数格式为 key = val每个参数会作为一个kv保存在map {}中 参数传入map，作为双星号参数的参数值传入map参数前加两个星号 ``** 常用描述from…import &amp; import…as from...importfrom A import b 相当于 12import Ab = A.b import...asimport A as B 给A库定义一个别名B lambda &amp; def 差别最大差别: lambda可以定义一个匿名函数，而def定义的函数必须有一个名字与JavaScript不同的是，Python中匿名函数与非匿名函数需要使用不同的语法来定义。这是因为：lambda是一个expression，不是一个statement因此lambda表达式可以出现在def无法出现的地方。比如list comprehension。lambda的函数体是一个简单的表达式而不是语句块。所以lambda中没有return语句。也不能使用if, while等等 if __name__ == &#39;__main__&#39;:作用及原理python文件两种使用方法 直接作为脚本执行 import到其他的python脚本中被调用（模块重用）if __name__ == &#39;__main__&#39;: 保证只有在直接作为脚本时才能执行，import到其他脚本时不会执行具体含义见特殊变量定义 python中的下划线 _xxx保护变量，只有类对象和子类对象自己能访问到这些变量； __xxx私有成员，意思是只有类对象自己能访问，连子类对象也不能访问到这个数据。 __xxx__系统定义名称 __name__ 直接被执行时，__name__为含.py尾缀的文件名 import时，__name__等于模块名称__main__ 当前执行文件的文件名__init 构造函数第一个参数永远是self，表示创建的实例本身，因此，在__init__方法内部，就可以把各种属性绑定到self，因为self就指向创建的实例本身 if-else 单行写法12345678if a&gt;b: c = aelse: c = b# 等同于c = a if a&gt;b else b python 用法list作为Stack .append() .pop() 作为Queue .append() .popleft() List ComprehensionsList comprehensionsList comprehensions provide a concise way to create lists以下三种方法等价 方法1 12345squares = [] for x in range(10): squares.append(x**2)squares&gt;&gt;&gt; [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] 方法2 1squares = list(map(lambda x: x**2, range(10))) 方法3 1squares = [x**2 for x in range(10)] Nested List Comprehensions1[[row[i] for row in matrix] for i in range(4)] defaultdict &amp; lambda基础用法123x = defaultdict(lambda: 0)# 可以简写为x = defaultdict(int) when I call x[k] for a nonexistent key k (such as a statement like v=x[k]), the key-value pair (k,0) will be automatically added to the dictionary, as if the statement x[k]=0 is first executed. 进阶用法1y = defaultdict(lambda: defaultdict(lambda: 0)) when you do y[&quot;ham&quot;][&quot;spam&quot;], the key “ham“ is inserted in y if it does not exist. The value associated with it becomes a defaultdict in which “spam“ is automatically inserted with a value of 0.I.e., y is a kind of “two-tiered” defaultdict. If “ham” not in y, then evaluating y[“ham”][“spam”] is like doing (),[],{}()代表tuple元组 [] 代表list列表数据，列表是一种可变的序列 字符串后边表示截取指定长度的字符串line = &#39;+&#39; + (&#39;+------&#39; * self.width + &#39;+&#39;)[1:]，最终实现目的是输出+------+------+------+------+这不是最优的写法，可以调整为line = &#39;+&#39; + (&#39;------+&#39; * self.width){}代表dict字典类型。Set集合类型12&#123;x: x**2 for x in (2, 4, 6)&#125;basket = &#123;&apos;apple&apos;, &apos;orange&apos;, &apos;apple&apos;, &apos;pear&apos;, &apos;orange&apos;, &apos;banana&apos;&#125; 定义函数 函数定义通过def定义函数 123def functionname(params): statement1 statement2 默认参数 12345def test(a , b=-99): if a &gt; b: return True else: return False 默认参数使用限制 默认参数后边不能再有普通参数 默认值只被赋值一次（比如data=[]，则整个代码生命周期中，都只会创建一次数组）12345678910def f(a, data=[]): data.append(a) return data...&gt;&gt;&gt; print(f(1))[1]&gt;&gt;&gt; print(f(2))[1, 2]&gt;&gt;&gt; print(f(3))[1, 2, 3] 强制关键字参数 1234def hello(*, name=&apos;User&apos;): print(&quot;Hello&quot;, name)hello(name=&apos;shiyanlou&apos;) 文档字符串 docstrings（说明如何使用代码） 12345678910111213#!/usr/bin/env python3import mathdef longest_side(a, b): &quot;&quot;&quot; Function to find the length of the longest side of a right triangle. :arg a: Side a of the triangle :arg b: Side b of the triangle :return: Length of the longest side c as float &quot;&quot;&quot; return math.sqrt(a*a + b*b) 高阶函数高阶函数（Higher-order function）或仿函数（functor）是内部至少含有一个以下步骤的函数： 使用一个或多个函数作为参数返回另一个函数作为输出 Python 里的任何函数都可以作为高阶函数。 12345def high(func, value): return func(value)lst = high(dir, int)print(lst[-3:])[&apos;imag&apos;, &apos;numerator&apos;, &apos;real&apos;] map函数map是一个在 Python 里非常有用的高阶函数。 它接受一个函数和一个序列（迭代器）作为输入，然后对序列（迭代器）的每一个值应用这个函数，返回一个序列（迭代器），其包含应用函数后的结果。 123456lst = [1, 2, 3, 4, 5]def square(num): return num * num...print(list(map(square, lst)))[1, 4, 9, 16, 25] any函数任何一个为True，则返回True 数据结构元组 tuple 由数个都好分割的值组成a = &#39;Fedora&#39;, &#39;ShiYanLou&#39;, &#39;Kubuntu&#39;, &#39;Pardus&#39; 可以对任何一个元组执行拆封操作并赋值给多个变量x, y = divmod(15,2) 元组是不可变类型 创建只含有一个元素的元组，在值后面跟一个逗号b = 321, 字符串一些有意思的地方 分几行输入字符串 12345678print(&quot;&quot;&quot;\ Usage: thingy [OPTIONS] -h Display this usage message -H hostname Hostname to connect to&quot;&quot;&quot;)&gt;&gt; Usage: thingy [OPTIONS]&gt;&gt; -h Display this usage message&gt;&gt; -H hostname Hostname to connect to python支持回文 1234567#!/usr/bin/env python3s = input(&quot;Please enter a string: &quot;)z = s[::-1]if s == z: print(&quot;The string is a palindrome&quot;)else: print(&quot;The string is not a palindrome&quot;) 单词计数 123#!/usr/bin/env python3s = input(&quot;Enter a line: &quot;)print(&quot;The number of words in the line are %d&quot; % (len(s.split(&quot; &quot;)))) 集合无序不重复元素的集集合支持的操作 union：联合 intersection：交集 difference：差集 symmetric difference：对称差集 集合表示方法 大括号{}basket = {&#39;apple&#39;, &#39;orange&#39;, &#39;apple&#39;, &#39;pear&#39;, &#39;orange&#39;, &#39;banana&#39;} set()a = set(&#39;abracadabra&#39;) k-v （字典） 创建data = {&#39;kushal&#39;:&#39;Fedora&#39;, &#39;kart_&#39;:&#39;Debian&#39;, &#39;Jace&#39;:&#39;Mac&#39;} 新增data[&#39;parthan&#39;] = &#39;Ubuntu&#39; 删除del data[&#39;kushal&#39;] 判断是否存在&#39;ShiYanLou&#39; in data 从包含键值对的元组中创建dict(((&#39;Indian&#39;,&#39;Delhi&#39;),(&#39;Bangladesh&#39;,&#39;Dhaka&#39;))) 遍历 12for x, y in data.items(): print(&quot;&#123;&#125; uses &#123;&#125;&quot;.format(x, y)) 不存在则添加默认v 12data = &#123;&#125;data.setdefault(&apos;names&apos;, []).append(&apos;Ruby&apos;) 查找的key不存在时返回默认值data.get(&#39;foo&#39;, 0) 遍历 遍历列表（或任何序列类型）的同时获得元素索引值 enumerate() 1234567for i, j in enumerate([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;]): print(i, j)# 其中i是索引# ...# 0 a# 1 b# 2 c 同时遍历两个序列类型 zip() 1234a = [&apos;Pradeepto&apos;, &apos;Kushal&apos;]b = [&apos;OpenSUSE&apos;, &apos;Fedora&apos;]for x, y in zip(a, b): print(&quot;&#123;&#125; uses &#123;&#125;&quot;.format(x, y)) 异常异常定义 名称 描述 NameError 试图访问一个未定义的变量 TypeError 当操作或函数应用于不适当类型的对象时引发，一个常见的例子是对整数和字符串做加法 处理异常1234567try: statements to be inside try clause statement2 statement3 ...except ExceptionName: statements to evaluated in case of ExceptionName happens 抛出异常 raise1raise ValueError(&quot;A value error happened.&quot;) 清理行为 finally1234try: raise KeyboardInterruptfinally: print(&apos;Goodbye, world!&apos;) 类在Python中，所有数据类型都可以视为对象，当然也可以自定义对象。自定义的对象数据类型就是面向对象中的类（Class）的概念。 定义类 &amp; 类继承1234class nameoftheclass(parent_class, parent_class_2, ...): statement1 statement2 statement3 构造方法 __init__123def __init__(self): statement statement 属性（attributes）读取 在 Python 里请不要使用属性（attributes）读取方法（getters 和 setters） 装饰器 @property（对指定的属性的set或get方法增加filter）12345678910111213class Account(object): @property def amount(self): &quot;&quot;&quot;账号余额（美元）&quot;&quot;&quot; return self.__amt @amount.setter def amount(self, value): if value &lt; 0: print(&quot;Sorry, no negative amount in the account.&quot;) return self.__amt = value 模块 模块是包括 Python 定义和声明的文件。文件名就是模块名加上 .py 后缀。 __name__可以由全局变量 name 得到模块的模块名（一个字符串）。 模块示例，文件名为 bars.py，可以通过import model_name导入模块12345678910111213141516171819202122232425&quot;&quot;&quot;Bars Module，File name is bars.py============这是一个打印不同分割线的示例模块&quot;&quot;&quot;def starbar(num): &quot;&quot;&quot;打印 * 分割线 :arg num: 线长 &quot;&quot;&quot; print(&apos;*&apos; * num)def hashbar(num): &quot;&quot;&quot;打印 # 分割线 :arg num: 线长 &quot;&quot;&quot; print(&apos;#&apos; * num)def simplebar(num): &quot;&quot;&quot;打印 - 分割线 :arg num: 线长 &quot;&quot;&quot; print(&apos;-&apos; * num) 常用模块 名称 描述 os 提供与操作系统相关的功能 requests Requests 唯一的一个非转基因的 Python HTTP 库，人类可以安全享用。警告：非专业使用其他 HTTP 库会导致危险的副作用，包括：安全缺陷症、冗余代码症、重新发明轮子症、啃文档症、抑郁、头疼、甚至死亡。 collections 包含一些很好用的数据结构 unittest python 单元测试，异常测试 Counter 有助于 hashable 对象计数的 dict 子类。它是一个无序的集合，其中 hashable 对象的元素存储为字典的键，它们的计数存储为字典的值，计数可以为任意整数，包括零和负数。 elements() 的方法，其返回的序列中，依照计数重复元素相同次数，元素顺序是无序的。 most_common() 方法返回最常见的元素及其计数，顺序为最常见到最少。12345678910111213&gt;&gt;&gt; from collections import Counter&gt;&gt;&gt; import re&gt;&gt;&gt; path = &apos;/usr/lib/python3.4/LICENSE.txt&apos;&gt;&gt;&gt; words = re.findall(&apos;\w+&apos;, open(path).read().lower())&gt;&gt;&gt; Counter(words).most_common(10)[(&apos;the&apos;, 80), (&apos;or&apos;, 78), (&apos;1&apos;, 66), (&apos;of&apos;, 61), (&apos;to&apos;, 50), (&apos;and&apos;, 48), (&apos;python&apos;, 46), (&apos;in&apos;, 38), (&apos;license&apos;, 37), (&apos;any&apos;, 37)]&gt;&gt;&gt; c = Counter(a=4, b=2, c=0, d=-2)&gt;&gt;&gt; list(c.elements())[&apos;b&apos;,&apos;b&apos;,&apos;a&apos;, &apos;a&apos;, &apos;a&apos;, &apos;a&apos;]&gt;&gt;&gt; Counter(&apos;abracadabra&apos;).most_common(3)[(&apos;a&apos;, 5), (&apos;r&apos;, 2), (&apos;b&apos;, 2)] 包含有 __init__.py 文件的目录可以用来作为一个包，目录里的所有 .py 文件都是这个包的子模块 如果 __init__.py 文件内有一个名为 __all__ 的列表，那么只有在列表内列出的名字将会被公开 迭代器Python 迭代器（Iterators）对象在遵守迭代器协议时需要支持如下两种方法。 __iter__()，返回迭代器对象自身。这用在 for 和 in 语句中。 __next__()，返回迭代器的下一个值。如果没有下一个值可以返回，那么应该抛出 StopIteration 异常。 生成器生成器表达式闭包 Closures （嵌套函数）闭包（Closures）是由另外一个函数返回的函数。我们使用闭包去除重复代码。在下面的例子中我们创建了一个简单的闭包来对数字求和。 1234567891011121314&gt;&gt;&gt; def add_number(num):... def adder(number):... #adder 是一个闭包... return num + number... return adder...&gt;&gt;&gt; a_10 = add_number(10)&gt;&gt;&gt; a_10(21)31&gt;&gt;&gt; a_10(34)44&gt;&gt;&gt; a_5 = add_number(5)&gt;&gt;&gt; a_5(3)8 文件操作 open()文件打开open() 函数打开文件。第一个参数是文件路径或文件名第二个是文件的打开模式。 模式通常是下面这样的：r: 默认方式 以只读模式打开，你只能读取文件但不能编辑/删除文件的任何内容w: 以写入模式打开，如果文件存在将会删除里面的所有内容，然后打开这个文件进行写入a: 以追加模式代开，写入到文件中的任何数据将自动添加到末尾 文件关闭 close() 需要保证显式关闭，因为能够打开的文件句柄是有限的 文件读取 read() read(): 全部读完 read(size): 读取指定长度 readline(): 读取一行 文件写入 write() 会覆盖当前存储的信息 安全的操作文件 with 使用with，可以保证文件自动关闭 123with open(&apos;sample.txt&apos;) as fobj: for line in fobj: print(line, end = &apos;&apos;) linux下查询当前CPU信息 lscpu只读方式读取 /proc/cpuinfo 中的信息 便利方法内建函数 type()查看任意变量的数据类型 range() __doc__查看方法的doc]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数学名词]]></title>
    <url>%2F2017%2F05%2F22%2Fmath-phrase%2F</url>
    <content type="text"><![CDATA[名词范数http://baike.baidu.com/item/%E8%8C%83%E6%95%B0是具有“长度”概念的函数。在线性代数、泛函分析及相关的数学领域，范数是一个函数，是矢量空间内的所有矢量赋予非零的正长度或大小。半范数可以为非零的矢量赋予零长度]]></content>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lambda基础]]></title>
    <url>%2F2017%2F05%2F21%2Fjdk-lambda-fundamental%2F</url>
    <content type="text"><![CDATA[Function接口Predicate&lt;T&gt; –&gt; 接收T对象并返回boolean（断言，返回true、false）Consumer&lt;T&gt; –&gt; 接收T对象，不返回值（处理，无返回）Function&lt;T, R&gt; –&gt; 接收T对象，返回R对象，T –&gt; R（T转换为R）Supplier&lt;T&gt; –&gt; 提供T对象（例如工厂），不接收值（构造器）UnaryOperator&lt;T&gt; –&gt; 接收T对象，返回T对象（一元运算）BinaryOperator&lt;T&gt; –&gt; 接收两个T对象，返回T对象（二元运算）]]></content>
      <tags>
        <tag>lambda</tag>
        <tag>jdk</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虎猫乐园markdown基本配色]]></title>
    <url>%2F2017%2F05%2F21%2Fbase-markdown-grammar%2F</url>
    <content type="text"><![CDATA[markdown syntaxmarkdown 语法 颜色 显示样式 markdown 重点提示 &lt;font color=#0099ff&gt;**重点提示**&lt;/font&gt; 错误信息 &lt;font color=#ff0000&gt;**错误信息**&lt;/font&gt;]]></content>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sublime插件管理]]></title>
    <url>%2F2017%2F05%2F21%2Fsublime-plugin-package-control%2F</url>
    <content type="text"><![CDATA[Sublime插件安装Package Control如何安装Package Control （推荐Simple方式） 安装插件如何安装插件 ctrl + shift + p (Win, Linux)cmd + shift + p (OS X) 输入 –&gt; Package Control: Install Package –&gt; 要安装的插件名称 插件浏览Package Control Browse]]></content>
      <tags>
        <tag>sublime</tag>
        <tag>plugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git_rebase]]></title>
    <url>%2F2017%2F05%2F20%2Fgit-rebase%2F</url>
    <content type="text"></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
</search>
