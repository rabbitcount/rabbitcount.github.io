---
title: CPU 缓存结构
date: 2019-05-15 17:47:13
tags:
- cpu cache
- false sharing
- 伪共享
---

简述
**CPU 缓存**： **Register >> L1 Cache >> L2 Cache >> L3 Cache >> Memory >> Mass storage**
- **L1**：最小、最快、核心独享；分为 数据(Data) 和 指令(Instruction) 缓存
- **L2**
- **L3**：最大、最慢、共享


<!-- more -->
---

# CPU Cache 介绍

随着CPU频率的不断提升，内存的访问速度却并没有什么突破。所以，为了弥补内存访问速度慢的硬伤，便出现了CPU缓存。它的工作原理如下：
多采用 **Register ―> L1 Cache ―> L2 Cache ―> L3 Cache ―> Memory ―> Mass storage** 的结构，在性能和成本间达成平衡；

* 当CPU要读取一个数据时，首先从缓存中查找，如果找到就立即读取并送给CPU处理；
* 如果没有找到，就用相对慢的速度从内存中读取并送给CPU处理，同时把这个数据所在的数据块调入缓存中，便于后续调用。

为充分发挥CPU的计算性能和吞吐量，现代CPU引入了一级缓存（L1）、二级缓存（L2）和三级缓存（L3），结构如下图所示：

![](https://wiki-1258407249.cos.ap-chengdu.myqcloud.com/2019-05-15-cpu-cache/cpu-architecture-v2.png)

* L1 Cache（Core独立）： 
    一般L1 Cache的大小是 **32k**；
    `D-Cache` ：用来存储数据；
    `I-Cache` 用来存放指令；
* L2 Cache（一般Core独立）：
     更大一些，例如 **256K** , 速度要慢一些；
     一般情况下每个核上都有一个独立的 L2 Cache；
* L3 Cache（共享）：
    三级缓存中最大的一级，例如 **25MB** ；
    同时也是最慢的一级，在同一个CPU插槽之间的核共享一个L3 Cache。

当CPU计算时，首先去L1去寻找需要的数据，如果没有则去L2寻找，接着从L3中寻找，如果都没有，则从内存中读取数据。所以，如果某些数据需要经常被访问，那么这些数据存放在L1中的效率会最高。

| 从CPU到 | 大约需要的CPU周期 | 大约需要的时间 | | 2019配置 | 
|---|---|---|---|---|
| 寄存器 |1 cycle  | | | |
| L1 Cache | ~3\-4 cycles  | ~0.5\-1 ns  | index0/index1 | 32K/32K |
| L2 Cache  | ~10\-20 cycles  |  ~3\-7 ns | index2 | 256K |
| L3 Cache  | ~40\-45 cycles  | ~15 ns  | index3 | 24M |
| 跨槽传输  | ~20 ns  | | | |
| 内存  | ~120\-240 cycles |  ~60\-120 ns | | | |

在Linux中可以通过如下命令查看 CPU Cache（2019年生产环境机器配置）：

```
> cat /sys/devices/system/cpu/cpu0/cache/index0/type
Data
> cat /sys/devices/system/cpu/cpu0/cache/index1/type
Instruction
> cat /sys/devices/system/cpu/cpu0/cache/index0/size
32K
> cat /sys/devices/system/cpu/cpu0/cache/index1/size
32K
> cat /sys/devices/system/cpu/cpu0/cache/index2/size
256K
> cat /sys/devices/system/cpu/cpu0/cache/index3/size
25600K
```
其中
- index0: `L1 D-Cache`
- index1: `L1 I-Cache`

# Cache Line 缓存行

缓存是由缓存行组成的。一般一行缓存行有 **64字节**（数据来源：2019生产环境机器）。
CPU在操作缓存时是以缓存行为单位的，可以通过如下命令查看缓存行的大小：
```
cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size
64
```

由于CPU存取缓存都是按行为最小单位操作的。对于long类型来说，一个long类型的数据有64位，也就是8个字节，所以对于数组来说，由于数组中元素的地址是连续的，所以在加载数组中第一个元素的时候会把后面的元素也加载到缓存行中。


如果一个long类型的数组长度是8，那么也就是64个字节了，CPU这时操作该数组，会把数组中所有的元素都放入缓存行吗？答案是否定的，原因就是在Java中，对象在内存中的结构包含对象头，可以参考我的另一篇文章[Java对象内存布局](https://link.jianshu.com?t=http://www.ideabuffer.cn/2017/05/06/Java%E5%AF%B9%E8%B1%A1%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/)来了解。

# Cache Miss

- cold misses（不可避免）
也称为 compulsory misses或者cold misses。
首次读写时，造成的miss；
- capacity misses
cache已满，即超出了cache本身的能力；这时如果要读取内存数据，而数据还没有移到cache里面，就会造成cache miss，比较常见。
- conflict misses
是一种可以避免的cache miss，主要由于我们的cache替换策略不当造成的，软件来说，需要写出内存友好的程序；主要场景 false sharing；

## capacity misses VS conflict misses
1. You repeatedly iterate over a 128k array. There's no way the data can fit in that cache, therefore all the misses are capacity ones (except the first access of each line which is a compulsory miss, and would remain even if you could increase your cache infinitely).
2. You have 2 small 8k arrays, but unfortunately they are both aligned and map to the same sets. This means that while they could theoretically fit in the cache (if you fix your alignment), they will not utilize the full cache size and instead compete for the same group of sets and thrash each other. These are conflict misses, since the data could fit, but still collides due to organization. The same problem can occur with set associative caches, although less often (let's say the cache is 2-way, but you have 4 aligned data sets...).

